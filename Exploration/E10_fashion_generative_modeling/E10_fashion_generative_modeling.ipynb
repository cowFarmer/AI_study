{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04dbb41a",
   "metadata": {},
   "source": [
    "# 인공지능으로 세상에 없던 새로운 패션 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed431a3f",
   "metadata": {},
   "source": [
    "지금까지 많이 분류 모델을 많이 만들었다. 이들은 판별 모델링(Discriminative Modeling)이라고 부른다. 생성 모델링(Generative Modeling)은 학습한 데이터셋과 비슷하면서 기존에 없는 새로운 데이터셋을 생성하는 모델이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303cf7c",
   "metadata": {},
   "source": [
    "[Announcing AWS DeepComposer with Dr. Matt Wood, feat. Jonathan Coulton\n",
    "](https://www.youtube.com/watch?v=XH2EbK9dQlg&t=650s)   \n",
    "AWS의 음악을 만드는 DeepComposer를 보면 생성자(generator), 판별자(discriminator) 두 가지 네트워크로 모델을 만들었다. 생성자는 오케스트라의 역할로 음악을 만드는 역할을 하고 판별자는 지휘자의 역할로 피드백을 하며 음악을 더 괜찮게 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20498ce7",
   "metadata": {},
   "source": [
    "# Pix2Pix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1663dcca",
   "metadata": {},
   "source": [
    "간단한 이미지를 입력하면 실제 사진처럼 바꿔줄 때 많이 사용하는 모델이다. input image를 받으면 내부 연산을 통해 실제 사진같은 predicted image를 출력해준다. 초기에는 ground truth와 비교하며 평가하고 점차 실제같은 결과물을 만들어낸다. [논문](https://arxiv.org/pdf/1611.07004.pdf)   \n",
    "![](https://cdn-ak.f.st-hatena.com/images/fotolife/l/lib-arts/20190602/20190602114525.png)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ed56f",
   "metadata": {},
   "source": [
    "# CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8096f",
   "metadata": {},
   "source": [
    "Pix2Pix에서 발전된 모델로 CycleGAN이 있다. 한 이미지와 다른 이미지를 번갈아가며 Cyclic하게 변환할 수 있다. 실사 이미지를 그림으로 바꾸는 것 과 그림을 실사 이미지로 바꾸는 두 가지가 모두 가능한 양방향으로 이미지 변환이 가능하다. 각각의 사진 데이터만 있으면 각 스타일을 학습해서 이미지에 학습한 스타일을 입힐 수 있다. 딥러닝에서 쌍으로 된 데이터가 필요 없다는 것은 데이터를 구하기 쉽고 라벨을 붙이는 주석 비용이 필요하지 않아 큰 장점이다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/CycleGAN.max-800x600.png)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e93fa4",
   "metadata": {},
   "source": [
    "다른 유명한 활용 사례는 실제 사진을 가른 화가가 그린 그림처럼 바꾸는 것이다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/CycleGAN2.max-800x600.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d368e14",
   "metadata": {},
   "source": [
    "# Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0241f92c",
   "metadata": {},
   "source": [
    "이미지의 스타일을 변환시키는 방법이다. 전체 이미지를 구성하고 싶은 Base Image의 content(내용)만 추출하고, 입히고 싶은 스타일이 담긴 Style Image의 style을 추출한다. base와 style 두 장을 활용해서 새로운 이미지를 만들어 내는 것이다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/StyleTransfer.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c254922",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5c1e8",
   "metadata": {},
   "source": [
    "fashion MNIST 데이터셋으로 [fashion-mnist 깃허브](https://github.com/zalandoresearch/fashion-mnist)를 참고하자.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7f4b5",
   "metadata": {},
   "source": [
    "28x28 흑백 사진의 train set 6만장, test set 1만장으로 이루어져있다. 0~9까지의 카테고리로 0-T-shirt/top, 1-Trouser, 2-Pullover, 3-Dress, 4-Coat, 5-Sandal, 6-Shirt, 7-Sneaker, 8-Bag, 9-Ankle boot으로 구성되어 있다. 기존 숫자 분류기 MNIST는 too easy, overused, noet represent modern CV tasks 의 이유로 새롭게 만들어졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69406644",
   "metadata": {},
   "source": [
    "# 코드 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ebf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_x, _), (test_x, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa2a46",
   "metadata": {},
   "source": [
    "라벨이 필요 없기 때문에 `y_train`, `y_test`는 `_`로 데이터를 무시하고 불러오도록 진행했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a51fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max pixel:\", train_x.max())\n",
    "print(\"min pixel:\", train_x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798065d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (train_x - 127.5) / 127.5 # 이미지를 [-1, 1]로 정규화\n",
    "\n",
    "print(\"max pixel:\", train_x.max())\n",
    "print(\"min pixel:\", train_x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c101b22",
   "metadata": {},
   "source": [
    "딥러닝에서 이미지를 다루려면 채널 수에 대한 차원이 필요하다. 흑백 이미지이므로 채널값 1을 추가하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99868d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], 28, 28, 1).astype('float32')\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[0].reshape(28, 28), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05968cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_x[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'index: {i}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 12))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    random_index = np.random.randint(1, 60000) # 랜덤으로 정수를 만들어서 25개를 보여주는 함수\n",
    "    plt.imshow(train_x[random_index].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'index: {random_index}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f40692",
   "metadata": {},
   "source": [
    "### 데이터 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec083aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daddc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_x).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17e050",
   "metadata": {},
   "source": [
    "BUFFER_SIZE가 데이터셋을 섞어서 모델에 넣어주고, BATCH_SIZE별로 잘라서 학습을 진행하는 __미니 배치 학습__이다. [텐서플로우 도큐먼트 tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4bdc3",
   "metadata": {},
   "source": [
    "# 그림을 만드는 생성자, 평가하는 비평가 판별자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c511d91",
   "metadata": {},
   "source": [
    "가장 간단한 형태의 생성 모델중 GAN(Generative Adversarial Network)이 있다. 2014년 lan Goodfellow라는 연구자에서 나왔고 두 가지 네트워크가 있다. [논문 확인하기](https://arxiv.org/pdf/1406.2661.pdf)   \n",
    "- 생성자 generator: 의미 없는 랜덤 노이즈로부터 신경망에서 연산을 통해 이미지 형상의 벡터를 생성한다. \n",
    "- 판별자 discriminator: 기존에 있던 진짜 이미지와 생성자가 만들어낸 이미지를 입력받아 각 이미지가 real, fake에 대한 판단을 실숫값 정도로 출력한다. \n",
    "\n",
    "논문을 확인하면 두 네트워크에 생성자가 만든것을 판별자가 구별할 수 없을만큼 계속해서 경쟁하듯 서로의 개선을 유도하는데, 이 때문에 Adversarial(적대적인)으로 표현했다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GAN.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d21c3",
   "metadata": {},
   "source": [
    "## 생성자 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c37e0d",
   "metadata": {},
   "source": [
    "DCGAN(Deep convolutional GAN)은 GAN이 발표되고 1년 반 후에 발표된 논문이다. GAN을 발전시켜 고화질 이미지 생성을 이루어낸 첫 번재 논문이다. 이후 GAN 기반 이미지 생성은 DCGAN 모델을 발전시킨 형태이므로 매우 의미 있으니 한번 구조를 살펴보자. [Tensorflow 2.0 DCGAN 구현](https://www.tensorflow.org/tutorials/generative/dcgan?hl=ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0548cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "\n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # First: Dense layer\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Second: Reshape layer\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "\n",
    "    # Third: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=(5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fourth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fifth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(1, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False, \\\n",
    "                                     activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777ada4",
   "metadata": {},
   "source": [
    "중요한게 Conv2DTranspose 레이어로 Conv2D와 반대로 이미지 사이즈를 넓혀주는 층이다. 이를 세 번 사용해 (7, 7, 256) -> (14, 14, 64) -> (28, 28, 1) 으로 이미지를 키웠다.   \n",
    "BatchNormalization 레이어는 신경망의 가중치가 폭발하지 않도록 정규화 시켜주고 활성화 함수는 LeakyReLU를 사용했다. 마지막은 tanh를 사용했는데 -1~1로 정규화한 데이터셋과 동일하기위해 사용했다.\n",
    "- [Batch normalization](https://eehoeskrap.tistory.com/430)\n",
    "- [활성화 함수](https://newly0513.tistory.com/20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
