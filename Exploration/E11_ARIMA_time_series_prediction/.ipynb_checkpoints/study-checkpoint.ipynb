{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2098e2",
   "metadata": {},
   "source": [
    "# 어제 오른 내 주식, 과연 내일은?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c4411",
   "metadata": {},
   "source": [
    "시계열 예측(Time-Series Prediction)을 다루는 여러 통계적 기법 중 가장 널리 알려진 ARIMA(Auto-regressive Integrated Moving Average)에 대해 알아보고 이를 토대로 주식의 가격을 예측하는 실습을 진행해보자.   \n",
    "시계열 예측에 페이스북에서 발표한 Prophet이나 딥러닝을 활용하는 LSTM 등 다양한 방법이 있다. ARIMA는 통계학 이론적 기반을 갖추고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ada4c",
   "metadata": {},
   "source": [
    "# 11-2. 미래 예측 가능할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef256be7",
   "metadata": {},
   "source": [
    "미래 예측 시나리오를 가정해보자.   \n",
    "- 지금까지의 주가 변화를 바탕으로 다음 주가 변동 예측하기\n",
    "- 특정 지역의 기후 데이터를 바탕으로 내일의 온도 변화 예측하기\n",
    "- 공장 센터 데이터 변화 이력을 토대로 이상 발생을 예측하기   \n",
    "\n",
    "위 3가지의 공통점은 예측의 근거가 시계열(time series) 데이터이다. 시계열은 시간 순서대로 발생한 데이터의 수열이다. 일정 시간 간격으로 발생한 데이터면 좋지만 꼭 그래야만 하진 않다. 그리고 매일의 주식 거래 가격을 `날짜-가격` 형태로 모아둔 데이터가 있으면 훌륭한 시계열 데이터가 될것이다. 이때 날짜가 index 역할을 하게 된다.   \n",
    "\n",
    "과거의 데이터만 보고 주가가 오를지 내릴지 예측이 가능할까? 사실 미래 예측은 불가능하고 다음 전제가 필요하다.   \n",
    "1. 과거의 데이터에 일정한 패턴이 발견된다.\n",
    "2. 과거의 패턴은 미래에도 동일하게 반복될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ae8e2",
   "metadata": {},
   "source": [
    "즉 __안정적(stationary)__ 인 데이터만 미래 예측이 가능하다. 이 말은 시계열 데이터의 통계적 특성이 변하지 않는다는 뜻이다. 매우 불규칙해 보이는 하루하루의 날씨 변화에도 연 단위 기후 변화를 보면 일정한 패턴이 유지된다. 그러면 이런 경우 지구상의 일정한 기후 변동 프로세스가 안정성을 갖고 있으며 내일의 기온도 일정 오차 범위 내에서 예측이 가능할 것이다. [그림자로 원유재고 알아낸다](https://news.einfomax.co.kr/news/articleView.html?idxno=4082410) 기사를 읽어보자   \n",
    "\n",
    "시계열 데이터 분석은 완벽한 예측을 보장하지 않는다. 왜냐하면 수많은 변수에 의해 시계열 데이터 분석의 전제인 안정성(stationarity)이 훼손될 가능성이 크기 때문이다. 그럼에도 시간적 변화를 묘사하는데 훌륭하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379db09",
   "metadata": {},
   "source": [
    "# 11-3. Stationary한 시계열 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc473e",
   "metadata": {},
   "source": [
    "안정적 시계열(stationary time-series)의 직관적인 정의를 알아보자. [A Complete Tutorial on Time Series Modeling in R](https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/)에서 `1. Basics`를 보면 안정적인 시계열에서 시간의 추이와 관계없이 __평균, 분산, 공분산__ 은 일정해야 한다고 한다.   \n",
    "__분산과 공분산__ 은 무엇일까? [공분산과 상관계수](https://destrudo.tistory.com/15)   \n",
    "평균은 분포의 중간부분이고, 분산은 분포가 얼마나 퍼져있는지를 말한다. 2가지의 확률변수가 어떤 모양으로 확률분포되어 있는지 알고 싶을 때 이를 나타내는 것이 공분산이다. 하지만 공분산은 단위의 크기에 영향을 받고 이를 보완하기 위해 항상 `-1 ~ 1`의 값을 가진 상관계수가 나왔다.   \n",
    "[__자기공분산과 자기상관__](https://m.blog.naver.com/sw4r/221030974616)   \n",
    "자기공분산은 X(t)와 X(t+h) 사이의 공분산이다. h 간격만큼 이동시켰다고 표현했다. X(t-h)와 X(t)도 안정적인 시계열이라는 조건이 있으면 같은 의미이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219c089",
   "metadata": {},
   "source": [
    "> 직전 5년치 판매량 X(t-4), X(t-3), X(t-2), X(t-1), X(t)를 가지고 X(t+1)이 얼마인지 예측해보자.\n",
    "\n",
    "이 예측이 의미가 있으려면 t에 무관하게 예측이 맞아야 한다. t=2010일때의 데이터로 X(2011)을 정확하게 예측하는 모델이라면 t=2020을 대입해도 x(2021)을 정확하게 예측할 수 있다. 그렇기 위해선 __t에 무관하게__ X(t-4), `X(t-3), X(t-2), X(t-1), X(t)`의 평균과 분산이 일정 범위 안에 있어야 한다. 그리고 X(t-h)와 X(t)는 t에 무관하게 h에 대해서만 달라지는 일정한 `상관도`를 가져야 한다. 그렇지 않으면 시계열 예측은 t에 따라 달라지는 예측이 된다. 이것은 `과거의 패턴이 미래에 반복된다`는 시계열 예측의 대전제를 무너뜨린다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef839d0",
   "metadata": {},
   "source": [
    "# 11-4. 시계열 데이터 사례 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b74d33",
   "metadata": {},
   "source": [
    "```\n",
    "$ mkdir -p ~/aiffel/stock_prediction/data\n",
    "$ ln -s ~/data/* ~/aiffel/stock_prediction/data\n",
    "```\n",
    "\n",
    "`Daily Minimum Temperatures in Melbourne`이라는 온도 변화 데이터를 다뤄보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4500a55",
   "metadata": {},
   "source": [
    "### 시계열 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filepath = os.getenv('HOME')+'/aiffel/stock_prediction/data/daily-min-temperatures.csv' \n",
    "df = pd.read_csv(dataset_filepath) \n",
    "print(type(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a6d7c",
   "metadata": {},
   "source": [
    "Date를 index로 삼아서 시계열을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 Date를 index_col로 지정\n",
    "df = pd.read_csv(dataset_filepath, index_col='Date', parse_dates=True)\n",
    "print(type(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = df['Temp']  # 데이터 확인용 time series 의 이니셜을 따서 'ts'\n",
    "print(type(ts1))\n",
    "ts1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d9c37",
   "metadata": {},
   "source": [
    "### 시계열 안정성의 정성적 분석   \n",
    "\n",
    "시각화를 통해 안정성 여부를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 13, 6    # matlab 차트의 기본 크기를 13, 6으로 지정해 줍니다.\n",
    "\n",
    "# 시계열(time series) 데이터를 차트로 그려 봅시다. 특별히 더 가공하지 않아도 잘 그려집니다.\n",
    "plt.plot(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1[ts1.isna()]  # 시계열(Time Series)에서 결측치가 있는 부분만 Series로 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e0eee",
   "metadata": {},
   "source": [
    "결측치를 확인하는데 만약 있다면 결측치가 있는 데이터를 모두 삭제하거나, 양 옆의 값들을 이용해 적절히 보간(interpoltae)하여 대입하는 방법이 있다. [결측값 보간하기 interpolate()](https://rfriend.tistory.com/264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 있다면 이를 보간합니다. 보간 기준은 time을 선택합니다. \n",
    "ts1=ts1.interpolate(method='time')\n",
    "\n",
    "# 보간 이후 결측치(NaN) 유무를 다시 확인합니다.\n",
    "print(ts1[ts1.isna()])\n",
    "\n",
    "# 다시 그래프를 확인해봅시다!\n",
    "plt.plot(ts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d588da",
   "metadata": {},
   "source": [
    "직관적으로 차트만 봤을 때 평균, 분산, 자기공분산의 패턴이 있어보인다. 일정 시간 내 구간 통계치(rolling statistics)를 시각화 하는 함수를 사용해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_statistics(timeseries, window=12):\n",
    "    \n",
    "    rolmean = timeseries.rolling(window=window).mean()  # 이동평균 시계열\n",
    "    rolstd = timeseries.rolling(window=window).std()    # 이동표준편차 시계열\n",
    "\n",
    "     # 원본시계열, 이동평균, 이동표준편차를 plot으로 시각화해 본다.\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')    \n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9dbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_statistics(ts1, window=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f64ce",
   "metadata": {},
   "source": [
    "명확하게 안정적 데이터라고 결론을 내리기엔 좀 더 통계적인 접근이 필요해 보인다. 다른 시계열 데이터의 패턴과 비교해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9be3b",
   "metadata": {},
   "source": [
    "### 다른 데이터에 대해서도 비교해보자.   \n",
    "`International airline passengers` 데이터셋이다. 월별 항공 승객 수의 시계열 데이터인데 한번 분석해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filepath = os.getenv('HOME')+'/aiffel/stock_prediction/data/airline-passengers.csv' \n",
    "df = pd.read_csv(dataset_filepath, index_col='Month', parse_dates=True).fillna(0)  \n",
    "print(type(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224cdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = df['Passengers']\n",
    "plt.plot(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b316cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_statistics(ts2, window=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bcd58",
   "metadata": {},
   "source": [
    "시간이 지남에 따라 시계열의 평균과 분산이 지속적으로 커지는 패턴을 보이고 있다. 이런 시계열 데이터는 안정적이지 않다고 정성적인 결론을 내릴 수 있다. 그렇다면 예측을 시도할 수 없는 것일까? 불안정적(non-stationary) 시계열 데이터의 안정성을 평가하는데 정량적인 방법이 있는데 이를 통해 대해 분석을 다뤄보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0ea8d",
   "metadata": {},
   "source": [
    "# 11-5. Stationary 여부를 체크하는 통계적 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce316a0f",
   "metadata": {},
   "source": [
    "### Augmented Dickey-Fuller Test\n",
    "통계적 방법인 ADF Test를 이용해서 시계열 데이터의 안정성을 테스트해보자. `statsmodels` 패키지에서 제공하는 `adfuller` 메서드를 이용할것이다.   \n",
    "1. 주어진 시계열 데이터가 안정적이지 않다라는 Null Hypothesis를 세운다.\n",
    "2. 통계적인 검정 과정을 통해 기각이 되면\n",
    "3. 데이터가 안정적이라는 Alternative Hypothesis를 채택한다.\n",
    "\n",
    "null hypothesis가 기각하는 과정에 p-value(probability value)가 나온다. 가정한 null hypothesis의 확률분포상 현재 관측보다 더 극단적인 관측이 나올 확률로, 해당 가정이 틀렸다고 볼 수 있는 확률이다. 이 값이 0.05 미만으로 낮게 나오면, p-value의 오류 가능성하에 null 가설을 기각하고 alternative 가설을 채택할 수 있는 근거가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925a340",
   "metadata": {},
   "source": [
    "### statsmodels 패키지와 adfuller 메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92cfb2",
   "metadata": {},
   "source": [
    "statsmodels 패키지는 R에서 제공하는 통계 패키지로 통계검정, 시계열분석 등 기능을 파이썬에서 사용할 수 있게 해준다. 아래는 adfuller 메서드를 이용해 timeseries에 대한 ADF test를 수행하는 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce68acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def augmented_dickey_fuller_test(timeseries):\n",
    "    # statsmodels 패키지에서 제공하는 adfuller 메서드를 호출합니다.\n",
    "    dftest = adfuller(timeseries, autolag='AIC')  \n",
    "    \n",
    "    # adfuller 메서드가 리턴한 결과를 정리하여 출력합니다.\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a103e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dickey_fuller_test(ts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73230642",
   "metadata": {},
   "source": [
    "ts1(날씨) 시계열이 안정적이지 않다는 null hypothesis는 p-value가 0에 가깝게 나타났다. 그래서 이 가설은 기각되고, alternative 가설을 채택하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb622f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dickey_fuller_test(ts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603d2f7",
   "metadata": {},
   "source": [
    "ts2(항공사 승객) 시계열은 p-value가 1에 가깝게 나타났다. 그래서 null hypothesis를 기각할 수 없고 이는 안정적인 시계열 데이터가 아니라고 말하는 통계학적 증거가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdc059",
   "metadata": {},
   "source": [
    "# 11-6. Stationary하게 만드는 방법은 없을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2485e",
   "metadata": {},
   "source": [
    "위에서 확인한 불안정한 데이터인 `international airline passengers` 시계열을 분석해보자. 불안정한 데이터를 안정적으로 바꾸기 위해 어떻게 해야할까? 크게 두 가지가 있다.   \n",
    "1. 정성적인 분석을 통해 안정적인 특성을 갖게 데이터를 가공, 변형하기\n",
    "2. 시계열 분해(time series decomposition) 기법 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dda3b5",
   "metadata": {},
   "source": [
    "### stationary한 시계열로 가공하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc49882",
   "metadata": {},
   "source": [
    "__1-1. 로그 함수 변환__   \n",
    "시간 추이에 따라 분산이 점점 커지고 있는점을 활용해 로그함수로 변환을 해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts2)\n",
    "plt.plot(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dickey_fuller_test(ts_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9d58b",
   "metadata": {},
   "source": [
    "p-value가 0.42로 절반 이상 줄었다. 시간 추이에 따른 분산도 일정해졌다. 하지만 가장 큰 문제는 시간이 지나면서 평균이 계속 증가한다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d3497",
   "metadata": {},
   "source": [
    "__1-2. Moving average 제거 - 추세(Trend) 상쇄하기__   \n",
    "시간 추이에 따라 나타나는 평균값 변화를 추세(trend)라고 한다. 이 변화량을 제거하기 위해 거꾸로 moving average를 하는 rolling mean을 구해 ts_log에서 빼주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e26268",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = ts_log.rolling(window=12).mean()  # 이평선의 평균\n",
    "plt.plot(ts_log)\n",
    "plt.plot(moving_avg, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1867c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_moving_avg = ts_log - moving_avg # 변화량 제거\n",
    "ts_log_moving_avg.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181b1c0",
   "metadata": {},
   "source": [
    "전달받는 데이터의 사이즈가 12인 경우 앞의 11개의 데이터는 moving average가 계산되지 않아 결측치가 발생한다. 그래서 이를 제거해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_moving_avg.dropna(inplace=True)\n",
    "ts_log_moving_avg.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_statistics(ts_log_moving_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dickey_fuller_test(ts_log_moving_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429c057",
   "metadata": {},
   "source": [
    "p-value가 0.02정도 나와 stationary한 시계열 데이터가 됐다. 만약 rolling하는 과정에서 window의 값을 다르게 주면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg_6 = ts_log.rolling(window=6).mean()\n",
    "ts_log_moving_avg_6 = ts_log - moving_avg_6\n",
    "ts_log_moving_avg_6.dropna(inplace=True)\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_statistics(ts_log_moving_avg_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316656df",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dickey_fuller_test(ts_log_moving_avg_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d62c9d",
   "metadata": {},
   "source": [
    "p-value가 0.18로 올라 불안정한 데이터가 됐다. 이 데이터셋은 월 단위로 발생하는 시계열이고 12개월 단위로 주기성이 있기 때문에 `window=12`가 적당하다고 추측을 했지만, moving average를 고려할 때 rolling mean을 구하기 위한 window 크기가 매우 중요함을 알 수 있다.   \n",
    "시간이 지나면서 평균이 증가하는 추세를 제거하였으나 안정적인 시계열이라 하기엔 걸리는 부분이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b42b7",
   "metadata": {},
   "source": [
    "__1-3. 차분(differencing) - 계절성(seasonality) 상쇄하기__   \n",
    "trend에는 잡히지 않지만 시계열 데이터 안에 포함된 패턴이 파악되지 않은 주기적 변화는 예측에 방해되는 불안정성 요소이다. 이것은 moving average 제거로는 상쇄되지 않는다. 이런 주기적인 패턴을 계절성이라고 한다. [시계열 패턴](https://otexts.com/fppkr/tspatterns.html)   \n",
    "이런 패턴을 상쇄하는 효과적인 방법으로 차분(differencing)이 있다. 미분(differentiation)과 비슷한 개념인데, 한 스텝 앞으로 시프트한 시계열을 원래 시계열에 빼 주는 방법이다. `현제 스텝 값 - 직전 스텝 값`을 하면 이번 스텝에 발생한 변화량을 볼 수 있다. 이 변화량은 시계열에서 어떤 패턴을 보이게 될까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789c72e",
   "metadata": {},
   "source": [
    "시프트한 시계열과 원본 시계열 그래프로 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac672498",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_moving_avg_shift = ts_log_moving_avg.shift()\n",
    "\n",
    "plt.plot(ts_log_moving_avg, color='blue')\n",
    "plt.plot(ts_log_moving_avg_shift, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961fe87",
   "metadata": {},
   "source": [
    "그리고 원본에서 시프트 시계열을 뺀 값을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b427132",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_moving_avg_diff = ts_log_moving_avg - ts_log_moving_avg_shift\n",
    "ts_log_moving_avg_diff.dropna(inplace=True)\n",
    "plt.plot(ts_log_moving_avg_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b93c5",
   "metadata": {},
   "source": [
    "마지막으로 이동평균, 이동표준편차를 그래프로 나타내어 정성적으로 안성정 여부를 파악해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8508b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_statistics(ts_log_moving_avg_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc202df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dickey_fuller_test(ts_log_moving_avg_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b93be",
   "metadata": {},
   "source": [
    "이동평균을 빼서 추세(trend)를 제거하고 시계열에 1차 차분(1st order differencing)을 적용해 seasonality 효과를 상쇄한 결과 p-value가 0.022에서 0.0019로 1/10 수준으로 줄었다. 데이터에 따라 2차 차분, 3차 차분을 적용하면 더더욱 p-value를 낮출 수 있을지도 모른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f098732",
   "metadata": {},
   "source": [
    "### 시계열 분해(Time series decomposition)   \n",
    "statsmodels 라이브러리 안에 `seasonal_decompose` 메서드를 통해 시계열 안에 존재하는 trend, seasonality를 분리하는 기능이 있다. 이 기능을 통해 moving average 제거, differencing 등 수행해 안정적인 시계열을 분리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ae82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(ts_log)\n",
    "\n",
    "trend = decomposition.trend # 추세(시간 추이에 따라 나타나는 평균값 변화 )\n",
    "seasonal = decomposition.seasonal # 계절성(패턴이 파악되지 않은 주기적 변화)\n",
    "residual = decomposition.resid # 원본(로그변환한) - 추세 - 계절성\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11,6)\n",
    "plt.subplot(411)\n",
    "plt.plot(ts_log, label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cc42f",
   "metadata": {},
   "source": [
    "`Original`에서 `Trend`와 `Seasonality`를 제거하고 난 나머지는 `Residuals`가 된다. 이말은 즉 `Original = Trend + Seasonality + Residuals`이다.   \n",
    "`Residuals`의 안정성 여부를 따져보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (13,6)\n",
    "plot_rolling_statistics(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual.dropna(inplace=True)\n",
    "augmented_dickey_fuller_test(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ac07d",
   "metadata": {},
   "source": [
    "p-value가 가장 낮게 나왔다. 라이브러리를 통해 안정적인 시계열이 얻어졌으니 이런 원리를 통해 예측 모델으 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfeaedd",
   "metadata": {},
   "source": [
    "# 11-7. ARIMA 모델의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef09c5",
   "metadata": {},
   "source": [
    "### 1. ARIMA 모델의 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341a33b",
   "metadata": {},
   "source": [
    "시계열 데이터가 `Trend` + `Seasonality` + `Residuals`로 분해되는 것을 확인했고, `Trend`와 `Seasonality`를 어떻게 분해하냐에 따라 `Residuals`에서 검출된 p-value의 결과값이 달라져 예측력 있는 시계열 데이터가 되는 것을 확인했다.   \n",
    "이 원리를 갖고 ARIMA를 사용해 예측 모델을 만들어보자. ARIMA는 `AR(Autoregressive)` + `I(Integrated)` + `MA(Moving Average)`인데 위에서 배운 개념과 닮아있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7479e4",
   "metadata": {},
   "source": [
    "- __AR(자기회귀, Autogressive)__   \n",
    "과거 값들에 대한 회귀로 미래 값을 예측하는 방법이다. 시계열의 `residual`에 해당하는 부분을 모델링한다고 볼 수 있고, 주식값이 항상 일정한 균형 수준을 유지할 것이라고 예측하는 관점이 AR로 모델링하는 관점이다.   \n",
    "- __MA(이동평균, Moving Average)__   \n",
    "시계열의 `trend` 부분을 모델링한다고 볼 수 있다. 주식값이 최근의 증감 패턴을 지속할것이라고 보는 관점이 MA로 모델링하는 관점이다.   \n",
    "- __I(차분 누적, Integration)__   \n",
    "시계열의 `seasonality`에 해당하는 부분을 모델링한다.   \n",
    "\n",
    "ARIMA는 우리의 태도와 비슷한데, 주식값이 떨어졌을때 올라서 균형을 맞추겠지? 하는 AR 형태의 기대와 떨어졌으니 계속 떨어지겠다 하는 MA 형태의 우려가 동시에 떠오르게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f575fb",
   "metadata": {},
   "source": [
    "### 2. ARIMA 모델의 파라미터 p, q, d   \n",
    "ARIMA 모델에 3가지의 파라미터가 있는데 잘 정해야 올바른 예측을 구할 수 있다.   \n",
    "- p: AR의 시차\n",
    "- d: I 횟수\n",
    "- q: MA의 시차   \n",
    "\n",
    "p와 q는 일반적으로 `p + q < 2`, `P * q = 0`인 값을 사용하는데 둘중 하나는 0이라는 뜻이다. 왜냐하면 많은 시계열 데이터가 AR이나 MA중 하나의 경향만 갖기 때문이다. 그렇다면 이들은 어떻게 결정될까? 대표적으로 ACF(Autocorrelation Function), PACF(Partial Autocorrelation Function)가 있다.   \n",
    "\n",
    "- ACF\n",
    "시차(lag)에 따른 관측치들 사이의 관련성을 측정하는 함수, 주어진 시계열의 현재 값이 과거값과 어떻게 상관되는지 설명한다. ACF의 plot에서 X축은 상관 계수, y축은 시차 수를 나타낸다.\n",
    "- PACF\n",
    "다른 관측치의 영향력을 배제하고 두 시차의 관측치 간 관련성을 측정하는 함수, k 이외의 모든 시차를 갖는 관측치의 영향력을 배제한 가운데 특정 두 관측지, $Y_t$와 $Y_t-k$가 얼마나 관련이 있는지 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "plot_acf(ts_log)   # ACF : Autocorrelation 그래프\n",
    "plot_pacf(ts_log)  # PACF : Partial Autocorrelation 그래프\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a075fd7",
   "metadata": {},
   "source": [
    "International airline passengers 시계열을 예시로 플로팅 기능을 사용한 결과물이다.   \n",
    "ACF로 MA 모델의 시차 q를 결정하고, PACF를 통해 AR 모델의 시차 p를 결정한다. 요약하면 다음과 같다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/E-16-4.max-800x600.png)   \n",
    "PACF에서 p=1이 적합한거같다. 왜냐하면 p가 2이상인 경우에는 PACF는 0에 가까워지고 있기 때문이다. ACF는 점차적으로 감소하여 AR(1) 모델에 유사한 형태를 보인다. q에 적합한 값도 없어 보이고 MA를 고려할 필요가 없음 q=0으로 둘 수 있지만 q를 바꿔가면서 확인하는게 좋아보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차 차분 구하기\n",
    "diff_1 = ts_log.diff(periods=1).iloc[1:]\n",
    "diff_1.plot(title='Difference 1st')\n",
    "\n",
    "augmented_dickey_fuller_test(diff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f88181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 차분 구하기\n",
    "diff_2 = diff_1.diff(periods=1).iloc[1:]\n",
    "diff_2.plot(title='Difference 2nd')\n",
    "\n",
    "augmented_dickey_fuller_test(diff_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8c307",
   "metadata": {},
   "source": [
    "### 3. 학습 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3edd9",
   "metadata": {},
   "source": [
    "9:1 비율로 나눠서 테스트해보자. 시계열 예측이니 가장 마지막 데이터를 테스트용으로 삼았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = ts_log[:int(len(ts_log)*0.9)], ts_log[int(len(ts_log)*0.9):]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.plot(ts_log, c='r', label='training dataset')  # train_data를 적용하면 그래프가 끊어져 보이므로 자연스러운 연출을 위해 ts_log를 선택\n",
    "plt.plot(test_data, c='b', label='test dataset')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_log[:2])\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74cd7e7",
   "metadata": {},
   "source": [
    "# 11-8. ARIMA 모델 훈련과 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #경고 무시\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Build Model\n",
    "model = ARIMA(train_data, order=(14, 1, 0)) # 모수는 이전 그래프를 참고 \n",
    "fitted_m = model.fit() \n",
    "\n",
    "print(fitted_m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6643e6",
   "metadata": {},
   "source": [
    "ARIMA 모델이 훈련한 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d58c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_m = fitted_m.predict()\n",
    "fitted_m = fitted_m.drop(fitted_m.index[0])\n",
    "plt.plot(fitted_m, label='predict')\n",
    "plt.plot(train_data, label='train_data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ce641",
   "metadata": {},
   "source": [
    "forecat() 메소드로 테스트 데이터 구간의 데이터를 예측해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train_data, order=(14, 1, 0))  # p값을 14으로 테스트\n",
    "fitted_m = model.fit() \n",
    "fc= fitted_m.forecast(len(test_data), alpha=0.05)  # 95% conf\n",
    "\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=test_data.index)   # 예측결과\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9,5), dpi=100)\n",
    "plt.plot(train_data, label='training')\n",
    "plt.plot(test_data, c='b', label='actual price')\n",
    "plt.plot(fc_series, c='r',label='predicted price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc787e",
   "metadata": {},
   "source": [
    "시계열 데이터를 로그 변환하여 사용했으므로 np.exp()를 통해 원본으로 돌린 후 MSE, MAE, RMSE, MAPE를 계산하고 결과를 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a65c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(np.exp(test_data), np.exp(fc))\n",
    "print('MSE: ', mse)\n",
    "\n",
    "mae = mean_absolute_error(np.exp(test_data), np.exp(fc))\n",
    "print('MAE: ', mae)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(np.exp(test_data), np.exp(fc)))\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "mape = np.mean(np.abs(np.exp(fc) - np.exp(test_data))/np.abs(np.exp(test_data)))\n",
    "print('MAPE: {:.2f}%'.format(mape*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97204cd1",
   "metadata": {},
   "source": [
    "예측 모델의 메트릭으로 활용하기에 적당한 MAPE 기준 10%의 오차율을 보인다. p=14를 줄 경우 2%로 내려간다. 다양한 테스트를 통해 최적화된 모델을 만들어보자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
