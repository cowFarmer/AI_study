{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6435a976",
   "metadata": {},
   "source": [
    "# 한국어 대화형 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce2971",
   "metadata": {},
   "source": [
    "# 1. 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2beeef5",
   "metadata": {},
   "source": [
    "한국어 챗봇 데이터는 송영숙님이 공개한 데이터를 사용해보자. [songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)   \n",
    "```\n",
    "$ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "$ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511100ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b7a1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>쌍커풀 해볼까</td>\n",
       "      <td>눈은 기본이죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>쳇바퀴 도는 하루</td>\n",
       "      <td>그 속에서 가치와 의미를 찾아보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>사는 게 허무해요</td>\n",
       "      <td>뜻대로 되는게 많지 않죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>베터리 15%야</td>\n",
       "      <td>미리 충전하세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7416</th>\n",
       "      <td>이별 괜찮타.</td>\n",
       "      <td>그렇게 생각하다 보면 정말 괜찮아질 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>자꾸 나약하게 느껴져</td>\n",
       "      <td>절대 그렇지 않아요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>군대 기다리면 부담스러워할까</td>\n",
       "      <td>너무 걱정하지 마세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>스킨십 언제부터 할까?</td>\n",
       "      <td>두 사람이 준비가 되었을 때요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>모르는 번호로 전화왔어</td>\n",
       "      <td>받지마세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>짝사랑 하는 사람이 날 좋아할리는 없겠지?</td>\n",
       "      <td>나를 비하하지 마세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "2816                   쌍커풀 해볼까                  눈은 기본이죠.      0\n",
       "4496                 쳇바퀴 도는 하루      그 속에서 가치와 의미를 찾아보세요.      0\n",
       "2259                 사는 게 허무해요            뜻대로 되는게 많지 않죠.      0\n",
       "2059                  베터리 15%야                 미리 충전하세요.      0\n",
       "7416                   이별 괜찮타.  그렇게 생각하다 보면 정말 괜찮아질 거예요.      1\n",
       "3901               자꾸 나약하게 느껴져               절대 그렇지 않아요.      0\n",
       "289            군대 기다리면 부담스러워할까              너무 걱정하지 마세요.      0\n",
       "10102             스킨십 언제부터 할까?         두 사람이 준비가 되었을 때요.      2\n",
       "1705              모르는 번호로 전화왔어                    받지마세요.      0\n",
       "11583  짝사랑 하는 사람이 날 좋아할리는 없겠지?              나를 비하하지 마세요.      2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('~/aiffel/transformer_chatbot/data/ChatbotData .csv')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318fd28",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb79d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n",
      "11662\n",
      "7779\n",
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data['Q'].nunique())\n",
    "print(data['A'].nunique())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4aba40",
   "metadata": {},
   "source": [
    "> 데이터셋의 중복 데이터는 제거하면 안될거 같다. 이는 비슷한 유형의 대답이 있을때 똑같은 대답을 많이 함을 유추할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fd569",
   "metadata": {},
   "source": [
    "### 데이터 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a86693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점 사이에 space를 만든다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # (a-z, A-Z, 가-힣, \"?\", \".\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체한다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣?.!,]+\", \" \", sentence)\n",
    "  \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937c4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations():\n",
    "    inputs, outputs = [], []\n",
    "    for i in data['Q']:\n",
    "        inputs.append(preprocess_sentence(i))\n",
    "    for i in data['A']:\n",
    "        outputs.append(preprocess_sentence(i))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06654488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7211a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e387ca1",
   "metadata": {},
   "source": [
    "# 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bacab",
   "metadata": {},
   "source": [
    "### 단어장 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a336ad",
   "metadata": {},
   "source": [
    "__SubwordTextEncoder__를 사용해서 단어장(Vocabulary) 만들기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d5ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8382424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 정수를 부여한다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf9bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8139]\n",
      "END_TOKEN의 번호 : [8140]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4437d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8141\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 단어장의 크기를 +2 한다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb1015b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5746, 611, 2485, 4152]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2353, 7490, 7, 6255, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 토큰을 고유한 정수로 변환하는 인코딩 작업\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b2220",
   "metadata": {},
   "source": [
    "### 패딩, 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f006af2",
   "metadata": {},
   "source": [
    "패딩 작업을 진행하기 전에 문장의 최대 길이를 정해야한다. 데이터의 분포를 시각적으로 확인하고 정하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc48067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna = questions + answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f7aee8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소 길이 : 1\n",
      "최대 길이 : 24\n",
      "평균 길이 : 4.3276241224731455\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qna_len = [len(s.split()) for s in qna]\n",
    "\n",
    "print('최소 길이 : {}'.format(np.min(qna_len)))\n",
    "print('최대 길이 : {}'.format(np.max(qna_len)))\n",
    "print('평균 길이 : {}'.format(np.mean(qna_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(qna_len)\n",
    "plt.title('QnA')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('QnA')\n",
    "plt.hist(qna_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b3ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 문장의 최대 길이 정하기\n",
    "MAX_LENGTH = 12\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0958e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a052795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 12 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # 최대 길이 12으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "840fb4f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8141\n",
      "필터링 후의 질문 샘플 개수: 10747\n",
      "필터링 후의 답변 샘플 개수: 10747\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4987888",
   "metadata": {},
   "source": [
    "전체 샘플 수 : 11823 -> 필터링 후의 질문 샘플 개수: 10747"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d266acb",
   "metadata": {},
   "source": [
    "### Teacher Forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f704d769",
   "metadata": {},
   "source": [
    "__tf.data.Dataset API__ 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API를 사용한다. 질문과 답변의 쌍을 입력으로 넣어주는데, 디코더의 입력과 실제 값을 정의해주기 위해 teacher forcing을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8e02dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용한다.\n",
    "# 그래서 outputs의 START_TOKEN을 제거한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc486d9",
   "metadata": {},
   "source": [
    "# 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf226f9",
   "metadata": {},
   "source": [
    "### Transformer 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff4cd4",
   "metadata": {},
   "source": [
    "입력 위치 정보를 갖고 있는 __positinal encoding layer__ 선언하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be595c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda482e",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a16146",
   "metadata": {},
   "source": [
    "단어들의 유사도를 구하기 위해 __scaled dot product attention__ 선언하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dea0c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5748c828",
   "metadata": {},
   "source": [
    "병렬로 어텐션을 수행하기 위해 __멀티 헤드 어텐션__ 선언하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc779709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용한다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만든다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)한다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용한다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a6a4a",
   "metadata": {},
   "source": [
    "### 마스킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98586eaf",
   "metadata": {},
   "source": [
    "패딩을 마스킹 처리해주는 __padding masking__ 그리고 트랜스포머의 특성상 문장을 불러오는데 RNN 구조로 단어를 학습하는 __look ahead masking__ 선언하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "235a58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa1a8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9cca9",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc5f1d",
   "metadata": {},
   "source": [
    "인코더 층은 2개의 sublayer로 나누어져 있다. __self attention__, __feed forward__.   \n",
    "\n",
    "self attention은 `multiheadattention()`으로 병렬적으로 이루어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ac96e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 레이어 : 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행한다.\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행한다.\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd7e4f",
   "metadata": {},
   "source": [
    "위에서 선언한 encoder_layer를 __embedding layer__, __positional encoding__을 연결하고, 인코더 층(num_layers)을 쌓으면 트랜스포머의 인코더가 완성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56327b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43614e9b",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605cb3c2",
   "metadata": {},
   "source": [
    "__self attention__, __encoder-decoder attention__의 __scaled dot product attention__ 처리를 `MultiHeadAttention()`으로 병렬적으로 이루어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c4f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재한다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e858de",
   "metadata": {},
   "source": [
    "인코더 층과 동일하게 __embedding layer__, __positional encoding__을 연결하고, 인코더 층(num_layers)을 쌓으면 트랜스포머의 디코더가 완성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f82c41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f376a4",
   "metadata": {},
   "source": [
    "### transformer로 앞서 선언한 함수들 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15fd6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용한다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f8f62",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81ff0d",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "618f14e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3138304     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3665664     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8141)   2092237     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,896,205\n",
      "Trainable params: 8,896,205\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수, 논문은 6\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원, 논문은 512\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a3ac6",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5ecfdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe1763",
   "metadata": {},
   "source": [
    "### custom Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ca71f",
   "metadata": {},
   "source": [
    "학습 초기에 learning rate를 높였다가 train step이 진행되면서 낮추는 __custom learning rate scheduling__을 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5cf96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dfa9986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111650aa",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d4bb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc0081",
   "metadata": {},
   "source": [
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b219fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "168/168 [==============================] - 11s 30ms/step - loss: 4.8373 - accuracy: 0.0695\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 3.9629 - accuracy: 0.1663\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 3.3228 - accuracy: 0.1783\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 3.0381 - accuracy: 0.1879\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 2.8501 - accuracy: 0.1984\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 2.6670 - accuracy: 0.2104\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 2.4671 - accuracy: 0.2294\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 2.2474 - accuracy: 0.2525\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 2.0065 - accuracy: 0.2790\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 1.7514 - accuracy: 0.3089\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 1.4887 - accuracy: 0.3411\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 1.2300 - accuracy: 0.3745\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.9814 - accuracy: 0.4103\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.7570 - accuracy: 0.4444\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.5681 - accuracy: 0.4753\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.4124 - accuracy: 0.5023\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.2953 - accuracy: 0.5249\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.2153 - accuracy: 0.5376\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.1661 - accuracy: 0.5465\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.1392 - accuracy: 0.5509\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.1244 - accuracy: 0.5530\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.1170 - accuracy: 0.5541\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.1110 - accuracy: 0.5543\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.1099 - accuracy: 0.5538\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.1001 - accuracy: 0.5569\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0886 - accuracy: 0.5589\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0778 - accuracy: 0.5618\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.0682 - accuracy: 0.5643\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0643 - accuracy: 0.5653\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0588 - accuracy: 0.5666\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0527 - accuracy: 0.5683\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0502 - accuracy: 0.5686\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0433 - accuracy: 0.5702\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0413 - accuracy: 0.5711\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0404 - accuracy: 0.5714\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0364 - accuracy: 0.5722\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0330 - accuracy: 0.5732\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0328 - accuracy: 0.5733\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0316 - accuracy: 0.5735\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0296 - accuracy: 0.5738\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0270 - accuracy: 0.5745\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0275 - accuracy: 0.5745\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0249 - accuracy: 0.5750\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0247 - accuracy: 0.5754\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0230 - accuracy: 0.5755\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0226 - accuracy: 0.5757\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0222 - accuracy: 0.5758\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0206 - accuracy: 0.5762\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0183 - accuracy: 0.5764\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.0192 - accuracy: 0.5766\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "es = EarlyStopping(monitor='accuracy', patience=2, verbose=1)\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03150f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb49455",
   "metadata": {},
   "source": [
    "# 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9168880",
   "metadata": {},
   "source": [
    "모델을 평가하기 위해 주어진 문장을 보고 예측을 하게 되는데 다음과 같은 과정을 거친다.   \n",
    "- 입력된 문장을 전처리를 거쳐 정수로 바꾸고 시작 토큰과 종료 토큰을 추가한다.\n",
    "- 마스킹을 계산한다.\n",
    "- 디코더는 입력 시퀀스를 받으면 다음 단어를 예측한다.\n",
    "- 예측한 단어를 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "- `END_TOKEN`이 나오거나 최대 길이에 도달하면 멈춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38e5b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 토큰 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 예측한 출력 시퀀스를 저장하는 변수, 초기 값은 시작 토큰으로 저장\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 종료 토큰이 나오면 반복문 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들을 output_sequence에 추가하고 추가된 단어들은 다시 디코더의 입력으로 할당\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e3d6e",
   "metadata": {},
   "source": [
    "`decoder_inference()`를 받아 대답을 얻는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2e8b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a75b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕하세요?\n",
      "출력 : 안녕하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('안녕하세요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "763a756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너도 감정이 있을까?\n",
      "출력 : 가만히 있어도 생각나는 거 아닐까요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'가만히 있어도 생각나는 거 아닐까요 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너도 감정이 있을까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98912893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 삶이란 무엇일까?\n",
      "출력 : 지칠 때는 쉬어도 돼요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'지칠 때는 쉬어도 돼요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('삶이란 무엇일까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64f35eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 취업할 수 있을까?\n",
      "출력 : 간절한 만큼 할 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'간절한 만큼 할 수 있을 거예요 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('취업할 수 있을까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b72c7301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 저녁 먹을 시간이야\n",
      "출력 : 맛 있는거 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛 있는거 드세요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('저녁 먹을 시간이야')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "621d34b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 헤어스타일 좀 바꿔볼까?\n",
      "출력 : 기분 전환해보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'기분 전환해보세요 .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('헤어스타일 좀 바꿔볼까?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db88c96",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee10fb",
   "metadata": {},
   "source": [
    "- ~~패딩하는 과정에서 max_lenth를 짧게 정해주면 데이터셋이 없어지는 문제가 생겼다.~~ __해결했다.__    \n",
    "for문 안에 if문을 써야하는데 코드를 수정하면서 for문 밖에 선언하면서 생긴 버그였다. __버그찾기 어렵다!__\n",
    "- 그 전까지는 모델을 조금만 수정해도 결과물이 크게 바뀌어 수정을 팍팍 할 수 있었는데, 이번에 진행하면서 잘 짜여진 모델을 수정하려니 손을 대기 어려웠다. 데이터셋이 적은 척박한 환경이었는데, 결과물을 보면 추상적인 얘기도 잘 받아주고 있다. 수정한 부분은 딱히 없고 한국어 전처리와 train 단계에서 accuracy가 계속 늘어나는 추세를 보고 epoch를 50으로 잡았다. \n",
    "- 똑같은 코드를 갖고 데이터를 새롭게 학습할때마다 `accuracy`가 가끔 튈 때가 있다. 그래서 `earlystopping`이 epoch 50을 다 안돌고 멈춰 있을 때가 있다. 왜 이럴까?\n",
    "- 데이터셋의 padding을 추가하는 과정에서 `pre`로 앞 부분에 dummy data를 넣도록 추가했다. 하지만 결과물을 봤을때 뒷부분이 2번씩 나와서 다시 `post`로 바꿨다. transformer는 다른 NLP와 다르게 dummy 데이터를 앞에 추가하면 흐름이 이상해질까? 아니면 다른 버그때문에 생긴걸까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621a8fd",
   "metadata": {},
   "source": [
    "# 후기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107f1de",
   "metadata": {},
   "source": [
    "transformer 모델이 갖고 있는 데이터 튜닝하는 방법을 이해하려고 시간을 많이 소비했다. cs231n lecture 10을 스터디하면서 NLP 부분에 대한 이해도가 많이 늘었다고 생각했는데, 아직도 갈길이 멀다. 그래도 하나하나 배워가는게 재미있다.   \n",
    "그 전까지는 NLP는 NLP만의 기술을 쓰고, CV는 CV만의 기술을 독자적으로 써서 서로 연관이 없을거라고 생각 했는데, cs231n과 익스 12번을 진행하면서 생각이 바뀌었다. 원하는 결과물에 따라 디테일한 부분은 다르지만 데이터의 흐름을 가져갈 때 비슷한 부분이 많이 있다. 예를들어서 저번 익스에 시계열을 통해 주식 가격을 예측하는 프로젝트를 진행했다. 이를 CV에서 응용해 시계열을 통해 image의 변화를 감지하는 방향으로 사용할 수 있다고 생각했다.   \n",
    "위에서 말한거처럼 transformer를 NLP에서만 쓰는게 아닌 CV에서도 사용할 수 있을거라고 생각했다. 그래서 예시를 찾다가 정리가 잘 되어있는 깃허브를 발견했는데, 다양한 연구가 활발하게 이루어지고 있음을 확인했다. 한쪽만 깊게 공부해야지 라는 생각보다 모델을 구축하고 데이터를 다루는 다양한 방법에 폭넓은 지식을 갖고있는게 중요하다고 느꼈다.   \n",
    "깃허브 링크는 여기를 참고하자. __[Awesome-tranformer-in-CV](https://github.com/Yutong-Zhou-cv/Awesome-Transformer-in-CV)__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
