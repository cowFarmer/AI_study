{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5585f943",
   "metadata": {},
   "source": [
    "# 대화형 챗봇이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73861ef6",
   "metadata": {},
   "source": [
    "인공지능을 생각할 때 인간의 언어를 이해하고 서로 소통할 수 있는 기계를 자연스럽게 떠올리곤 한다. 그리고 우리 주변에서 볼 수 있는 챗봇은 모두 대화형이 아니다. [챗봇의 5가지 유형](https://tonyaround.com/%ec%b1%97%eb%b4%87-%ea%b8%b0%ed%9a%8d-%eb%8b%a8%ea%b3%84-%ec%b1%97%eb%b4%87%ec%9d%98-5%ea%b0%80%ec%a7%80-%eb%8c%80%ed%91%9c-%ec%9c%a0%ed%98%95-%ec%a2%85%eb%a5%98/)을 보면 대화형, 트리형, 추천형, 시나리오형, 이들을 결합한 결합형 챗봇이 있다. 대화형 챗봇이 아니라면 한계는 명확하게 있다. 진정한 팻봇이면 사용자가 어떤 말을 하더라도 알아듣고 적절하게 대응할 수 있는 자유도가 있어야 하기 때문이다. 그래서 딥러닝을 통한 자연어처리 기술이 가능성을 보여주자, 사람들은 대화형 챗봇이 가져올 변화에 기대감을 가지기 시작했다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08cf0b",
   "metadata": {},
   "source": [
    "__챗봇과 딥러닝__   \n",
    "하지만 우리 주변에 있는 챗봇은 스마트하지 않다. 왜일까? [챗봇 역사의 모든 것](https://blog.performars.com/ko/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EC%B1%97%EB%B4%87chatbot-%EC%B1%97%EB%B4%87-%EC%97%AD%EC%82%AC%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B2%83)을 확인해보면 챗봇의 발전 흐름을 볼 수 있다.   \n",
    "초창기 챗봇에 대한 기대, 한계점을 느낀 후 최근 ALBERT, BERT, ULMFiT, Transformer-XL 등 tansformer 모델을 활용해 pretrain을 적용한 NLP 모델들이 각광을 받고 있다.   \n",
    "\n",
    "트랜스포머 모델을 기반으로 인코더-디코더 구조를 바탕으로 챗봇을 제작해보자. 물론 좋은 성능을 내기 위해 수많은 코퍼스로 pretrained model을 활용하는게 필요하지만 오늘은 모델의 기본 구조를 알아보는데 초점을 맞추고 알아보자.   \n",
    "\n",
    "```\n",
    "$ mkdir -p ~/aiffel/songys_chatbot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb33a0",
   "metadata": {},
   "source": [
    "# 12-2. 트랜스포머와 인코더 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea01f17",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_UcFQAjh.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1a6c6",
   "metadata": {},
   "source": [
    "번역기는 인코더와 디코더 두 가지 아키텍처로 구성되어있다. 인코더에 입력문장, 디코더에 출력문장. 이를 훈련하는것은 입력, 출력 두 가지 병렬 구조로 구성된 데이터셋을 훈련한다는 의미다. 이러한 구조는 번역기가 아닌 주어진 질문에 답변할 수 있는 챗봇으로 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90188222",
   "metadata": {},
   "source": [
    "트랜스포머도 입력 문장을 넣으면 출력 문장을 내뱉는 인코더와 디코더 구성을 갖고 있다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_2_EnQyi4S.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bd8d6",
   "metadata": {},
   "source": [
    "초록색이 encoder layer, 핑크색이 decoder layer인데 입력 문장은 누적된 인코더의 층을 통해 정보를 뽑아내고 디코더는 누적된 디코더 층을 통해 출력 문장의 단어를 하나씩 만들어 가는 구조를 갖고 있다. 이 과정을 더 확대하면 다음과 같다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_3_ddZedfW.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb06ec",
   "metadata": {},
   "source": [
    "# 12-3. 트랜스포머의 입력 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbc303",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_4_fuzN6PD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23e7ec",
   "metadata": {},
   "source": [
    "많은 자연어 처리 모델들은 텍스트 문장을 입력으로 받기 위해 단어를 임베딩 벡터로 변환하는 벡터화 과정을 거친다. 트랜스포머 또한 그 점에서는 다른 모델들과 다르지 않다. 하지만 트랜스포머 모델의 입력 데이터 처리는 RNN 계열의 모델들과 달리 임베딩 벡터에 어떤 값을 더해준 뒤 입력으로 사용한다.위 그림의 Positional Encoding에 해당하는 부분이다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_5_kH52kQN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe42285",
   "metadata": {},
   "source": [
    "이렇게 하는 이유는 입력 받을 때 문장에 있는 단어들을 1개씩 순차적으로 받는게 아니라 모든 단어를 한꺼번에 입력으로 받기 때문이다. 트랜스포머와 RNN의 결정적인 차이점이 이 부분이다. RNN은 문장을 구성하는 단어들이 어순대로 모델에 입력되어 어순 정보를 알려줄 필요가 없었는데, 같은 단어라도 어순에 따라 의도하는 정보가 달라질 수 있음을 유의하여 위치를 알려주는 벡터값을 더해 모델의 입력으로 삼는다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_6_DyxB6Ax.png)   \n",
    "$d_{model}$은 임베딩 벡터의 차원을 의미하고, $pos$는 입력 문장에서 입베딩 벡터의 위치를 나타내며, $i$는 임베딩 벡터 내의 차원의 인덱스를 의미한다. 임베딩 행렬과 포지셔널 행렬이라는 두 행렬을 더함으로써 각 단어 벡터에 위치 정보를 더해주게 된다.   \n",
    "포지셔널 행렬을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355ed0a7",
   "metadata": {},
   "source": [
    "행의 크기가 50, 열의 크기가 512인 행렬을 그렸다. 이는 최대 문장의 길이가 50, 임베딩 차원을 512로 하는 모델의 입력 벡터 모양과 같다. 실제 논문에서는 다음과 같이 그림으로 표현하고 있다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_9_l58gVWT.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c0c0d",
   "metadata": {},
   "source": [
    "# 12-4. 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150e484",
   "metadata": {},
   "source": [
    "어텐션 메커니즘을 그림으로 표현하면 다음과 같다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_10_AaCfqrY.png)   \n",
    "주어진 query에 대해 모든 key와의 유사도를 각각 구한다. 그리고 구한 유사도를 key와 맵핑되어있는 각각의 값에 반여애준다. 그리고 유사도가 반영된 값을 모두 더해서 뭉쳐주면 어텐션 값이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e15273",
   "metadata": {},
   "source": [
    "트랜스포머는 세 가지의 어텐션을 사용한다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_11_tFFhFjx.png)   \n",
    "- 인코더 셀프 어텐션은 인코더에서 인코더의 입력으로 들어간 문장 내 단어들이 서로 유사도를 구한다.\n",
    "- 디코더 셀프 어텐션은 디코더에서 단어 1개씩 생성하는 디코더가 이미 생성된 앞 단어들과 유사도를 구한다.\n",
    "- 인코더-디코더 어텐션은 디코더에서 잘 예측하기 위해 인코더에 입력된 단어들과 유사도를 구한다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_12_SIe2V15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59162500",
   "metadata": {},
   "source": [
    "트랜스포머 어텐션 함수에 사용되는 query, key, value는 기본적으로 정보를 함축한 단어 벡터이다. 여기서 단어 벡터란 초기 입력으로 사용된 임베딩 벡터가 아닌, 트랜스포머의 여러 연산을 거친 단어 벡터이다. 어텐션중 두개가 셀프 어텐션인데 이의 의미를 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a8641",
   "metadata": {},
   "source": [
    "셀프 어텐션은 유사도를 구하는 대상이 다른 문장의 단어가 아닌 현재 문장 내의 단어들을 말한다. 위에서 말한 인코더-디코더 어텐션은 서로 다른 단어 목록 사이에서 유사도를 구한다.   \n",
    "우리는 이것, 저것에 대한 의미를 문장에 있는 단어들로 통해 쉽게 유추한다. 하지만 기계는 그렇지 않다. 그러므로 셀프 어텐션을 통해 유사도를 구하고 이를 통해 무엇과 연관되어 있는지 확률을 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14811064",
   "metadata": {},
   "source": [
    "# scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda11dc",
   "metadata": {},
   "source": [
    "어텐션이 단어들간 유사도를 구하는 메커니즘인데 유사도를 어떻게 구할까?   \n",
    "$Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$   \n",
    "$Q,K,V$는 순서대로 query, key, value를 말한다. 어텐션 함수는 query에 대한 모든 key의 유사도를 각각 구한다. 그리고 구한 유사도를 키와 맵핑된 각각의 값에 반영한다. 그리고 유사도가 반영된 값을 모두 더해주면 최종적으로 어텐션 값이 나온다.   \n",
    "1. Q, K, V는 단어 벡터를 행으로 하는 문장 행렬이다.\n",
    "2. 백터의 내적(dot product)은 벡터의 유사도를 의미한다.\n",
    "3. 특정 값을 분모로 사용하는 것은 값의 크기를 조절하는 스케일링을 위함이다.   \n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_15_pUfIgKn.png)\n",
    "문장 행렬 $Q$, 문장 행렬 $K$를 곱하면 초록색 행렬을 얻을 수 있다. 초록생 행렬은 각 단어 벡터의 유사도(내적값)가 모두 기록된 유사도 행렬을 의미한다.   \n",
    "이 유사도 값을 스케일링 해주기 위해 행렬 전체를 특정 값으로 나누고, 유사도를 0과 1사이의 값으로 normalize하기 위해 softmax 함수를 사용한다. 여기에 문장 행렬 $V$와 곱하면 어텐션 값을 얻게 된다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_16_neA52rZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e0e25a",
   "metadata": {},
   "source": [
    "정리하자면 내적(dot product)를 통해 단어 벡터간 유사도를 구한 후 특정 값을 분모로 나눠주는 방식을 통해 Q, K의 유사도를 구하여 __Scaled Dot Product Attention__ 이라고 한다. 분모에 특정 값을 나눠주지 않았다면 dot product attention이라고 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d4261",
   "metadata": {},
   "source": [
    "# 12-6. 병렬로 어텐션 수행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797c1c8",
   "metadata": {},
   "source": [
    "트랜스포머의 `num_heads`라는 하이퍼파라미터 변수는 병렬적으로 몇 개의 어텐션 연산을 수행할지 결정한다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_18_nnOTx9p.png)   \n",
    "트랜스포머의 초기 입력인 문장 행렬의 크기는 문장의 길이를 행으로, `d_model`은 열의 크기로 갖게 된다. 이렇게 입력된 문장 행렬을 `num_heads`의 수만큼 쪼개서 어텐션을 수행하고, 이렇게 얻은 `num_heads`의 개수만큼 어텐션 값 행렬을 하나로 concatenate한다. 위 그림은 `num_heads`가 8개인 경우인데 concatenate 하면서 열의 크기가 `d_model`이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563acef6",
   "metadata": {},
   "source": [
    "### 멀티-헤드 어텐션\n",
    "\n",
    "병렬로 어텐션을 수행하면 어떤 효과를 얻을 수 있을까?   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_19_FwmaA3q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6202fb",
   "metadata": {},
   "source": [
    "위 그림은 `num_heads` 값이 8일 때, 병렬로 수행되는 어텐션이 서로 다른 셀프 어텐션 결과를 보여준다. 이렇게 어텐션을 병렬로 수행하는 것을 멀티 헤드 어텐션이라고 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위해 여러 개 만든다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1cde9",
   "metadata": {},
   "source": [
    "# 12-7. 마스킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff587d7",
   "metadata": {},
   "source": [
    "특정 값들을 가려 실제 연산에 방해 되지 않도록 하는 것을 마스킹이라고 부른다. 트랜스포머에서는 어텐션을 위해 크게 두 가지 padding masking, look-ahead masking을 사용한다.   \n",
    "\n",
    "__Padding Masking__   \n",
    "패딩 토큰을 이용한 마스킹 방법이다. 자연어 처리에서 패딩은 문장의 길이가 서로 다를 때 문장의 길이를 동일하게 해주는 과정에서 짧은 문장에 숫자 0을 채워 길이를 맞춰주는 전처리 방법이다. 주어진 숫자 0은 실제 의미가 있는 단어는 아니여서 실제 어텐션과 같은 연산에서 제외할 필요가 있다. 패딩 마스킹은 숫자 0의 위치를 체크한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71965949",
   "metadata": {},
   "source": [
    "숫자가 0인 부분을 체크한 벡터를 리턴한다. 결과를 보면 두 정수 시퀀스에 대해 결과가 출력되는데, 숫자 0인 위치에서만 1이 나오고 아닌 위치에서는 0 벡터를 출력한다. 어텐션 연산할 때 패딩 마스킹을 참고하면 숫자 0을 참고하지 않게 할 수 있다.   \n",
    "\n",
    "__Look-ahead masking__   \n",
    "순환 신경망, RNN과 트랜스포머는 문장을 입력받을 때 입력받는 방법이 전혀 다르다. RNN은 step의 개념으로 각 step마다 단어 순서대로 입력받는 구조인데 트랜스포머는 문장 행렬을 만들어 한번에 입력받는 구조이다. 그래서 이 특징 때문에 masking이 필요하다.   \n",
    "자신보다 다음에 나올 단어를 참고하지 않도록 가리는 기법이 look ahead masking 기법이다. Query 단어 뒤에 나오는 Key 단어들에 마스킹 한다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/_.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0046a",
   "metadata": {},
   "source": [
    "행을 Query 열을 Key로 표현된 행렬이고 빨간색으로 색칠된 부분이 마스킹이다. 실제 어텐션 연산에서 가리는 역할을 하고 어텐션 연산 시에 현재 단어를 기준으로 이전 단어들과 유사도를 구할 수 있다.   \n",
    "\n",
    "예를들어 Query 단어가 '찾고'이면 여기 있는데 행에 `<s>, <나는>, <행복을>, <찾고>`를 갖고있고 뒤에는 마스킹이 되어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d697390",
   "metadata": {},
   "source": [
    "마스킹과 패딩 마스킹은 별개이므로 숫자 0인 단어가 있으면 패딩을 해야한다. 다음과 같이 적용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84bd3e",
   "metadata": {},
   "source": [
    "# 12-8. 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4da11",
   "metadata": {},
   "source": [
    "트랜스포머의 인코더 층은 셀프 어텐션과 피드포워드 신경망 총 2개의 sublayer로 구성되어 있다. 셀프 어텐션 레이어는 멀티 헤드 어텐션으로 병렬적으로 이루어져있다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_21_Y7Cy8sm.max-800x600.png)   \n",
    "\n",
    "두 개의 서브 층을 가지는 하나의 인코더 층을 구현하는 함수를 살펴보자. 함수 내부적으로 첫 번쨰 서브 층과 두 번째 서브 층을 구현하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf209374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재한다\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b98186",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_22_teJgoCi.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc66da",
   "metadata": {},
   "source": [
    "이렇게 구현한 인코더 층을 임베딩 층과 포지서녕 인코딩을 연결하고, 사용자가 원하는 만큼 인코더 층을 쌓으면 트랜스포머의 인코더가 완성된다.   \n",
    "인코더와 디코더 내부에는 서브층 이후 훈련을 돕는 layer normalization이 사용됐다. 위 그림에서 normalize에 해당하는 부분이다.   \n",
    "트랜스포머는 num_layers 개수의 인코더 층을 쌓는다. 논문에서는 6개의 인코더 층을 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ab691",
   "metadata": {},
   "source": [
    "# 12-9. 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8154a",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_23_vBHZ3i0.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1af91",
   "metadata": {},
   "source": [
    "디코더의 세 개의 서브 층으로 구성되어 있다. 첫 번쨰는 셀프 어텐션, 두 번째는 인코더-디코더 어텐션, 세 번째는 피드 포워드 신경망이다. 인코더-디코더 어텐션은 Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터다. 이 부분이 인코더가 입력 문장으로부터 정보를 디코더에 전달하는 과정이다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_24_Kj9egLY.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd935084",
   "metadata": {},
   "source": [
    "인코더의 셀프 어텐션와 마찬가지로 디코더의 셀프 어텐션, 인코더-디코더 어텐션 두 개의 어텐션 모두 scaled dot product attention을 multi head attention으로 병렬적으로 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334324e",
   "metadata": {},
   "source": [
    "### 디코더 층을 쌓아 디코더 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7078d",
   "metadata": {},
   "source": [
    "위처럼 구현한 디코더 층은 임베딩 층과 포지셔널 인코딩을 연결하고, 사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성된다. 인코더와 동일하게 `num_layers` 개수의 디코터 층을 쌓는다. 논문에서는 6개의 디코더 층을 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b8e02",
   "metadata": {},
   "source": [
    "# 12-10. 챗봇의 병렬 데이터 받아오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51d87c",
   "metadata": {},
   "source": [
    "__Cornell Movie-Dialogs Corpus__ 라는 영화 및 TV 프로그램에서 사용된 대화의 쌍을 데이터셋으로 사용한다. 기본적으로 먼저 말하는 사람의 대화 문장이 있고, 그에 응답하는 대화 문장의 쌍으로 이루어져있다.   \n",
    "데이터를 받아올 때 다음과 같은 전처리를 해주자.   \n",
    "- 정해진 50,000개의 질문과 답변의 쌍을 추출한다. \n",
    "- 문장에서 단어와 구두점 사이에 공백을 추가한다. \n",
    "- 알파벳과 !, ?, ,, . 총 4개의 구두점을 제외하고 다른 특수문자는 제거한다.   \n",
    "\n",
    "데이터를 불러와보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b092987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885d6a3",
   "metadata": {},
   "source": [
    "전처리를 위한 함수를 선언해보자. 정규 표현식을 사용하여 구두점을 제거하여 단어 토크나이징에 방해가 되지 않도록 정제하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152bd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "  id2line = {}\n",
    "  with open(path_to_movie_lines, errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    id2line[parts[0]] = parts[4]\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(path_to_movie_conversations, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(conversation) - 1):\n",
    "      # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "      if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장한다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31fd21",
   "metadata": {},
   "source": [
    "# 12-11. 병렬 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e7080",
   "metadata": {},
   "source": [
    "전처리 과정을 요약하면 다음과 같다.   \n",
    "- TensorFlow Datasets SubwordTextEncoder를 토크나이저로 사용하자. 단어보다 작은 단위인 Subword를 기준으로 토크나이징하고, 각 토큰을 고유한 정수로 인코딩한다. \n",
    "- 각 문장을 토큰화하고 시작과 끝에 `START_TOKEN`, `END_TOKEN`을 추가한다. \n",
    "- 최대 길이 MAX_LENGTH 40을 넘으면 필터링한다.\n",
    "- MAX_LENGTH보다 길이가 짧으면 40에 맞도록 패딩한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6762e4",
   "metadata": {},
   "source": [
    "### 1. 단어장 만들기   \n",
    "각 단어에 고유한 정수 인덱스를 부여하기 위해 단어장을 만들자. 질문과 답변 데이터셋 모두 사용하자. 시작 토큰과 종료 토큰도 단어장에 추가해서 정수를 부여하자. 각각 단어장의 크기보다 +1된 큰 수를 부여해 적용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53da665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여한다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f735df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87079342",
   "metadata": {},
   "source": [
    "### 2. 각 단어를 고유한 정수로 인코딩, 패딩하기   \n",
    "`tokenizer.encode()`로 단어를 정수로 변환할 수 있고 `tokenizer.decode()`로 정수 시퀀스를 단어 시퀀스로 변환할 수 있다. MAX_LENGTH가 40이 넘는 애들은 필터링해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94cd027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a09074",
   "metadata": {},
   "source": [
    "### 3. 교사 강요(Teacher Forcing) 사용하기   \n",
    "tf.data.Dataset API는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API이다. 이를 사용하기 위해 질문과 답변의 쌍을 `tf.data.Dataset`의 입력으로 넣어주는 작업을 한다.   \n",
    "디코더의 입력과 실제값(레이블)을 정의해주기 위해 교사 강요(Teacher Forcing)이라는 언어 모델의 훈련 기법을 이해해야한다. [RNN 언어 모델](https://wikidocs.net/46496)을 읽고 한번 교사 강요에 대해 알아보자.   \n",
    "> 테스트 과정에서 t 시점의 출력이 t+1 시점의 입력으로 사용되는 RNN 모델을 훈련시킬 때 사용하는 훈련 기법입니다. Teacher Forcing을 사용하지 않은 경우 잘못된 예측이 다음 시점의 입력으로 들어가면서 연쇄적으로 예측에 정확도를 미친다.   \n",
    "\n",
    "자신의 상태를 결정하는 모델을 자기회귀 모델(auto-regressive model, AR)이라고 한다. RNN 언어 모델은 대표적인 자기 회귀 모델의 예시이며, 트랜스포머의 디코더도 자기 회귀 모델이다. 트랜스포머의 디코더에 교사 강요(teacher forcing)를 적용한다.   \n",
    "\n",
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파리프라인을 구성하자. 교사 강요를 위해 `answers[:, :-1]`를 디코더의 입력값, `answers[:, 1:]`를 디코더의 레이블로 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
