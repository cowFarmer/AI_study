# EXPLORATION   
### 2022.01.13
4. 작사가 인공지능 만들기   

---

### 2022.01.13 log   

갖고있는 데이터셋을 정제해서   
토큰 형태로 분석하고 모델을 학습시켰다.   
그리고 이 모델에 단어를 넣으면 문장을 만들어 준다.   

투두 리스트   

- ~~데이터셋의 train valum이 약 140,000개인데 정제하는 과정에서 130,000개 미만으로 줄이기~~   
**130,250개로 해결 완료**

### 회고

NLP 관련 프로젝트를 했다.   
텍스트 데이터를 전처리 하면서 애를 썻는데   
18~19만개의 데이터를 정제하면서 12만5천개를 목표로 줄이라고 나와 있었다.   
조건은 토큰의 개수가 15개를 넘어갔을 때 데이터에서 제외하기   
`tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')` 여기에 `maxlen=15` 옵션을 추가로 넣고 진행했는데   
제대로 필터링이 되지 않았음을 확인했고, 그렇다면 이 옵션은 어떤 역할을 하는지 의문이 생겼다.   
또한 아직 공식 문서들을 보아도 제대로 해석하는 능력이 많이 부족함을 느꼈다.   
결국 문장들을 전처리 하는 과정에서 띄어쓰기를 기준으로 자르는 `len(sentence.split(' ')`을 사용해서 해결했지만 그래도 데이터셋 분리했을 때 13만개가 나왔다.   
LMS에서 제시한 목표 데이터보다 4% 정도 더 많아서 찜찜했지만 크게 중요해보이지 않아 넘어갔다.   

후에 프로젝트를 진행하고 나서 아지트에 인천 2기 김지훈님이 이름이 유사한 중복 파일과 토큰의 개수 제거 관련해서 글을 올려주셨는데 덕분에 깨달음을 얻을 수 있었다.   
~~후에 김용욱 콘텐츠 담당님이 목표 데이터 관련 문제가 많아 삭제되었다고 하셨다.~~   

주어진 코드를 보면 흐름을 이해하는 속도는 빨라졌는데, 직접 구현하라고 하면 어려울거같다.   
~~이번에도 단순히 옵션 몇줄 추가하는데도 몇 시간이 걸렸다..~~   
그래서 앞으로 LMS 진행할 때 코드를 이해하는 속도는 빨라졌으니 왜 이런식으로 구현하려고 했는지 이해하는것에 시간 투자를 많이 할 것이다.
