{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993a6ee5",
   "metadata": {},
   "source": [
    "# 1. 백본 네트워크 구조 상세분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8bb0b",
   "metadata": {},
   "source": [
    "딥러닝을 공부하면서 컴퓨터 비전 분야의 백본 네트워크, AlexNet, VGG, ResNet 등을 들어봤을 것이다. 이 이후에는 어떤 방식으로 네트워크들이 생겼는지 알아보자.   \n",
    "\n",
    "딥러닝 업계에서 한 해에 수천 편의 논문이 쏟아지고, 2년전 논문도 당연한 기술이 된다. ResNet도 2015년 ImageNet challenge에서 공개된 네트워크로, 다른 분야에 비해 기술이 굉장히 빠르게 보급된 것이다. 그래서 딥러닝 공부를 계속하기 위해 새로 나오는 논문을 읽고, 최신 기법을 파악하는게 중요하다.   \n",
    "\n",
    "이번 시간에 딥러닝 논문의 구조 파악과 대표적인 딥러닝 네트워크 구조를 알아보자. ResNet을 보면서 딥러닝 논문의 구조를 살펴보고 친해지자. 이후에는 ResNet 이후의 다른 시도 DenseNet,SENet을 소개하고 네트워크의 구조를 최적화하는 NAS(Neual Architecture Search), EfficientNet에 대해 간략히 짚어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc811f",
   "metadata": {},
   "source": [
    "# 1-2. 딥러닝 논문의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333df7b0",
   "metadata": {},
   "source": [
    "__참고 자료__\n",
    "- 원본 논문: [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)   \n",
    "- [Andrew Ng교수님의 C4W2L03 Resnets](https://www.youtube.com/watch?v=ZILIbUvp5lk)\n",
    "- [원본 pdf](https://arxiv.org/pdf/1512.03385.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d44307",
   "metadata": {},
   "source": [
    "딥러닝 기반 컴퓨터 비전 모델 중 하나로 꼽히는 ResNet 논문부터 살펴보자. 2015년 발표됐으며 Deep Residual Learning for Image Recognition 이라는 제목으로 Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun이 작성했다.   \n",
    "Kaiming He는 Facebook AI Reserach 소속으로, 딥러닝 분야를 계속 공부하다보면 이름을 많이 접하게 되는 유명한 딥러닝 연구자이다.   \n",
    "\n",
    "ResNet 논문은 `Residual Block`이라는 간단하면서도 획기적인 개념을 도입하여 딥러닝 모델의 레이어가 깊어져도 안정적으로 학습되면서 모델 성능 개선까지 가능함을 입증했다. 이렇게 딥러닝 분야에서 사용되는 많은 기법들은 논문을 통해 공개되는 경우가 많이 있다.   \n",
    "\n",
    "논문에서 ResNet의 잔차 학습을 어떤 과정으로 소개하고 효과를 증명할까? __실험__ 으로 효과를 눈으로 보여준다. 이를 파악하기 위해 논문의 구조를 파악하고 이해할 수 있어야 한다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2a220",
   "metadata": {},
   "source": [
    "### 논문의 형식적 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65c740",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-4.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d6416",
   "metadata": {},
   "source": [
    "논문은 정형화된 형식을 갖고 있다. __초록(abstract)__ 은 아이디어를 제안하는 방식과 학계에 이 논문이 기여하는 점을 요약한다. 그 뒤로 논문의 주요 내용이 따라오는데, 일반적으로 __서론(introduction)__, __관련 연구(related work)__ 그리고 소제목의 표현방식에 따라 달라지지만 일반적으로 제안하는 방법에 관한 __이론 설명__ 이 따라온다. 이렇게 제안하는 방법을 소개한 후 이 효과를 확인하기 위해 __실험(experiments)__ 셋팅과 결과가 따라 붙는다. ResNet 논문에는 없지만 그 뒤로 __결론(conclusion)__ 으로 연구 내용 요약과 추가적인 연구 방향을 소개하기도 한다.\n",
    "\n",
    "눈문의 내용이 끝나면 __참고문헌(reference)__, __부록(appendix)__ 이 붙는다. 참고문헌에서는 눈문의 설명과 구현에 있어 인용한 논문들의 리스트가 소개되고, 부록에서는 미처 본문에서 설명하지 못한 구현 또는 추가적인 실험 설명이 포함된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d79463",
   "metadata": {},
   "source": [
    "이러한 논문의 형식에는 논리 구조가 있다.\n",
    "1. 이전까지 연구가 해결하지 못한 문제의식\n",
    "2. 문제를 해결하기 위해 그동안의 다른 시도\n",
    "3. 문제에 대한 논문만의 독창적인 시도\n",
    "4. 그러한 시도가 가져온 차별화된 성과\n",
    "\n",
    "introduction은 이러한 논리구조를 명확하게 정리하여 제시하는 중요한 역할을 담당하고 있다. related work는 2)의 내용을, 논문의 본론과 experiments은 3)의 내용, experiment에 포함된 실험 결과와 해석이 4)의 내용을 구체화하여 제시하는 역할을 한다. \n",
    "\n",
    "이러한 논문의 논리 구조는 후속 논문에서 인용되면서, 제시한 방법론이 가지는 한계점이 새로운 문제의식으로 제시되고, 그 문제가 새로운 방법으로 해결되는 과정을 통해 수많은 논문들로 이루어진 거대한 생각의 족보를 만들어가게 된다. 그래서 __논문을 보면서 역사적인 의의와 그 논문이 처음 제시했던 독창적인 아이디어가 무엇인지 파악하는게 중요하다.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055a61b",
   "metadata": {},
   "source": [
    "ResNet의 논문 Deep Residual Learning for Image Recognition을 보면 논리구조가 이렇게 되어 있다.\n",
    "- Abstract과 Introduction에서 문제의식과 해결하는 솔루션의 개요를 제시한다.\n",
    "- Related Work에서 논문의 솔루션과 유사한 다른 시도를 언급한다.\n",
    "- Deep Residual Learning은 솔루션의 구체적인 내용과 구현 방법을 소개한다.\n",
    "- Experiments에 실험결과를 통해 검증한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872dd585",
   "metadata": {},
   "source": [
    "# 1-3. ResNet의 핵심 개념과 그 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298bbfc",
   "metadata": {},
   "source": [
    "### ResNet 논문의 문제의식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302bc7f7",
   "metadata": {},
   "source": [
    "introduction을 통해 ResNet 논문이 제기하고 있는 문제의 핵심을 정리해보자.   \n",
    "\n",
    "최초로 제기하는 질문은 딥러닝 모델이 레이어를 깊게 쌓으면 항상 성능이 좋아지는가에 대한 질문이다. 레이어를 깊이 쌓았을 때 gradient vanishing, exploding 문제가 발생하여 모델의 학습을 통한 수렴에 문제가 생긴다.   \n",
    "\n",
    "가장 눈에 띄는 키워드는 `Degradation Problem`이다. 모델의 수렴을 방해하는 vanishing, exploding 문제와 달리, 레이어를 깊이 쌓았을 때 모델이 수렴하고 있음에도 불구하고 발생하는 문제로, 제시된 아래의 그래프가 이 문제의 핵심을 보여준다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/GC-1-L-degradation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b559f",
   "metadata": {},
   "source": [
    "이를 해결하기 위해 언급한 방법으로 `normalized initialization [23, 9, 37, 13] and intermediate normalization layers` 문구가 있다.   \n",
    "`Degradation Problem`은 레이어가 20개 쌓였음에도 56개 쌓인 모델보다 성능이 좋게 나옴을 말한다. 이는 오버피팅 문제가 아니라 최적화로 생긴 문제다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72e3e5",
   "metadata": {},
   "source": [
    "### ResNet 논문이 제시한 솔루션 Residual Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0409a6",
   "metadata": {},
   "source": [
    "레이어가 깊은 모델은 학습이 어렵다는 점을 해결하기 위해 레이어의 입력값을 활용하여 residual function(잔차 함수)을 학습하도록 한다.   \n",
    "\n",
    "단순히 말하자면 지름길(shortcut connection)을 통해 레이어가 입력값을 직접 참조하도록 레이어를 변경했음을 말한다. 이는 앞에서 입력으로 들어온 값을 네트워크의 출력층에 곧바로 더해준다. 네트워크는 출력값에서 원본 입력을 제외한 residual 함수를 학습하기 위해 ResNet이라는 이름을 갖게 되었다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/GC-1-L-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84cf6b",
   "metadata": {},
   "source": [
    "레이어를 많이 쌓았는데 모델 성능이 떨어지는 것에 저자들은 의문을 품었다. 만약 기존 모델에 identity mapping 레이어를 수십 장 덧붙인다고 모델 성능이 떨어질 리는 없는데, 그렇다면 레이어를 많이 쌓았을 때 이 레이어들은 오히려 identity mapping 레이어보다 못하다는 뜻이 된다. 많이 겹쳐 쌓은 레이어가 제대로 학습이 이루어지지 않았다는 반증이 된다.\n",
    "\n",
    "여기서 저자들이 기발한 생각을 한다. 학습해야할 레이어 $H(x)$를 $F(x)+x$로 만든다. $x$는 레이어의 입력값이다. 만약 $F(x)$가 기울기 소실 현상으로 학습이 안되어 zero mapping이 될지라도 최종 $H(x)$는 최소한의 identity mapping이 되어 성능 저하가 발생하지 않게 된다.   \n",
    "그렇다면 실제로 학습해야할 $F(x)$는 학습해야할 레이어 $H(x)$에 입력값 $x$를 뺀 형태, 잔차(residual) 함수가 되는데, 이것이 $H(x)$를 직접 학습하는 것보다 학습이 쉽지 않겠냐는 것이다. 레이어를 깊이 쌓을수록 Residual에 해당하는 F(x)는 0에 가까운 작은 값으로 수렴해도 충분하다. 실험 결과도 이 구조가 안정적으로 학습이 되며, 레이어를 깊이 쌓을수록 성능이 향상되는 것을 확인했다.   \n",
    "\n",
    "정리하면, Residual 레이어를 $F(x)$로 표현하면 이 레이어의 결과는 입력값 $x$에 대해 $F(x)$가 된다. 여기에 레이어의 입력값 $x$를 더해주면 최종 출력값은 $F(x)+x$, 즉 우리가 보통 생각하는 레이어의 결괏값이 된다. 이후 ReLU 를 거치게 된다. 위 식에서 $F(x, W_i)$는 학습되어야할 residual mapping으로소 잔차 학습은 이 식을 학습한다. ResNet에서 shortcut connection을 가진 ResNet의 기본 블록을 Residual Block이라고 부르고 이러한 블록이 여러개로 이루어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d1f36",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3015036d",
   "metadata": {},
   "source": [
    "ResNet 논문의 실험(eexperiments) 부분을 자세히 살펴보자.   \n",
    "\n",
    "shortcut connection의 아이디어를 검증하려면 어떤 실험을 해야 할까? 이를 사용한 네트워크와 사용하지 않은 네트워크의 성능 비교를 통해 알아보자.\n",
    "\n",
    "실제 논문에서 네트워크가 깊어지면서 발생하는 gradient vanishing 문제를 ResNet이 해결함을 보여주기 위해, shortcut connection 유무와 네트워크 깊이에 따라 경우를 나누어 모델을 구현한다. 18, 34 layer와 각각 shortcut이 있는 plain network와 없는 ResNet으로 총 4가지를 통해 효과를 분석한다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-5.max-800x600.png)   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/GC-1-L-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9be438",
   "metadata": {},
   "source": [
    "Top-1 error는 모델이 가장 높은 확률 값으로 예측한 class 1개가 정답과 일치하는지 보는 경우의 오류율을 말한다. Top-5는 모델이 예측한 값중 가장 높은 확률 값부터 순서대로 5개 class중 정답이 있는지 보는 것으로 숫자가 낮을수록 좋다.\n",
    "\n",
    "좌측을 보면 layer 18보다 34가 성능이 낮게 나오지만, 우측 shortcut을 넣은 ResNet의 결과를 보면 layer 18보다 34가 성능이 더 좋게 나왔다. 어떻게 간단한 실험으로 Residual Block의 효과를 입증했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bba6d6",
   "metadata": {},
   "source": [
    "# 1-4. ResNet 이후 시도 (1) Connection 촘촘히"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094fa2aa",
   "metadata": {},
   "source": [
    "__참고 자료__\n",
    "- [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)\n",
    "- [DenseNet Tutorial [1] Paper Review & Implementation details](https://hoya012.github.io/blog/DenseNet-Tutorial-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b8fa8",
   "metadata": {},
   "source": [
    "ResNet 이후에도 개선의 여지가 남아있다. `Densely Connected Convolutional Networks`의 저자들은 __DenseNet__ 의 shortcut connection을 마치 Fully Connected Layer처럼 촘촘히 가지도록 하면 성능 개선 효과가 클 것이라 생각하고 실험으로 입증했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a3c68",
   "metadata": {},
   "source": [
    "### Dense Connectivity\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-7.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15509ee8",
   "metadata": {},
   "source": [
    "일반적인 CNN이 $L$개의 레이어에 대해 각 하나씩 연결하는 총 $L$개의 연결을 갖는 것과 달리, DenseNet의 기본 블록은 $L$개의 레이어가 있을 때 레이어간 $L(L+1)/2$개의 직접적인 direct connection을 만든다. 이러한 연결 구조를 dense connectivity 라고 부르며, 아래처럼 $H_l$로 표기하고 이를 합성함수(composite function)라 부른다.   \n",
    "\n",
    "$X_l = H_l([X_0,X_1,...,X_l-1])$\n",
    "\n",
    "각 레이어는 이전 레이어들에서 나온 feature map 전부를 입력값으로 받는다. $X_0,X_1,...,X_l-1$ 의 경우 $0$부터 $l-1$번째 레이어까지 거친 특성 맵을 의미한다. 이들은 합성함수 $H$를 거쳐 $l$번째 레이어의 출력값이 된다. DenseNet은 이를 통해 gradient vanishing을 개선하고 특성을 계속 재사용할 수 있게 한다.\n",
    "\n",
    "Shortcut connection이 있어 ResNet과 비슷해 보일 수 있지만, ResNet은 shortcut을 원소별로 단순하게 더해줬다. 하지만 DenseNet은 하나하나를 차원으로 쌓아(concatenate) 하나의 텐서로 만들어 내는 차이점이 있다. 그리고 이전 ResNet은 connection에 다른 연산이 없는데, 합성함수 $H_l$은 이 텐서에 배치 정규화, ReLU 활성화 함수, 3x3 컨볼루션 레이어를 통해 pre-activation을 수행한다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/GC-1-L-preactivation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738305eb",
   "metadata": {},
   "source": [
    "Pre-activation의 개념은 [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf) 논문에서 제시되었는데, (b)에서 보듯 ReLU가 컨볼루션 블록 안으로 들어간 것을 의미한다. 아래의 리뷰를 통해 어떤 역할을 하는지 알 수 있다.   \n",
    "- [Pre-Activation ResNet(2016) 리뷰, Identity Mappings in Deep Residual Networks](https://deep-learning-study.tistory.com/510)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98992597",
   "metadata": {},
   "source": [
    "### Growth Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87febdc8",
   "metadata": {},
   "source": [
    "feature map을 더해주던 ResNet과 달리 DenseNet은 특성 맵을 채널 방향으로 쌓아서 사용한다. 4개의 채널을 가진 CNN 레이어를 4개의 DenseNet 블록으로 만들었을 때 입력값의 채널 개수가 4인 경우 블록 내 각 레이어의 입력값은 몇 개의 채널을 갖게 될까?\n",
    "\n",
    "첫 번째 레이어의 입력값의 채널은 입력 데이터의 채널 그대로 4가 된다. 두 번째 레이어의 입력값은 입력 데이터의 채널 값과, 첫 번째 레이어 출력값의 채널 4를 더해 8이 된다. 세 번째 레이어는 첫, 두 번째 레이어의 채널 값 4씩 받아 12개의 특성 맵을 입력받고, 네 번째 레이어는 같은 방식으로 16개의 특성 맵을 입력받는다.\n",
    "\n",
    "입력값의 채널이 4로 시작했으나 진행할수록 특성 맵의 크기가 매우 커지는 것을 볼 수 있다. 이를 제안하기 위해 논문에서 `growth rate`라는 값을 조정하여 커지는 채널의 개수를 조절한다.\n",
    "\n",
    "위에서 CNN의 채널 수를 4로 정했는데 이 값이 growth rate이라고 할 수 있다. 블록 내의 채널 개수를 작게 가져가면서 최종 출력값의 특성 맵 크기를 조정할 수 있도록 했다. 이외에도 여러 방식이 적용되었다. [DenseNet Tutorial 1 Paper Review & Implementation details](https://hoya012.github.io/blog/DenseNet-Tutorial-1/) \n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/gc-1v2-l-3-1.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d29cd",
   "metadata": {},
   "source": [
    "위 그림처럼 이미지넷 챌린지에 참가하기 위한 DenseNet 구현체는 growth rate로 32를 사용했다고 한다.   \n",
    "\n",
    "12개의 컨볼루션 레이어가 있는 두 번째 Dense block을 구현할 때 각 레이어에서 입력받는 채널은 몇 개가 될까? 두 번째 Dense block에 주어지는 입력은 32개의 채널을 갖고있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c603e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dense Block내의 각 레이어 output의 channel을 계산하는 함수\n",
    "def get_channel_list():\n",
    "    channel_list = []\n",
    "    input_channel = 32\n",
    "    growth_rate = 32\n",
    "    for i in range(12):\n",
    "        channel_list.append(input_channel + growth_rate*i)\n",
    "    return channel_list\n",
    "\n",
    "get_channel_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde99ae",
   "metadata": {},
   "source": [
    "# 1-5. ResNet 이후 시도 (2) 어떤 특성이 중요할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf3f75",
   "metadata": {},
   "source": [
    "__참고 자료__   \n",
    "- [Squeeza-and-Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
    "- [jayhey님의 gitblog SENet(Squeeze and excitation networks)](https://jayhey.github.io/deep%20learning/2018/07/18/SENet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9efb1e",
   "metadata": {},
   "source": [
    "__SENet__ 을 살펴보자. SENet은 Squeeza and Excitation Networks의 줄임말고 어떤것을 squeeza and excite 한다는 것일까?\n",
    "\n",
    "일반적인 CNN은 입력에 대해 convolution filter를 filter size에 따라 적용한다. 이때 필터의 개수가 convolution layer 출력값의 채널 개수가 된다. SqueezaNet에서는 이때 채널 방향으로 global average pooling을 적용하고, 압축된 정보를 활용하여 중요한 채널이 활성화되도록 한다. 이는 CNN에서 나온 특성 맵 채널에 어텐션 매커니즘을 적용한 블록을 만들어냈다고 볼 수 있다.    \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-10.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220e6d6",
   "metadata": {},
   "source": [
    "### Squeeze\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-11.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b62e26",
   "metadata": {},
   "source": [
    "__Squeeze__ 는 특성에서 중요한 정보를 짜내는 과정이다. 특성 맵 채널에서 어느 채널이 중요한지 정보를 만들기 위해 채널에 따른 정보를 압축해서 가져와야 한다.   \n",
    "어떻게 채널별 정보를 압축할 수 있을까? 일반 CNN에서도 많이 사용하듯, pooling 기법을 사용하면 된다. 이는 보통 kernel 영역의 정보를 압축하는데 사용한다. 커널 영역에 최댓값만 남기는 Max Pooling, 평균값을 남기는 Average Pooling이 있다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-10.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c1d98",
   "metadata": {},
   "source": [
    "그림에서 Squeeze는 $F_{sq}$ 함수에서 일어난다. $F_{tr}$ 이라는 컨볼루션 레이어를 거치면 \"HxWxC\" 크기를 가진 특성 맵 $U$가 나온다. $U$에 Squeeze를 적용하면 \"1x1xC\"의 크기가 나온다. 이를 해석하면 채널별로 1개의 숫자만 남게 2D 특성맵 전체에 평균값을 남기는 global average pooling을 수행한다. 이렇게 얻어진 \"1x1xC\" 벡터는 채널별 정보를 압축해 담고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e602345",
   "metadata": {},
   "source": [
    "### Excitate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c37ba",
   "metadata": {},
   "source": [
    "채널별 정보를 짜내는데 성공했다. 이제 어떤 채널을 강조해야 할지 판단하면 된다. 이러한 강조를 논문에서는 excitation으로 표현하고 수식은 $F_{ex}$이다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-12.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165fd82",
   "metadata": {},
   "source": [
    "수식을 해석해보자.   \n",
    "- $W_1z$의 $z$는 squeeze한 결과물이다. 이를 ReLU 활성화 함수 $\\delta$를 거친다.\n",
    "- 이후에 $W_2$를 곱해주는 linear layer를 거쳐 마지막으로 시그모이드 $\\sigma$를 거친다.\n",
    "\n",
    "시그모이드를 사용하는 이유는 가장 중요한 하나의 채널만 활성화 하는게 아닌, 여러 채널들이 서로 다른 정도로 활성화되도록 하기 위함이다. 데이터셋에 정답 라벨이 하나뿐인 단순 분류 모델의 활성화 함수로 소프트맥스를 사용해 단 하나의 최댓값을 찾지만, 하나의 대상에 여러 개의 클래스의 정답 라벨을 지정할 수 있는 다중 라벨 분류(multi label classification)에서 시그모이드를 사용하는 것과 같은 방식이다.\n",
    "\n",
    "이렇게 계산된 벡터를 기존의 특성 맵 채널에 따라 곱하여 중요한 채널이 활성화 되도록 만든다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-13.max-800x600.png)   \n",
    "[논문](https://arxiv.org/pdf/1709.01507.pdf)의 `TABLE 14`를 보면 SE-Identity block이 제일 좋은 성능을 보이고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1d2f3",
   "metadata": {},
   "source": [
    "# 1-6. 모델 최적화하기 (1) Neural Architecture Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f459441",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-14.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59194636",
   "metadata": {},
   "source": [
    "지금까지 본 방식은 사람이 고안한 방식을 네트워크 구조에 적용하여 효과를 본 방법이다. 모델의 훈련은 컴퓨터가 시켜줄 수 있어도, 모델의 구조는 사람이 직접 고민하고 실험했다. 하지만 이 과정을 반복하다 보니 __딥러닝으로 이미지 분류 문제를 풀기 위해 모델의 파라미터를 최적화하듯이 모델의 구조를 최적화할 수 없을지__ 생각하게 된다. 여러가지 네트워크 구조를 탐색하는 것을 아키텍쳐 탐색(architecture search)이라 한다. 그중 신경망을 사용해 모델의 구조를 탐색하는 접근 방법을 __NAS(neural architecture search)__ 라고 한다.\n",
    "\n",
    "NASNet은 NAS에 강화학습을 적용하여 500개의 GPU로 최적화한 CNN 모델들이다. 직접 모델 탐색을 할 환경을 구축하지 않아도 텐서플로우에 이미지넷 2012년 데이터셋에 최적화된 구조의 pre-trained NASNet 모델을 쉽게 사용할 수 있다. [참고자료](https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet)\n",
    "\n",
    "NASNet은 어떤 방법으로 만들어졌는지 대략적으로 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70573a",
   "metadata": {},
   "source": [
    "### NASNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd720d",
   "metadata": {},
   "source": [
    "__참고자료__\n",
    "- [Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012)\n",
    "- [AI 논문 리뷰 – Neural Architecture Search With Reinforcement Learning](http://solarisailab.com/archives/2691)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab04bb",
   "metadata": {},
   "source": [
    "NASNet과 같이 거창한 방법이 아니여도, 머신러닝에서 grid search 등으로 실험과 모델 세팅(config)을 비교하기 위한 자동화된 방법을 사용하곤 한다.   \n",
    "그리드 탐색을 간단히 말하면 모든 조합을 실험해보는 것이다. 하지만 이렇게 접근할 경우 머신 러닝중 학습이 오래 걸리는 딥러닝에서는 적합하지 않다.\n",
    "\n",
    "딥러닝에서 모델을 탐색하기 위해 강화학습 모델이 대상 신경망의 하이퍼파라미터를 조정하면서 최적의 성능을 내는 방법중 하나가 NASNet이다. 아키텍쳐 탐색을 하는 동안 강화학습 모델은 대상 신경망의 구성을 일종의 변수로 조정하면서 최적의 성능을 내도록 한다.   \n",
    "우리가 지금까지 봐왔던 레이어의 세부 구성, CNN 필터 크기, 채널의 개수, connection 등이 조정할 수 있는 하이퍼파라미터 변수가 된다. 이렇게 네트워크 구성에 대한 요소들을 조합할 수 있는 범위를 탐색 공간(search space)라고 한다. 이 공간에서 최고의 성능을 낼 수 있는 요소의 조합을 찾아야한다.\n",
    "\n",
    "NASNet이 NAS를 처음 적용한 것은 아니며 이전 논문에도 많이 있다. 많이 접한 MNIST에 최적화하는데 800개의 GPU를 사용해서 28일이 걸렸다. 그렇게 나온 구조가 아래의 그림이다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-15.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64214d1",
   "metadata": {},
   "source": [
    "NASNet 논문은 이미지넷 데이터에 대해 이보다 짧은 시간 안에 최적화를 했다. 어떻게 했을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98afa24c",
   "metadata": {},
   "source": [
    "### Convolution cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d2a73",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-16.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccca5269",
   "metadata": {},
   "source": [
    "레이어 하나마다 하이퍼 파라미터를 조절하면 탐색 공간의 영역이 방대해진다. 탐색 공간이 넓으면 찾아야 할 영역이 넓어지고, 여기서 최적의 포인트를 찾는데 더 오랜 시간이 걸린다. NASNet 논문에서는 이러한 탐색 공간을 줄이기 위해 모듈(cell) 단위의 최적화를 하고 그 모듈을 조합하는 방식을 채택한다.\n",
    "\n",
    "ResNet에서 Residual Block, DenseNet에는 Dense Block이라는 모듈이 사용되는데, 논문에서는 이와 유사한 개념을 convolution cell이라고 부른다. Convolution cell은 normal cell과 reduction cell로 구분된다.   \n",
    "\n",
    "Normal cell은 특성 맵의 가로, 세로가 유지되도록 stride를 1로 고정한다. Redution cell은 stride를 1 또는 2로 가져가서 특성 맵의 크기가 줄어들 수 있도록 한다. 논문의 모델은 normal cell과 reduction cell 내부만을 최적화하여, 이렇게 만들어진 convolution cell이 위 그림의 두 가지가 된다. 이 cell을 조합해 NASNet을 만들었고, 좀 더 적은 연산과 가중치고 SOTA 성능을 기록했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c0eb6",
   "metadata": {},
   "source": [
    "# 1-7. 모델 최적화하기 (2) EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621959a",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-17.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9516ee",
   "metadata": {},
   "source": [
    "__참고 자료__   \n",
    "- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)\n",
    "- [hoya012님의 EfficientNet： Rethinking Model Scaling for Convolutional Neural Networks 리뷰](https://hoya012.github.io/blog/EfficientNet-review/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fb8f0",
   "metadata": {},
   "source": [
    "2019년에 발표된 EfficientNet의 접근 방법에 대해 알아보자. EfficientNet의 강력함은 그래프로 한눈에 볼 수 있다. 기존 모델들의 오류율을 뛰어넘을 뿐만 아니라 모델의 크기인 number of parameters 또한 최적화된 것을 볼 수 있다. 빨간색 선이 EfficientNet의 모델들이고 그 아래로 여러 모델들이 존재한다. 다른 네트워크들과 비교하면 EfficientNet은 작고 효율적인 네트워크를 사용했다고 볼 수 있다.\n",
    "\n",
    "EfficientNet은 이미지에 주로 사용하는 CNN을 효율적으로 사용할 수 있도록 네트워크의 형태를 조정할 수 있는 `width`, `depth`, `resolution` 세 가지 요소에 집중한다.   \n",
    "`width`는 CNN의 채널에 해당한다. 채널을 늘려줄수록 CNN의 파라미터와 특성을 표현하는 차원의 크기를 키울 수 있다. `depth`는 네트워크의 깊이다. ResNet은 대표적으로 네트워크를 더 깊게 만들 수 있도록 설계해 성능을 올린 예시이다. `resolution`은 입력값의 너비와 높이의 크기다. 입력이 클수록 정보가 많아져 성능이 올라갈 여지가 생기지만 레이어 사이의 특성 맵이 커지는 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44089824",
   "metadata": {},
   "source": [
    "### Conpound scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe73ec4",
   "metadata": {},
   "source": [
    "EfficientNet은 `width`, `depth`, `resolution`을 최적으로 조정하기 위해 앞선 NAS와 유사한 방법을 사용해 baseline network의 구조를 미리 찾고 고정해둔다. 모델의 구조가 고정이 되면 효율적인 모델을 찾는다는 커다란 문제가, 개별 래이어의 `width`, `depth`, `resolution`을 조절해 기본 모델을 적절히 확장시키는 문제로 단순화했다.   \n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-L-18.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e6f7a",
   "metadata": {},
   "source": [
    "EfficientNet 논문에서는 `width`, `depth`, `resolution` 세 가지 \"scaling factor\"를 동시에 고려하는 compound scaling을 제안한다. 위 식에서 compound coefficient $\\phi$는 모델의 크기를 조정하기 위한 계수가 된다. 위 식을 통해 레이어의 `width`, `depth`, `resolution` 세 요소를 각각 조정하는 것이 아닌 고정된 계수 $\\phi$에 따라 변하도록 하면 보다 일정한 규칙에 따라(in a principled way) 모델의 구조가 조절되도록 할 수 있다.\n",
    "\n",
    "논문은 $\\phi$를 1로 고정한 뒤 세 요소들을 정하는 $\\alpha, \\beta, \\gamma$의 최적값을 찾는다. 논문에서는 그리드 탐색으로 찾을 수 있었다고 설명한다. 이후 `width`, `depth`, `resolution`의 기본 배율을 고정한 뒤 compound coefficient의 $\\phi$를 고정하여 모델의 크기를 조정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ec36c",
   "metadata": {},
   "source": [
    "# 1-8. 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aadfa9",
   "metadata": {},
   "source": [
    "컴퓨터 비전을 공부하면서 AlexNet, VGG, ResNet부터 오늘 다룬 DenseNet, SENet, NASNet, EfficientNet 등 다양한 아키텍처를 접한다. 이렇게 유명한 네트워크들은 앞으로 이미지를 다루게 된다면 즐겨 사용하게 될 기법들이 하나씩 담겨있다. 이들을 모두 기억하기보다 어떤 상황에 해당 아이디어들이 제안되었는지 기억하면 새로운 모델을 만드는데 큰 도움이 된다.   \n",
    "\n",
    "앞으로 세부 분야를 정해 배우고 공부할때에도 알맞은 논문과 방법을 찾고 이를 활용하는 것은 매우 중요한 능력이 된다. \n",
    "\n",
    "- [9 Applications of Deel Learning for Computer Vision](https://machinelearningmastery.com/applications-of-deep-learning-for-computer-vision/)\n",
    "\n",
    "이미지 분류하는 claasification task, 물체 검출 detection, 물체의 영역을 분리하는 segmentation 등 다양한 task를 딥러닝으로 푸는 논문들을 읽어볼 수 있는데, 해결하거나 관심있는데 task를 찾고 관련된 논문을 통해 내용을 정리해보는 시간을 가지면 좋다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
