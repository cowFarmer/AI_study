{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"G15_human_pose_estimation.ipynb","provenance":[],"authorship_tag":"ABX9TyMS0AkrwjdM1E9Sb5eaYKc/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 15. 사람의 몸짓을 읽어보자"],"metadata":{"id":"HYWvdAbK4c8n"}},{"cell_type":"markdown","source":["# 15-1. 들어가며"],"metadata":{"id":"j5PyjwEl4erU"}},{"cell_type":"markdown","source":["### Human Pose Estimation with Keypoint detection\n","전 세계적으로 인기를 끌고 있는 틱톡 애플리케이션을 보면 지금까지 우리가 만들어온 얼굴인식과 달리 전신이 등장한다.\n","\n","오늘은 human pose estimation에 대한 개념과 이론에 대해 알아보자."],"metadata":{"id":"GzGT4NUE6m89"}},{"cell_type":"markdown","source":["# 15-2. body language, 몸으로 하는 대화"],"metadata":{"id":"WH8Ji_DG4gOl"}},{"cell_type":"markdown","source":["human pose estimation은 크게 2D와 3D로 나누어진다.\n","\n","2D는 2D 이미지에서 x,y 2차원 좌표들을 찾아내고, 3D는 2D 이미지에서 x,y,z 3차원 좌표들을 찾아내는 기술이다.   \n","하지만 2차원 이미지에서 3차원 이미지를 복원하는 일은 굉장히 어려운 일이다.\n","- [영상 Geometry #1 좌표계](https://darkpgmr.tistory.com/77)\n","- [영상 Geometry #7 Epipolar Geometry](https://darkpgmr.tistory.com/83?category=460965)\n","\n","실세계 좌표계에서 사람의 발은 바닥에 있으면서 무릎은 머리 위로 갈 수 없듯이, 사람의 몸은 3D 환경에서 제약이 있다. 그래서 이런 제약 조건을 이용하면 어느 정도 문제를 해결할 수 있다.\n","\n","3D pose estimation을 깊이 있게 다루기에 매우 오랜 시간이 걸리기 때문에, 오늘은 2D 영상 내에서 (x, y) pose(관절)의 위치를 찾는 방법을 다뤄보자."],"metadata":{"id":"Fvl15mnH7AAz"}},{"cell_type":"markdown","source":["# 15-3. Pose는 face landmark랑 비슷해요"],"metadata":{"id":"nRND9sPU4ikD"}},{"cell_type":"markdown","source":["![](https://d3s0tskafalll9.cloudfront.net/media/original_images/02_8LQHgwE.png)"],"metadata":{"id":"CLHD03qdAnL9"}},{"cell_type":"markdown","source":["2D pose estimation을 다룬 적이 있다. face landmark와 매우 비슷하다.   \n","딥러닝이나 사람의 시각에서도 실제로 매우 비슷한 앱이다. 입력과 출력 개수만 다를 뿐 상당히 비슷하다.\n","\n","하지만 난이도에서 차이가 난다. face landmark는 물리적으로 거의 고정되어 있는데(입이 얼굴보다 클 수 없음), human pose는 팔, 다리가 상대적으로 넓은 범위와 자유도를 갖는 것을 고려해야 한다.\n","\n","자유도가 높다는 것은 데이터 분포를 특정하기 어렵다고 표현할 수 있다. 데이터 분포 학습하기 어렵다 -> 학습에 더 많은 데이터가 필요하고 더 복잡한 모델을 사용해야함을 의미한다.\n","\n","따라서 상당히 많은 사전 작업이 요구되고 사용하려는 앱에 따라 접근 방법도 달라진다.   \n","가장 초기에 만나는 접근법은 두 가지로 나눠질 수 있다."],"metadata":{"id":"mV-HLcYWAnx3"}},{"cell_type":"markdown","source":["### 우리에게 맞는 방법은 뭘까?\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/03_6C5RZR1.max-800x600.png)"],"metadata":{"id":"wnTpNsxKBS69"}},{"cell_type":"markdown","source":["첫 번째 방법은 Top-down 방법이다.   \n","- 모든 사람의 정확한 keypoint를 찾기 위해 object detection을 사용한다.\n","- crop한 이미지 내에서 keypoint를 찾아내는 방법으로 표현한다.\n","- detector가 선행되어야 하고 모든 사람마다 알고리즘을 적용해야 하기 때문에, 사람이 많이 등장할 때는 느리다는 단점이 있다.\n","\n","두 번째 방법은 Bottom-up 방법이다.\n","- detector가 없고 keypoint를 먼저 검출한다. 예를들어 손목에 해당하는 모든 점들을 검출한다.\n","- 한 사람에 해당하는 keypoint를 clustering 한다.\n","- detector가 없기 때문에 다수의 사람이 영상에 등장하더라도 속도 저하가 크지 않다. 반면 top down 방식에 비해 keypoint 검출 범위가 넓어 성능이 떨어지는 단점이 있다.\n","\n","얼마나 정확해야 하는지, 여러 사람이 등장하는지에 따라 필요한 알고리즘이 달라질 수 있다. 핸드폰 카메라로 찍는 인물들은 대체로 소수가 등장하기 때문에 top-down 방식을 이용해도 큰 속도 저하 없이 사용할 수 있을 것이라 생각한다.\n","\n","Top-down 방법들에 대해 자세히 알아보자."],"metadata":{"id":"NpWVQMmrBVoO"}},{"cell_type":"markdown","source":["# 15-4. human keypoint detection(1)"],"metadata":{"id":"aZckBQQo4l8k"}},{"cell_type":"markdown","source":["### 자유도가 높은 사람의 동작\n","![](https://github.com/Team-Neighborhood/Kalman-Filter-Image/raw/master/result/KF_result.gif)"],"metadata":{"id":"Dm7Lyyb5C90y"}},{"cell_type":"markdown","source":["human pose estimation은 keypoint의 localization 문제를 푼다는 점에서 비슷하다.   \n","하지만 손목, 팔꿈치 등의 joint keypoint 정보는 얼굴의 keypoint보다 훨씬 다양한 위치와 변화를 보인다.\n","\n","위 gif에서 볼 수 있듯이 손이 얼굴을 가리는 행위, 모든 keypoint가 영상에 담기지 않는 invisible, occlusions, clothing, lighting change가 face landmark에 비해 더 어려운 환경을 만든다.\n","\n","딥러닝 기반 방법이 적용되기 전에는 다양한 사전 지식이 사용됐다.   \n","가장 기본이 되는 아이디어는 인체는 변형 가능 부분으로 나눠져 있고 각 부분끼리 연결성을 갖고 있다는 것이다."],"metadata":{"id":"OtYLRUbSDA2i"}},{"cell_type":"markdown","source":["![](https://d3s0tskafalll9.cloudfront.net/media/images/05_9oDmNOY.max-800x600.png)\n","\n","그림에서 보이는 것처럼 손은 팔, 팔은 몸과 연결되어 있다. 손이 다리 옆에 있을 확률이 팔 옆에 있을 확률보다 훨씬 작은 것이다. 이런 제약 조건을 그림에 보이는 스프링으로 표현했다.\n","\n","3D 환경에서 생각하면 좋은 방법이다. 하지만 우리가 다루는 2D 데이터는 촬영 각도에 따라 충분히 팔이 다리 옆에서 관찰될 수 있다.\n","\n","이 문제를 해결하기 위해 Deformable park models 방법에서는 각 part들의 complex joint relationship의 mixture model로 keypoint를 표현하는 방법을 이용했지만 성능은 기대에 미치지 못했다.\n","- [Articulated human detection with flexible mixtures-of-parts](https://www.cs.cmu.edu/~deva/papers/pose_pami.pdf) 관련 논문\n","\n","deformable part model은 template들의 모음으로 구성되어 있다. 그리고 이는 global과 part 두 가지 종류로 나눠져 있다."],"metadata":{"id":"j9KI9Yg5Dpc-"}},{"cell_type":"markdown","source":["### DeepPose\n","딥러닝 이전의 전통적 pose estimation 모델은 분명한 한계가 있었다. deformable parts model 논문에서 언급했듯이 graphical tree model은 같은 이미지에 두 번 연산을 하는 등 연산 효율이 떨어지는 점과 그에 비해서도 부족한 성능이 문제점으로 인식되어 왔다.\n","\n","AlexNet 이후, 다양한 분야에 CNN이 적용되면서 pose estimation 분야에도 CNN을 이용한 방법이 나타나기 시작했다. Toshev and Szegedy는 처음으로 딥러닝 기반 keypoint localization 모델을 제안했다.\n","- [DeepPose: Human Pose Estimation via Deep Neural Networks](https://arxiv.org/pdf/1312.4659.pdf)\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/original_images/06_ihhZoAI.png)\n","\n","기존 기술로 풀기 어려웠던 동작의 다양성, invisible joint의 문제를 언급하며 딥러닝 기반 추론 방법이 해결책이 될 수 있다는 것을 증명했다.\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/original_images/07_GOoFtrb.png)\n","\n","초기의 pose estimation 모델은 x, y 좌표를 직접적으로 예측하는 position regression 문제로 인식했다. human detection을 통한 crop된 사람 이미지를 이용해서 딥러닝 모델에 입력하고 (x,y) 좌표를 출력하도록 만든다.\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/original_images/08_iBnIDWo.png)\n","\n","DeepPose는 매우 혁신적인 시도였지만 사실 성능이 압도적으로 높았던 것은 아니다.   \n","표에서 볼 수 있듯이 DeepPose가 전반적으로 높은 성능을 나타내고 있긴 하지만 기존 Tree based model인 Wang et al.의 방법에 비해 비약적으로 성능 향상이라 말하기 어렵다. DeepPose의 기여는 SOTA에 가까운 성능을 내면서 딥러닝을 적용한 첫 번째 사례라고 할 수 있다."],"metadata":{"id":"V5UkyBdiFYf2"}},{"cell_type":"markdown","source":["### Efficient Object Localization Using Convolutional Network\n","DeepPose는 딥러닝을 사용했는데 왜 성능이 비약적으로 상승하지 않았을까?\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/09_NSfxHyY.max-800x600.png)\n","\n","Tompson이 제안한 Efficient object localization 방법을 알아보자.   \n","이 논문에서는 제안했던 모델도 DeepPose에 비해 깊어졌지만, 가장 중요한 건 keypoint의 위치를 직접 예측하기보다 keypoint가 존재할 확률 분포를 학습하게 하자는 점이다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/10_SBHBawM.max-800x600.png)\n","\n","human pose(keypoint)도 사람이 labeling을 할 수 밖에 없는데 사람이 항상 같은 위치의 점을 찍을 수 있을까?   \n","아까 위의 gif를 보면 kalman filter라고 적힌 동영상에 비해 orig measured는 점이 굉장히 떨리고 있다. 항상 같은 위치라고 생각하면서 keypoint를 선택하지만 사실 매 사진마다 수 픽셀씩 차이가 생기고 있다.\n","\n","자연상태에서 일어나는 확률 분포는 가우시안 분포일 가능성이 크다. Tompson은 이런 점에 착안하여 label을 (x,y) 좌표에서 (x,y)를 중심으로 하는 heatmap으로 변환했다. 딥러닝 모델은 이 heatmap을 학습하게 되는 것이다.\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/original_images/11_bVXlDCF.png)\n","\n","keypoint가 존재할 확률을 학습하게 된 이후로 성능이 비약적으로 향상되는 모습을 볼 수 있다.\n","\n","Toskev가 제안한 DeepPose에 비해 2배가 넘는 수치를 볼 수 있다. 머리의 경우 0.9가 넘는 높은 성능을 갖게 됐다."],"metadata":{"id":"9uw69NpnYM6V"}},{"cell_type":"markdown","source":["![](https://d3s0tskafalll9.cloudfront.net/media/images/12_VPfjvOz.max-800x600.png)\n","\n","MPII 데이터는 2014년에 나왔다. 기존 FLIC 데이터가 머리, 어깨, 팔꿈치, 손목 수준의 적은 keypoint를 갖고 있었지만 MPII는 몸의 각 관절 불위 16개의 keypoint를 갖는다. 기존 논문(Gkioxari, Sapp)들이 일부 데이터가 없는 이유이다. MPII는 실습에서 자세히 다뤄보자.\n","\n","Tompson이 제안한 방법은 heatmap 학습뿐만이 아닌 모델에서도 개선을 이뤘다.\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-9-L-Casecaded.max-800x600.png)\n","\n","사진을 살펴보면 coarse model과 fine model로 나누어지는데 coarse model에서 32x32 heatmap을 추출한 후 multi resolution 입력을 coarse heatmap 기준으로 crop한 후에 fine model에서 refinement를 수행한다.\n","\n","그리고 coarse model과 fine model이 같은 모델로 weight를 공유한다. 목적이 같아 빠른 학습이 가능하고 메모리, 저장공간을 효율적으로 사용할 수 있다."],"metadata":{"id":"cC73u9FUZkNB"}},{"cell_type":"markdown","source":["# 15-5. human keypoint detection(2)"],"metadata":{"id":"vqBbEQwP4pQj"}},{"cell_type":"markdown","source":["### Convolutional Pose Machines\n","CVPR 2016에서 발표한 CPM은 completely differentiable한 multi-stage 구조를 제안했다.   \n","해당 방법들은 DeepPose부터 지속적으로 사용되어 왔었다. 하지만 crop 연산 등 비연속적인 미분 불가능한 stage 단위로 나눠져 있었기 때문에 학습 과정을 여러 번 반복하는 비효율적인 방법을 사용했다.\n","- [Convolutional Pose Machines](https://arxiv.org/pdf/1602.00134.pdf)\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/13_wp3QD5J.max-800x600.png)\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/14.max-800x600.png)\n","\n","CPM은 end-to-end로 학습할 수 있는 모델을 제안한다.\n","\n","Stage 1은 image feature를 계산하는 역할이고 stage 2는 keypoint를 예측하는 역할을 한다.   \n","g1, g2 모두 heatmap을 출력하게 만들어서 재사용이 가능한 부분은 weight sharing 할 수 있도록 세무 모델을 설계했다.\n","\n","Stage >= 2에서 볼 수 있듯이 stage 2 이상부터는 반복적으로 사용할 수 있다. 보통 3개의 스테이지를 사용한다고 한다.   \n","stage 1 구조는 고정, stage 2부터는 해당 구조를 반복해서 추론한다. stage 2부터는 입력이 heatmap(image feature)이 되기 때문에 stage 단계를 거칠수록 keypoint가 refinement가 되는 효과를 볼 수 있다.\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/15.max-800x600.png)\n","\n","CPM이 아주 좋은 방법은 아니다 Multi-stage 방법을 사용하기 때문에 end-to-end로 학습이 가능하더라도 그대로 학습하는 경우는 높은 성능을 달성하기 어렵다.   \n","따라서 stage 단위로 pretraining을 한 후에 다시 하나의 모델로 합쳐서 학습을 한다. 논문을 작성하기 위해 충분히 감내할 수 있지만 서비스 측면에서는 불편한 요소이다. 이러한 문제점들은 후에 제안되는 모델들이 적극적으로 개선하고 있다."],"metadata":{"id":"l7O9p2oQbd1s"}},{"cell_type":"markdown","source":["![](https://d3s0tskafalll9.cloudfront.net/media/images/16.max-800x600.png)\n","\n","CPM을 다루는 이유는 성능 때문이다. receptive field를 넓게 만드는 multi stage refinement 방벙비 성능 향상에 크게 기여한 것 같다.   \n","주황색 실선이 Tompson 알고리즘이다. CPM에서 제안한 검정색, 회색 실선이 detection rate에서 유의미한 차이를 보이고 있다. MPII의 PCKh@0.5에서 87.95%를 달성했다고 한다. 당시 2등보다 6.11%p 높은 성능을 보였다."],"metadata":{"id":"lSxNqGp6gzLe"}},{"cell_type":"markdown","source":["### Stacked Hourglass Network\n","ECCV16에서 DeepPose 이후 랜드마크라고 불릴만한 논문이 제안되었다. [Stacked Hourglass Networks for Human Pose Estimation](https://arxiv.org/pdf/1603.06937.pdf)이다."],"metadata":{"id":"QVZ2YLXpbgbx"}},{"cell_type":"markdown","source":["__Hourglass__   \n","Stacked hourglass Network의 기본 구조는 모래시계와 같은 모양으로 만들어져 있다. Conv layer와 pooling으로 이미지(feature)를 인코딩하고 upsampling layer를 통해 feature map의 크기를 키우는 방향으로 decoding한다.   \n","feature map의 크기가 작아졌다가 커지는 구조여서 hourglass라고 표현한다.\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/17.max-800x600.png)\n","\n","기존 방법들과 가장 큰 차이점은 feature map upsampling, residual connection이다.\n","\n","pooling으로 image의 global feature를 찾고 upsampling으로 local feature를 고려하는 아이디어가 hourglass의 핵심 novelty라고 할 수 있따.   \n","hourglass의 모델 구조는 U-Net과 비슷하다. 간단한 구조를 여러 층으로 쌓아올려서 human pose estimation의 성능을 향상시켰다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/18.max-800x600.png)\n","\n","MPII에서 처음으로 PCKh@0.5 기준 90%를 넘어서는 성과를 보이게 된다. 특유의 간단한 구조와 높은 성능으로 현재까지도 많이 사용되고 있는 구조이다."],"metadata":{"id":"opaOxSYChS3v"}},{"cell_type":"markdown","source":["### SimpleBaseline\n","앞서 소개한 연구들은 딥러닝 기반 2D human pose estimation이 어떻게 발전했는지 보여주고 있다. (x, y)를 직접 regression 하는 방법이 heatmap 기반으로 바뀌고 모델의 구조가 바뀌면서 encoder-decoder가 쌓여가는 형태가 완성됐다.\n","\n","결과적으로 MPII에서 90%를 넘길 정도로 좋아졌지만 모델의 구조는 복잡해졌다.   \n","HPE의 연구를 하던 당시 microsoft 인턴 Haiping Wu는 다른 시각으로 보기 시작했다. \"기술 자체가 많이 발전했는데 현재의 간단한 모델은 얼마나 성능이 좋을까?\"   \n","\n","[SimpleBase](https://arxiv.org/pdf/1804.06208.pdf)의 저자는 아주 간단한 encoder-decoder 구조를 설계한다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/19.max-800x600.png)"],"metadata":{"id":"5tRaR_3Tbjhs"}},{"cell_type":"markdown","source":["해당 구조로 73.7%의 AP를 COCO에서 달성한다. 직전 연도 2017년의 72.1% 결과를 뛰어넘는 수치이다. 해당 성과로 ECVV'18에 출판됐다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/20.max-800x600.png)\n","\n","COCO에서 mAP 구치를 확인할 수 있다. 직전에 나온 hourglass와 비교해보면 다음과 같은 결과가 나온다고 한다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/21.max-800x600.png)\n","\n","resnet-50만 사용하던 간단한 구조가 hourglass와 같은 SOTA를 이겼다는 것에 큰 파장을 가져온 논문이라 생각한다.\n","\n","CPN은 Cascaded Pyramid Network이라는 모델이다. skip connection이 stage 사이에 연결되어 있다는 정도만 이해하고 넘어가자.   \n","\n","다음 스텝에서 코드와 함께 살펴보자."],"metadata":{"id":"_dkwk19ykD3l"}},{"cell_type":"markdown","source":["### Deep High-Resolution Network(HRNet)\n","[HRNet](https://arxiv.org/pdf/1902.09212.pdf)은 개발된 이후 현재까지 SOTA에 가까운 성능을 보일정도로 좋은 알고리즘이다. Simplebaseline의 1저자가 참여해 연구한 모델로 Simplebaseline과 같은 철학을 공유한다.\n","\n","Stacked hourglass, Casecaded pyramid network 등은 multi-stage 구조로 이루어져 있어 학습과 추론 속도가 느리다는 큰 단점이 있다.(대신 하이퍼파라미터를 최적화 할 경우 1-stage 방법보다 성능이 좋다.)   \n","반면 Simplebaseline과 HRNet은 간단하는 추구하는 만큼 1-stage를 고수한다. 덕분에 구조도 간결해지고 사용하기도 쉽다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/22.max-800x600.png)\n","\n","COCO dataset에서 한때 SOTA 성능을 자랑했다."],"metadata":{"id":"y0Nk5cf9bl6L"}},{"cell_type":"markdown","source":["![](https://d3s0tskafalll9.cloudfront.net/media/images/23.max-800x600.png)   \n","1-stage에서 어떻게 모델을 변화 시켰을까? 기존 알고리즘을 먼저 살펴보자.   \n","a는 Hourglass, b는 CPN(cascaded pyramid networks), c는 simplebaseline - tranposed conv, d는 simplebaseline - dilated conv를 나타냈다.\n","\n","c, d의 simplebaseline은 다른 알고리즘에 비해 성능이 떨어지진 않지만 구조적으로 공통점과 차이점을 관찰할 수 있다.   \n","공통점으로는 high -> low resolution인 encoder와 low -> high인 decoder 구조로 이루어져있다.   \n","차이점은 encoder가 resnet50같은 backbone을 사용하면서 skip connection을 사용하면서 encoder가 무섭지만 simplebaseline은 skip connection이 없다.\n","\n","그렇다면 왜 사용하지 않았을까?   \n","pooling을 할 때 소실되는 정보를 high level layer에서 사용하여 detail한 정보를 학습하기 위해 사용한다. 하지만 당연히 사용할 때 성능이 더 좋다.\n","\n","HRNet의 저자도 위 질문에 대해 고민을 했다. high -> low -> high 구조에서 high resolution representation을 유지할 수 있는 모델을 어떻게 만들 수 있을까?   \n","![](https://d3s0tskafalll9.cloudfront.net/media/original_images/24.png)\n","\n","고민의 결과 down sample layer를 만들고 작아진 layer feature 정보를 다시 up sampling을 통해 원본 해상도 크기에 적용하는 모델을 제안했다.   \n","다소 복잡해 보이지만 1-stage로 동작하기 때문에 전체 flow를 보면 엄청 간단하다.   \n","앞에서 다뤘던 CPM이나 Hourglass는 중간 단계의 heatmap supervision이 학습 과정에 꼭 필요했는데 HRNet은 필요가 없다.\n","\n","구현도 Simplebaseline의 backbone인 ResNet을 HRNet으로 교체만 해주면 되기 떄문에 사용하기도 굉장히 편리하다.\n","HRNet 또한 이전 알고리즘들과 마찬가지로 heatmap을 regression 하는 방식으로 학습하고 MSE loss를 이용한다.(simplebaseline과 거의 유사하다)\n","\n","![](https://d3s0tskafalll9.cloudfront.net/media/images/25.max-800x600.png)\n","\n","결과를 보면 HRNet이 4%에 가까운 비약적인 성능 향상을 이뤄냈다. 비교적 학습이 간단하면서 성능까지 좋은 모델이라 현재도 많이 사용되고 있다.   \n","원저자의 pytorch 코드가 매우 깔끔하게 구현되어 있어 재생산성이 높아 사용하기 좋다.   \n","- [https://github.com/leoxiaobin/deep-high-resolution-net.pytorch](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)"],"metadata":{"id":"2JUhWkUdlNiw"}},{"cell_type":"markdown","source":["# 15-6. 코드로 이해하는 pose estimantion"],"metadata":{"id":"bJPcQCVG42Vx"}},{"cell_type":"markdown","source":["오늘 본 6개의 모델 중 가장 간단한 모델인 SimpleBaseline 모델 부분만 정확하게 구현하여 이해해보자."],"metadata":{"id":"t3qJfS3dsHY6"}},{"cell_type":"markdown","source":["### SimpleBaseline 구조\n","![](https://d3s0tskafalll9.cloudfront.net/media/original_images/26.png)\n","\n","encoder는 conv layers, decoder는 deconv module + upsampling으로 이루어져 있다.   \n","\n","해당 conv layer가 어떻게 이루어져 있는지, devonv module은 어떻게 되어 있는지, deconv module 이 그림처럼 3개일지는 논문을 읽어봐야 알 수 있다.   \n","[Simple Baselines for Human Pose Estimation and Tracking](https://arxiv.org/pdf/1804.06208.pdf)"],"metadata":{"id":"A3jP7FBOsNh8"}},{"cell_type":"markdown","source":["backbone으로 resnet을 사용한다.   \n","deconv module은 deconv-Batch-relu가 3개로 이루어져 있다. deconv는 256 filter, 4x4 kernel, stride 2로 2배씩 feature map이 커진다.   \n","마지막 출력 레이어는 $k$개의 1x1 conv layer로 heatmap을 generate predicted한다."],"metadata":{"id":"StemTYues-xP"}},{"cell_type":"markdown","source":["### PyTorch code 읽어보기\n","[https://github.com/Microsoft/human-pose-estimation.pytorch](https://github.com/Microsoft/human-pose-estimation.pytorch)\n","\n","논문도 모든 디테일을 설명해주지 않는다. 인공지능 분야의 최대 장점은 저자의 공식 코드가 제공된다는 점이다.   \n","simplebaseline의 저자도 논문에서 코드 repo의 위치를 언급했다.\n","\n","18년 이후 pytorch의 성장으로 절반 이상의 오픈소스가 파이토치로 공개되고 있다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/27.max-800x600.png)   \n","주요 컨퍼런스의 pytorch, tensorflow의 성장률이다. 연구 분야에서 pytorch가 압도적으로 많이 사용되고 있다.\n","\n","[microsoft/human-pose-estimation.pytorch](https://github.com/microsoft/human-pose-estimation.pytorch/blob/master/lib/models/pose_resnet.py) 모델 부분을 읽어보자.\n","\n","`nn` 표현이 많이 등장한다. `torch.nn`으로 `keras.layers`와 같이 딥러닝 모델 구성에 필요한 도구들이 정의되어 있다.   \n","29번째 줄 BasicBlock 클래스가 있다. keras.models로 model을 선언하는 것과 비슷하다.   \n","\n","pytorch model에서는 사용된 layer를 forward 함수를 통해 computational graph를 그려준다.   \n","\n","42번째 줄 forward 함수는 residual block을 사용했다.   \n","\n","157번째 줄을 보면 메인 model에 4개의 residual block을 이용한다. 이는 resnet과 동일하다."],"metadata":{"id":"PE-DNEjHwNDt"}},{"cell_type":"markdown","source":["```\n","def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.deconv_layers(x)\n","        x = self.final_layer(x)\n","\n","        return x\n","```\n","\n","forward 함수를 봤을 때 resnet을 통과한 후 `deconv_layers`와 `final_layer`를 차례로 통과한다.\n","\n","219번째 줄의 deconv layer를 보면   \n","```\n","        layers.append(\n","                nn.ConvTranspose2d(\n","                    in_channels=self.inplanes,\n","                    out_channels=planes,\n","                    kernel_size=kernel,\n","                    stride=2,\n","                    padding=padding,\n","                    output_padding=output_padding,\n","                    bias=self.deconv_with_bias))\n","            layers.append(nn.BatchNorm2d(planes, momentum=BN_MOMENTUM))\n","            layers.append(nn.ReLU(inplace=True))\n","```\n","transpose conv와 bn, relu로 이루어져 있는 것을 확인할 수 있다.   \n","\n","세세한 파라미터는 EXTRA가 자주 등장하는걸 봤을 때, 어떤 configuration 파일이 있을 것으로 짐작해볼 수 있다. repo에서 검색해보면 파라미터 관련 정보를 담고 있는 파일을 찾을 수 있다.   \n","[https://github.com/microsoft/human-pose-estimation.pytorch/blob/master/experiments/coco/resnet50/256x192_d256x3_adam_lr1e-3.yaml#L23](https://github.com/microsoft/human-pose-estimation.pytorch/blob/master/experiments/coco/resnet50/256x192_d256x3_adam_lr1e-3.yaml#L23)\n","\n","```\n","NUM_DECONV_LAYERS: 3\n","    NUM_DECONV_FILTERS:\n","    - 256\n","    - 256\n","    - 256\n","    NUM_DECONV_KERNELS:\n","    - 4\n","    - 4\n","    - 4\n","```\n","deconv layer의 파라미터가 상세하게 적혀있다.\n","\n","이렇게 simplebaseline의 모델을 상세하게 파악할 수 있었다.\n","\n","192x256의 이미지가 입력될때 renset 출력이 6x8이 나오고 3개의 deconv layer를 통과해 48x64가 출력된다."],"metadata":{"id":"T2xSl1urxxPL"}},{"cell_type":"markdown","source":["### simplebaseline - tf2\n","파악한 지식을 토대로 tensorflow simplebaseline 모델을 만들어보자."],"metadata":{"id":"M_fu4pkQ3aec"}},{"cell_type":"code","source":["import os\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","resnet = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KFvAXH53gHX","executionInfo":{"status":"ok","timestamp":1650439664251,"user_tz":-540,"elapsed":5930,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"e93f273f-961c-4dd2-df34-0221eadcb206"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n","94781440/94765736 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["upconv1 = tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same')\n","bn1 = tf.keras.layers.BatchNormalization()\n","relu1 = tf.keras.layers.ReLU()\n","upconv2 = tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same')\n","bn2 = tf.keras.layers.BatchNormalization()\n","relu2 = tf.keras.layers.ReLU()\n","upconv3 = tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same')\n","bn3 = tf.keras.layers.BatchNormalization()\n","relu3 = tf.keras.layers.ReLU()"],"metadata":{"id":"WNYIs0gc3hnf","executionInfo":{"status":"ok","timestamp":1650439664251,"user_tz":-540,"elapsed":4,"user":{"displayName":"노현호","userId":"15410213599666758892"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["deconv module 중복을 제거해보자."],"metadata":{"id":"8MXy1lrH3mRA"}},{"cell_type":"code","source":["def _make_deconv_layer(num_deconv_layers):\n","    seq_model = tf.keras.models.Sequential()\n","    for i in range(num_deconv_layers):\n","        seq_model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same'))\n","        seq_model.add(tf.keras.layers.BatchNormalization())\n","        seq_model.add(tf.keras.layers.ReLU())\n","    return seq_model\n","\n","upconv = _make_deconv_layer(3)"],"metadata":{"id":"NG_NlYAP3o6k","executionInfo":{"status":"ok","timestamp":1650439694771,"user_tz":-540,"elapsed":6,"user":{"displayName":"노현호","userId":"15410213599666758892"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["final_layer = tf.keras.layers.Conv2D(17, kernel_size=(1,1), padding='same')"],"metadata":{"id":"GdzO1ilx3qg4","executionInfo":{"status":"ok","timestamp":1650439694771,"user_tz":-540,"elapsed":5,"user":{"displayName":"노현호","userId":"15410213599666758892"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(256, 192, 3))\n","x = resnet(inputs)\n","x = upconv(x)\n","out = final_layer(x)\n","model = keras.Model(inputs, out)\n","\n","model.summary()"],"metadata":{"id":"9T56rezp3tUq","executionInfo":{"status":"ok","timestamp":1650439695704,"user_tz":-540,"elapsed":937,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"fbdfef24-5f9c-402a-cedb-732e6ae2983c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 256, 192, 3)]     0         \n","                                                                 \n"," resnet50 (Functional)       (None, None, None, 2048)  23587712  \n","                                                                 \n"," sequential (Sequential)     (None, 64, 48, 256)       10489600  \n","                                                                 \n"," conv2d (Conv2D)             (None, 64, 48, 17)        4369      \n","                                                                 \n","=================================================================\n","Total params: 34,081,681\n","Trainable params: 34,027,025\n","Non-trainable params: 54,656\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["가상의 이미지를 넣어 출력이 잘 되는지 확인해보자."],"metadata":{"id":"1C5vwmNs3v3Y"}},{"cell_type":"code","source":["np_input = np.zeros((1,256,192,3), dtype=np.float32)\n","tf_input = tf.convert_to_tensor(np_input, dtype=tf.float32)\n","print('input shape')\n","print (tf_input.shape)\n","print('\\n')\n","\n","tf_output = model(tf_input)\n","print('output shape')\n","print (tf_output.shape)\n","print (tf_output[0,:10,:10,:10])"],"metadata":{"id":"K7rg-lb13xfr","executionInfo":{"status":"ok","timestamp":1650439697106,"user_tz":-540,"elapsed":1406,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"054cbc9d-cbb5-48ff-b489-f46869783ffe","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["input shape\n","(1, 256, 192, 3)\n","\n","\n","output shape\n","(1, 64, 48, 17)\n","tf.Tensor(\n","[[[ 1.12301810e-03  7.55356438e-03 -5.85100148e-03 -3.13820178e-03\n","   -7.37525849e-03 -2.96494062e-03  2.81174690e-03  6.87631546e-04\n","   -3.69152956e-04 -3.69123212e-04]\n","  [ 1.28022570e-03  1.68429445e-02 -1.87815186e-02  6.31378731e-03\n","    4.82132472e-03  6.44772779e-03 -1.59344543e-02  1.15692290e-02\n","   -4.74173529e-03 -8.99400096e-03]\n","  [-4.38117702e-03  2.58055832e-02 -7.25149410e-03  8.48388113e-03\n","   -3.30337323e-03 -1.30864577e-02  8.41084868e-03  1.08793154e-02\n","    1.81287667e-03  8.86158179e-03]\n","  [ 1.63132045e-02  9.74918995e-03 -1.93835236e-02  6.73894165e-03\n","   -1.78277753e-02  1.76498871e-02 -9.43202991e-03 -1.07784765e-02\n","   -2.23322995e-02  1.56888962e-02]\n","  [ 5.59044478e-04  5.55235185e-02 -2.42329743e-02  5.49104484e-03\n","   -1.16721243e-02 -5.55089163e-03  2.89102987e-04  5.92886051e-03\n","   -6.18943246e-03 -8.07856675e-03]\n","  [ 6.78506587e-03  1.85557567e-02 -1.32298907e-02  4.15522978e-03\n","   -2.04379577e-02  7.09541515e-03 -1.24543095e-02  2.63414532e-03\n","    4.00623493e-03 -2.59500351e-02]\n","  [ 8.14686995e-03  4.28560283e-03 -2.39498094e-02  8.74537975e-04\n","    2.16858052e-02 -1.13937650e-02 -1.38031347e-02  1.00710373e-02\n","    2.24265223e-03 -3.89984692e-03]\n","  [ 9.39277094e-03  3.02072931e-02 -1.13559142e-02 -7.83770066e-03\n","   -1.31413480e-02  1.10299699e-02 -1.45481937e-02  1.04233408e-02\n","   -1.21029641e-03 -7.55659770e-03]\n","  [-5.83087234e-03  2.99468432e-02 -1.64810810e-02 -4.65624547e-03\n","    5.72632824e-04 -2.94714049e-03  3.39814089e-03  1.59938503e-02\n","    6.49820082e-03 -1.47273717e-03]\n","  [ 1.14828423e-02  7.10486434e-03 -1.46589484e-02 -2.65776250e-03\n","   -5.46364160e-03  1.25861606e-02 -2.51622740e-02  1.97163522e-02\n","    5.63060679e-03 -1.81110315e-02]]\n","\n"," [[ 1.87482517e-02  7.58780586e-03  5.30824997e-03  7.88299646e-03\n","   -2.16415548e-03  8.32419004e-03 -9.09768860e-04 -6.61544083e-03\n","    8.96910205e-03 -7.79809570e-03]\n","  [ 2.85924561e-02  1.74818262e-02 -3.55152860e-02 -1.50205875e-02\n","   -2.61711366e-02  1.82964280e-02  2.80713532e-02  1.34498999e-02\n","    1.46059189e-02  8.37525527e-04]\n","  [ 7.17718713e-03  4.07182053e-02 -2.98686232e-02  1.91697963e-02\n","   -1.48819825e-02  2.24902984e-02 -1.74835045e-02  2.47519184e-02\n","    2.48163044e-02  2.18182132e-02]\n","  [ 1.27670858e-02  1.75380390e-02 -2.37547662e-02 -5.28569408e-02\n","    7.44711375e-03  3.18976305e-02  1.79491509e-02 -1.90396495e-02\n","    2.88240612e-02 -2.70835776e-03]\n","  [-1.61510967e-02  4.16648574e-02 -8.25453177e-03 -3.53413145e-03\n","   -4.31282967e-02  4.31701094e-02 -2.44694743e-02  1.53010441e-02\n","    1.20806126e-02 -5.43378480e-03]\n","  [ 4.86071445e-02  2.96981558e-02 -4.93159443e-02 -2.60844100e-02\n","   -1.02739362e-02  1.45769976e-02  5.10983309e-03 -5.37347887e-03\n","    1.11493552e-02  1.91213302e-02]\n","  [ 5.05202450e-02  6.39222488e-02 -5.12719564e-02 -5.05639426e-03\n","   -3.74458656e-02  1.40210064e-02 -3.10241673e-02  5.59158809e-03\n","    1.34965070e-02 -2.16864459e-02]\n","  [ 5.47913723e-02 -2.80390354e-03 -4.10380177e-02  9.62287188e-03\n","    1.19209359e-03  3.82818468e-02  3.18940654e-02 -1.96339637e-02\n","    1.45302787e-02 -2.04437450e-02]\n","  [-1.64374523e-02  8.42053369e-02  2.01545600e-02  2.14312635e-02\n","   -3.79358009e-02  2.51895823e-02  8.83349124e-03 -2.25616973e-02\n","    2.22604740e-02  8.68140161e-03]\n","  [ 4.30170260e-02  4.62811440e-02 -3.87359820e-02 -3.11317649e-02\n","   -6.50963467e-03  2.10241228e-02  4.70763445e-02  2.79805847e-02\n","    2.47148536e-02 -3.31042218e-04]]\n","\n"," [[-5.42848092e-03  8.65802914e-03 -1.76061150e-02  1.08128469e-02\n","    7.20072247e-04 -2.75062630e-03  2.36981735e-03 -3.03548877e-03\n","    2.13078875e-03  6.62189722e-03]\n","  [-7.29732262e-03  6.15477301e-02 -4.64744009e-02 -2.99012978e-02\n","   -3.70783545e-02  2.18940433e-02 -1.76641550e-02 -1.42477490e-02\n","    2.40249000e-02 -1.48040410e-02]\n","  [-6.50709728e-03  2.95270532e-02 -3.05425506e-02  4.26926315e-02\n","    1.86321493e-02 -3.85725382e-03 -1.38795860e-02 -2.00736448e-02\n","    1.59413423e-02  5.11864945e-03]\n","  [ 3.32306102e-02  1.29696773e-02 -4.59103547e-02  1.65755618e-02\n","   -5.11526763e-02  3.06243333e-03 -4.98625599e-02  1.77697297e-02\n","    8.72711744e-03 -2.85583977e-02]\n","  [ 7.29322713e-03  2.08453387e-02 -5.05799763e-02  5.00282831e-03\n","   -2.30399463e-02 -5.65155363e-03 -1.43227754e-02 -3.30296718e-02\n","    5.83366072e-03 -7.89042376e-03]\n","  [ 8.32762197e-03  2.44452059e-02 -3.44282500e-02 -1.19995335e-02\n","   -3.79449204e-02  4.54518711e-03 -3.06978989e-02  2.95663066e-03\n","    1.23423710e-02 -1.05785280e-02]\n","  [ 3.68671343e-02  2.81207915e-02 -5.92587516e-03  2.54639275e-02\n","    1.30127911e-02  3.38590294e-02  1.19940266e-02 -2.62241531e-02\n","   -1.09416014e-02 -4.86501353e-03]\n","  [ 4.23956141e-02  2.41112337e-02 -4.05301340e-02 -3.18148397e-02\n","   -1.94431785e-02  3.06509659e-02  2.19452195e-02  4.45801876e-02\n","    2.50920877e-02 -1.29264006e-02]\n","  [-1.09247183e-02  4.31124754e-02 -3.36099043e-02  4.07969840e-02\n","   -2.51218174e-02  1.28766866e-02 -2.61786859e-02 -5.08777983e-03\n","    2.95468736e-02  3.18575576e-02]\n","  [ 6.57477975e-03  7.10317120e-02 -5.41877411e-02 -3.29212956e-02\n","   -5.24749979e-02  3.23923267e-02 -1.98975913e-02  1.84400789e-02\n","    1.18844388e-02 -2.26578899e-02]]\n","\n"," [[ 2.54517552e-02  1.11383600e-02 -6.37559267e-03  1.18036177e-02\n","    1.72970630e-03  6.98315864e-03 -7.68617203e-04  1.27465965e-03\n","    1.50730200e-02  3.68748442e-03]\n","  [ 6.66487440e-02  2.34489609e-02 -4.64316681e-02  9.38141346e-03\n","   -2.18413677e-03  9.95066389e-03  5.37513755e-02 -1.69773796e-03\n","    1.27214584e-02 -6.32662850e-04]\n","  [ 3.09379329e-03  4.16107550e-02 -3.30557786e-02 -5.67359803e-03\n","   -3.14700156e-02  6.84277911e-04 -2.76044384e-03 -3.02339415e-03\n","    1.29863694e-02  2.52412669e-02]\n","  [ 3.64140011e-02  9.00631864e-03 -4.06222343e-02  3.05714924e-03\n","   -3.01143732e-02  1.42401196e-02  2.78439410e-02  2.60205716e-02\n","    5.83695807e-02 -4.26064394e-02]\n","  [ 2.74764206e-02  5.71778230e-02 -3.08879800e-02 -6.19135518e-03\n","   -3.14100459e-02  2.72920448e-02 -1.60270687e-02  3.73728573e-02\n","    2.20585093e-02  1.37936240e-02]\n","  [ 4.21846807e-02  1.13636060e-02 -6.14988580e-02  2.56610662e-02\n","   -1.24286627e-02  9.81756579e-03  2.30466705e-02 -3.08353212e-02\n","    9.19584781e-02 -5.67201804e-03]\n","  [ 1.64907165e-02  1.66471023e-02 -3.68572399e-02 -9.96725401e-04\n","   -4.59387973e-02  2.27761120e-02 -1.69544928e-02  1.14243394e-02\n","   -1.13458494e-02  1.22543527e-02]\n","  [ 2.81711686e-02  1.05812736e-02 -7.01785833e-02 -7.30515318e-03\n","   -2.40324195e-02  3.38193886e-02  5.23820855e-02 -4.99259727e-03\n","    6.39851466e-02 -5.41666336e-02]\n","  [ 5.85386865e-02  8.40518251e-02 -5.15680462e-02 -1.66234132e-02\n","   -1.29290484e-02  2.08997596e-02  1.70735829e-02 -1.25181135e-02\n","    6.21366017e-02  1.57025252e-02]\n","  [ 8.09672847e-02  3.15086916e-02 -5.19002266e-02  1.98789146e-02\n","    1.44820511e-02  4.42331396e-02  5.46290837e-02  1.32198604e-02\n","    5.49021736e-02  8.58315919e-03]]\n","\n"," [[-2.25466513e-03  1.67156085e-02 -2.10780576e-02  8.76685511e-03\n","   -1.16865253e-02 -1.78746171e-02 -1.81030855e-03 -1.50075005e-02\n","    1.92638841e-02  8.84767808e-03]\n","  [ 3.80500071e-02  6.21298291e-02 -5.78897037e-02  1.43362619e-02\n","   -2.27062721e-02  3.27045582e-02 -4.99446057e-02  4.53328118e-02\n","    5.20891920e-02  2.51051839e-02]\n","  [-7.91482348e-03  7.60158384e-03 -4.98975553e-02  3.62057574e-02\n","   -5.04187774e-04 -1.78953838e-02 -6.43128715e-03  1.59776341e-02\n","    2.81867106e-02 -3.47462110e-02]\n","  [ 2.70557329e-02  3.55517939e-02 -4.59326059e-02  1.92076173e-02\n","    3.40937171e-04  1.19465189e-02 -4.58431542e-02 -5.24448743e-03\n","    4.36761864e-02  2.27931682e-02]\n","  [ 2.84271291e-03  3.99743654e-02 -2.25246064e-02  3.94186303e-02\n","    2.73621120e-02  1.52065791e-02  9.85455816e-04  1.49724493e-02\n","    4.91082333e-02  2.63988357e-02]\n","  [-1.42842131e-02  6.26989752e-02 -3.52769718e-02 -7.76143651e-03\n","   -1.89185496e-02  2.65088305e-02 -3.18892337e-02  2.48639472e-02\n","   -1.59138311e-02 -6.94297254e-03]\n","  [-1.58585906e-02  3.72589454e-02 -3.88853513e-02  4.07280438e-02\n","    3.77596356e-02  1.60406400e-02  7.62824016e-03  4.05034190e-03\n","    2.79736798e-02 -1.68817397e-02]\n","  [ 2.02974249e-02  3.31557356e-02 -8.94511417e-02  2.59102397e-02\n","   -4.11354611e-03  2.42289696e-02 -5.35649918e-02  4.95321751e-02\n","    6.05341122e-02  4.51610610e-03]\n","  [-2.12193839e-02  2.94261649e-02 -5.86470217e-02  1.54203055e-02\n","    2.66874153e-02  8.64318106e-03 -2.03305762e-02  3.03913783e-02\n","    4.52723689e-02 -2.90909107e-03]\n","  [ 4.27425429e-02  5.78531660e-02 -5.08736446e-02 -9.96671338e-03\n","   -4.22730148e-02  4.59470861e-02 -7.59473965e-02  3.49889733e-02\n","    9.41084698e-02 -9.66808200e-03]]\n","\n"," [[ 5.91208274e-03  1.72934085e-02 -9.99369950e-05  7.70478463e-03\n","   -1.10355057e-02 -4.84757917e-03  4.70828643e-04  1.33370254e-02\n","    3.59241222e-03 -3.91724752e-03]\n","  [ 3.28758024e-02 -1.16262091e-02 -5.40913604e-02 -1.56951118e-02\n","   -4.39256430e-02  2.65897028e-02 -6.53648097e-03 -2.44225003e-02\n","    4.73226458e-02  1.62751712e-02]\n","  [ 3.18238214e-02  4.80608046e-02 -1.86005384e-02  3.86567041e-02\n","   -3.03149614e-02  1.78349875e-02 -1.67248640e-02  5.37833991e-03\n","    4.25209999e-02  1.35200024e-02]\n","  [ 3.11125256e-02 -2.51291431e-02 -4.72365059e-02 -2.57565174e-02\n","   -3.73076275e-02  4.20254096e-02  4.33691684e-03 -3.31021436e-02\n","    9.52049159e-03  1.85538884e-02]\n","  [ 1.92152821e-02  1.40274912e-02  3.05318851e-02 -4.20465358e-02\n","   -6.20811991e-02  2.39986684e-02 -2.96876188e-02  9.69225354e-03\n","   -1.63501482e-02 -6.05112780e-03]\n","  [ 4.72040959e-02  4.20105234e-02 -8.52106214e-02  1.09019072e-03\n","   -1.00348201e-02  4.57496531e-02  1.84861645e-02 -3.46740820e-02\n","    5.90944774e-02 -3.36364284e-02]\n","  [ 1.06422147e-02  1.48579851e-02 -6.80107921e-02 -9.20758117e-03\n","   -4.11387905e-02  6.29242416e-03 -3.00624669e-02  1.42130321e-02\n","    1.51427230e-02  5.84243275e-02]\n","  [ 4.40502204e-02  4.85602999e-03 -6.87403828e-02 -2.49762964e-02\n","   -9.04387608e-03  2.96635199e-02  5.85797429e-03 -3.16860974e-02\n","    4.61309664e-02 -4.94078584e-02]\n","  [ 1.51189137e-02  6.47528470e-02  9.95774567e-03  1.54332928e-02\n","   -6.57047927e-02  4.77511995e-02 -7.61329383e-03  2.84317210e-02\n","   -1.50774941e-02  2.37719659e-02]\n","  [ 3.45786214e-02  2.98189465e-02 -5.67868948e-02  1.23536009e-02\n","   -1.10562835e-02  2.56090332e-02  3.54533480e-03 -1.25727439e-02\n","    1.76615249e-02  3.12850326e-02]]\n","\n"," [[ 9.98242479e-03  2.68292148e-02 -2.26670671e-02  1.48387421e-02\n","    7.84580596e-03 -1.91441423e-03  4.01431601e-03 -1.31622814e-02\n","    8.83435924e-03 -2.07603839e-03]\n","  [ 2.26445738e-02  5.81219122e-02 -3.92247103e-02  1.00480055e-03\n","   -4.43557091e-02  3.05478964e-02 -3.43144648e-02 -1.35554373e-02\n","    1.47958174e-02 -1.93206072e-02]\n","  [ 1.96926296e-02  6.08315468e-02 -3.97839881e-02  7.62973875e-02\n","   -2.61202695e-05 -1.09777204e-03 -6.26884215e-03 -3.19572981e-03\n","    1.20905591e-02 -7.61411339e-03]\n","  [ 3.79791185e-02  4.61168885e-02 -4.36201133e-02  1.45725962e-02\n","   -1.87004916e-02  2.72370968e-02 -9.91112553e-03 -7.22195581e-03\n","    3.24269943e-02 -1.28184250e-02]\n","  [-3.42582562e-03  6.87062517e-02 -4.62325700e-02  2.14281701e-03\n","   -5.28917387e-02  2.50603203e-02 -3.13919224e-02 -2.08318625e-02\n","   -1.07639213e-03  2.70062294e-02]\n","  [ 7.41861342e-03  5.08007705e-02 -6.61788657e-02  9.97690205e-03\n","   -3.14674564e-02 -1.46942455e-02 -4.29615751e-02 -1.43925780e-02\n","    6.81774318e-02  2.98085157e-02]\n","  [ 8.48408863e-02  2.73942966e-02 -1.64993480e-02  4.72157411e-02\n","    9.54323541e-03  4.53357138e-02 -3.71959084e-03 -2.23949626e-02\n","    1.39949406e-02  1.94338989e-02]\n","  [ 8.49380624e-03 -5.94232045e-03 -2.93753501e-02 -2.32323352e-02\n","   -3.90522629e-02 -1.37471231e-02 -5.46969958e-02 -3.19170929e-03\n","    2.33794171e-02 -3.25887613e-02]\n","  [ 2.42557619e-02  2.47043110e-02 -3.00799198e-02  3.56806954e-03\n","    5.28820930e-03 -6.12513581e-03 -8.94949399e-03 -2.47059148e-02\n","    7.11346511e-03  4.17116610e-03]\n","  [-9.13851708e-03  5.09196520e-02 -8.78078192e-02 -1.39417360e-02\n","   -9.61659551e-02  4.27362584e-02 -3.21393125e-02  5.10521345e-02\n","    5.60150370e-02 -3.24728643e-03]]\n","\n"," [[ 2.66534109e-02  1.42466584e-02 -1.79782417e-02  1.21386452e-02\n","   -1.73767805e-02  8.60008644e-04  4.18709079e-03 -1.31951524e-02\n","    2.18150355e-02  2.55649746e-03]\n","  [ 5.15355654e-02  1.28127588e-02 -4.34606634e-02  1.37194889e-02\n","    2.39965972e-04  2.95409970e-02  3.16237845e-02 -2.77174506e-02\n","    2.88702454e-02 -1.35364803e-03]\n","  [ 2.47627217e-02  5.92623577e-02 -1.13529162e-02  2.37346068e-02\n","   -3.64061631e-02  3.11962496e-02  1.10341962e-02 -1.03614358e-02\n","    9.36244789e-04  3.80507037e-02]\n","  [ 4.56582084e-02  4.33198698e-02 -5.29467762e-02 -5.41198738e-02\n","   -5.87227270e-02  1.94950849e-02  3.93558070e-02  1.79396905e-02\n","    3.96283083e-02 -5.03166094e-02]\n","  [ 1.93914678e-02  3.27988267e-02 -7.25273695e-03  6.09215628e-03\n","   -4.13755365e-02 -5.52442390e-03 -5.86630718e-04  2.08116453e-02\n","    5.65687148e-03  1.49687156e-02]\n","  [ 9.68399346e-02  3.88586298e-02 -2.92599630e-02  6.58933120e-03\n","   -9.05309524e-03  5.90812676e-02  3.34032774e-02  1.08271111e-02\n","    6.19190410e-02 -3.83672956e-03]\n","  [ 2.23713238e-02  7.36840144e-02 -2.60197483e-02 -1.49101205e-03\n","   -4.84038778e-02  3.16808522e-02 -1.74278617e-02 -1.12481345e-03\n","    1.13839339e-02  2.72250921e-02]\n","  [-1.10180408e-03  2.84400564e-02 -7.66005218e-02 -6.42846758e-03\n","   -2.49558268e-03  3.82265449e-02  4.69159558e-02  4.20589447e-02\n","    1.07578719e-02  3.66438203e-03]\n","  [ 1.11415759e-02  5.74004017e-02 -1.60812493e-03  1.35283619e-02\n","   -5.91607690e-02 -1.86194573e-02 -3.45933475e-02  6.38461020e-03\n","    3.00063677e-02  4.98015725e-04]\n","  [ 5.63719012e-02 -3.63921747e-03 -3.75082232e-02  6.68647140e-03\n","   -3.34780291e-02  7.71347284e-02  1.83320493e-02 -2.97122505e-02\n","    4.72445637e-02 -3.24744545e-02]]\n","\n"," [[ 8.86030402e-03  6.20380463e-03 -7.26229791e-03  4.18336364e-03\n","   -6.92111673e-03 -4.08820197e-04  6.94487570e-03  4.81989142e-03\n","    6.17514923e-03  9.96681303e-03]\n","  [ 1.54723767e-02  3.25039960e-02 -6.22742735e-02  2.16345917e-02\n","   -3.55452001e-02 -5.42823505e-03 -6.54466823e-02  2.21951604e-02\n","    1.56672802e-02 -3.45844068e-02]\n","  [ 2.52406914e-02  4.70221527e-02 -4.78380658e-02  3.39336358e-02\n","    1.91876702e-02 -2.47866157e-02 -1.92843564e-02 -2.93775517e-02\n","    5.50752357e-02  1.11825550e-02]\n","  [-1.30559187e-02  3.83209065e-02 -7.70367682e-02 -2.02646479e-02\n","   -3.65108848e-02  2.44109635e-03 -3.16669345e-02  1.31128542e-03\n","    1.25116101e-02 -5.15760155e-03]\n","  [ 6.30792603e-03  5.63591719e-02 -1.56216254e-03  4.07710150e-02\n","    1.88410245e-02  6.88219722e-03 -4.91602626e-03 -3.32677849e-02\n","   -2.92026512e-02 -1.03348801e-02]\n","  [-5.57206746e-04  6.54309541e-02 -3.40980850e-02 -3.73088437e-06\n","    1.15292305e-02 -2.89217080e-03 -7.40462914e-02  7.90802017e-02\n","    4.00099009e-02 -5.10445833e-02]\n","  [ 1.73269901e-02  1.39796278e-02 -5.51542155e-02  3.50919329e-02\n","    1.66080892e-02 -2.79294699e-03 -1.75272897e-02 -7.69399432e-03\n","    1.82118360e-02 -1.32158585e-02]\n","  [ 1.88355539e-02  3.38468924e-02 -8.96879956e-02  1.35783013e-02\n","   -3.30844335e-03  2.08550449e-02 -7.82669261e-02  1.68858841e-02\n","    2.47981604e-02  2.82847742e-03]\n","  [-3.05118086e-03  3.92766595e-02 -2.24614087e-02  5.23083173e-02\n","    4.15935665e-02  1.94293577e-02 -3.71424221e-02  1.54032214e-02\n","    3.63971069e-02  1.44704394e-02]\n","  [ 3.41736749e-02  8.47209916e-02 -3.66912931e-02  5.46318432e-03\n","   -2.77068932e-02  2.47370470e-02 -7.32941926e-02 -1.75665468e-02\n","   -9.11453366e-03 -5.42706959e-02]]\n","\n"," [[ 5.72225591e-03  1.65423844e-02 -8.12793709e-03  8.21434334e-03\n","   -4.78303386e-03  3.96088697e-03  1.10547300e-02  4.21318458e-03\n","    9.35333408e-03  1.19068110e-02]\n","  [ 3.96715514e-02  8.94379988e-03 -4.34960090e-02 -1.30960438e-02\n","   -3.16575468e-02  1.65516101e-02 -2.33415049e-02 -7.00443343e-04\n","    3.12153269e-02 -1.64524000e-02]\n","  [ 3.19117680e-02  5.99092022e-02 -2.48167068e-02  1.84867252e-02\n","   -2.73467526e-02  2.95691490e-02 -3.17549519e-02  3.04287802e-02\n","    3.90601158e-02  2.14596801e-02]\n","  [ 1.83714107e-02  1.74480136e-02 -4.18762341e-02 -5.62856346e-02\n","    3.04422677e-02  4.65665758e-02  3.55460010e-02 -3.58509570e-02\n","    1.35557894e-02 -1.12663321e-02]\n","  [ 8.99965875e-03  5.82471415e-02  4.54571890e-03 -3.58290598e-02\n","   -3.74331623e-02  4.99518216e-02 -5.11289295e-03  5.43518141e-02\n","    7.64374156e-03  5.45879221e-03]\n","  [ 2.82745808e-02  3.11737806e-02 -4.92497459e-02  7.56426074e-04\n","   -2.56941151e-02  2.52867751e-02  3.73507999e-02 -1.20906038e-02\n","    6.84044848e-04  1.86393894e-02]\n","  [ 5.36345504e-02  6.83885738e-02 -7.22560808e-02 -1.38993673e-02\n","   -3.66916284e-02  3.17422375e-02 -3.21234763e-02  1.06559088e-02\n","   -1.09396065e-02 -4.34496626e-02]\n","  [ 4.50535193e-02  5.07069007e-03 -4.53112498e-02  9.80072655e-03\n","   -6.12285845e-02  5.57075553e-02  6.73691034e-02  5.56148868e-03\n","    2.91347392e-02  9.17059649e-03]\n","  [-1.62374470e-02  6.41823485e-02 -2.91106645e-02  1.26784632e-03\n","   -2.06938032e-02  1.70139857e-02  9.04515572e-03 -4.17984985e-02\n","   -3.62894610e-02  1.64194256e-02]\n","  [ 6.77298531e-02  1.47245266e-02 -5.99044114e-02 -6.84864214e-03\n","   -1.36962729e-02  3.40535771e-03  6.58429600e-03  2.87364256e-02\n","    5.10744713e-02 -1.92650594e-02]]], shape=(10, 10, 10), dtype=float32)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"3p7546NU3yo0"},"execution_count":null,"outputs":[]}]}