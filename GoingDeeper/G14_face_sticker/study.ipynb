{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"study.ipynb","provenance":[],"mount_file_id":"1xu94p3bRL3QNCS4sz8kx4LNZ-5FvK1o2","authorship_tag":"ABX9TyOJySEPHV73IfCtFNMRHeXS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 14. 멀리 있는 사람도 스티커를 붙여주자"],"metadata":{"id":"sDp6fEo8WPR0"}},{"cell_type":"markdown","source":["# 14-1. 들어가며"],"metadata":{"id":"PgyRsVwvWTN1"}},{"cell_type":"markdown","source":["### WIDER FACE 데이터셋\n","face detection 모델의 학습을 위해 [WIDER FACE 데이터셋](http://shuoyang1213.me/WIDERFACE/index.html)을 다룰 예정이다.   \n","빠른 YOLO, SSD같은 single stage model을 학습시키는 것은 흔히 COCO 데이터셋이 사용되겠지만, 먼 거리에 흩어져있는 여러 사람의 얼굴을 빠르게 detect하는 모델을 만들기 위해 보다 넓은 공간에서 다수의 사람이 등장하는 이미지 데이터셋이 적합하다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-11-P-00.max-800x600.png)"],"metadata":{"id":"RGC1PDdHYH4Z"}},{"cell_type":"markdown","source":["### 데이터셋 준비하기\n","WIDER FACE 데이터셋 홈페이지에 있는 4개의 zip파일을 사용할 예정이다.\n","\n","홈페이지의 Download에 해당한다.\n","- [WIDER Face Training Images Google Drive](https://drive.google.com/file/d/15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M/view)\n","- [WIDER Face Validation Images Google Drive](https://drive.google.com/file/d/1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q/view)\n","- [WIDER Face Testing Images Google Drive](https://drive.google.com/file/d/1HIfDbVEWKmsYKJZm4lchTBDLW5N7dY5T/view)\n","- [Face annotations WIDER FACE 데이터셋 홈페이지](http://shuoyang1213.me/WIDERFACE/index.html)\n","\n","위\u001d 파일들을 데이터셋 PATH에 widerface 폴더를 만들어서 unzip 해주자. 그리고 아이펠에서 제공한 9개의 python 모듈 파일이 포함되어 있는 파일도 PATH에서 unzip 하자.\n","\n","`unzip '*.zip'`"],"metadata":{"id":"bn3DKJIXYfnJ"}},{"cell_type":"markdown","source":["# 14-2. 데이터셋 전처리(1) 분석"],"metadata":{"id":"QrwIlHtlWTRw"}},{"cell_type":"markdown","source":["### WIDER FACE Bounding Box\n","오늘 다룰 WIDER FACE 데이터셋은 face detection을 위한 데이터셋으로, 입력 데이터는 이미지 파일로, Ground truth는 bounding box 정보로 되어있다."],"metadata":{"id":"i6oC-xfiheZA"}},{"cell_type":"code","source":["!cd /content/drive/MyDrive/aiffel_dataset/GD14_face_sticker/widerface && ls *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cSre7LEu4br","executionInfo":{"status":"ok","timestamp":1650118720721,"user_tz":-540,"elapsed":360,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"3d824788-9ecd-4c42-a237-18ca082e49f8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["wider_face_split.zip  WIDER_test.zip  WIDER_train.zip  WIDER_val.zip\n","\n","wider_face_split:\n","readme.txt\t\t      wider_face_train_bbx_gt.txt  wider_face_val.mat\n","wider_face_test_filelist.txt  wider_face_train.mat\n","wider_face_test.mat\t      wider_face_val_bbx_gt.txt\n","\n","WIDER_test:\n","images\n","\n","WIDER_train:\n","images\n","\n","WIDER_val:\n","images\n"]}]},{"cell_type":"markdown","source":["WIDER_test, train, val 디렉토리는 입력용 이미지 파일만 들어와 있다.   \n","wider_face_split 디랙토리 내에 wider_face_train_bbx_gt.txt와 wider_face_val_bbx_gt.txt 파일 안에 포함되어 있는 bounding box 정보를 알아보자."],"metadata":{"id":"zlmxDildvVDK"}},{"cell_type":"code","source":["!cd /content/drive/MyDrive/aiffel_dataset/GD14_face_sticker/widerface/wider_face_split/ && head -20 wider_face_train_bbx_gt.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N04GlEAH2Zvv","executionInfo":{"status":"ok","timestamp":1650120593810,"user_tz":-540,"elapsed":439,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"71bec2e5-ee7c-47f4-f406-979926556bc8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["0--Parade/0_Parade_marchingband_1_849.jpg\n","1\n","449 330 122 149 0 0 0 0 0 0 \n","0--Parade/0_Parade_Parade_0_904.jpg\n","1\n","361 98 263 339 0 0 0 0 0 0 \n","0--Parade/0_Parade_marchingband_1_799.jpg\n","21\n","78 221 7 8 2 0 0 0 0 0 \n","78 238 14 17 2 0 0 0 0 0 \n","113 212 11 15 2 0 0 0 0 0 \n","134 260 15 15 2 0 0 0 0 0 \n","163 250 14 17 2 0 0 0 0 0 \n","201 218 10 12 2 0 0 0 0 0 \n","182 266 15 17 2 0 0 0 0 0 \n","245 279 18 15 2 0 0 0 0 0 \n","304 265 16 17 2 0 0 0 2 1 \n","328 295 16 20 2 0 0 0 0 0 \n","389 281 17 19 2 0 0 0 2 0 \n","406 293 21 21 2 0 1 0 0 0 \n"]}]},{"cell_type":"markdown","source":["이는 다음과 같은 반복 구조로 이루어져 있음을 파악할 수 있다.\n","\n","```\n","# 이미지 파일 경로\n","0--Parade/0_Parade_marchingband_1_849.jpg\n","# face bounding box 개수\n","1\n","# face bounding box 좌표 등 상세정보\n","449 330 122 149 0 0 0 0 0 0 \n","```\n","\n","10개의 숫자로 이루어진 정보들은 다음과 같은 상세정보를 갖고 있다.   \n","```\n","x0, y0, w, h, blur, expression, illumination, invalid, occlusion, pose\n","```\n","\n","bounding box와 관련해서 가장 중요한 4개의 숫자는 왼쪽의 4개(X좌표, Y좌표, 너비, 높이)이다."],"metadata":{"id":"7LZsJ6aO4IpI"}},{"cell_type":"code","source":["import os, cv2, time\n","import tensorflow as tf\n","import tqdm\n","import numpy as np\n","import math\n","from itertools import product\n","import matplotlib.pyplot as plt\n","\n","PROJECT_PATH = '/content/drive/MyDrive/aiffel_dataset/GD14_face_sticker'\n","DATA_PATH = os.path.join(PROJECT_PATH, 'widerface')\n","MODEL_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n","TRAIN_TFRECORD_PATH = os.path.join(PROJECT_PATH, 'dataset', 'train_mask.tfrecord')\n","VALID_TFRECORD_PATH = os.path.join(PROJECT_PATH, 'dataset', 'val_mask.tfrecord')\n","CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n","\n","DATASET_LEN = 12880\n","BATCH_SIZE = 32\n","IMAGE_WIDTH = 320\n","IMAGE_HEIGHT = 256\n","IMAGE_LABELS = ['background', 'face']\n","\n","print(PROJECT_PATH)\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQZlZla04qow","executionInfo":{"status":"ok","timestamp":1650121236898,"user_tz":-540,"elapsed":10593,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"6738d883-8f1e-4138-d2c9-640c47bdf668"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/aiffel_dataset/GD14_face_sticker\n","2.8.0\n"]}]},{"cell_type":"markdown","source":["먼저 bounding box 파일을 분석해보자."],"metadata":{"id":"-FwBBeQI5LYd"}},{"cell_type":"code","source":["def parse_box(data):\n","    x0 = int(data[0])\n","    y0 = int(data[1])\n","    w = int(data[2])\n","    h = int(data[3])\n","    return x0, y0, w, h\n","\n","print('슝=3')"],"metadata":{"id":"-GSmaEU35OH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def parse_widerface(file):\n","    infos = []\n","    with open(file) as fp:\n","        line = fp.readline()\n","        while line:\n","            n_object = int(fp.readline())\n","            boxes = []\n","            for i in range(n_object):\n","                box = fp.readline().split(' ')\n","                x0, y0, w, h = parse_box(box)\n","                if (w == 0) or (h == 0):\n","                    continue\n","                boxes.append([x0, y0, w, h])\n","            if n_object == 0:\n","                box = fp.readline().split(' ')\n","                x0, y0, w, h = parse_box(box)\n","                boxes.append([x0, y0, w, h])\n","            infos.append((line.strip(), boxes))\n","            line = fp.readline()\n","    return infos\n","\n","print('슝=3')"],"metadata":{"id":"rLvtJgl_5QHh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위 함수는 이미지별 bounding box 정보를 `wider_face_train_bbx_gt.txt`에서 파싱해서 리스트로 추출하는 것이다.\n","\n","추출한 정보를 실제 이미지 정보와 결합해보자.   \n","bounding box 정보는 [x, y, w, h] 형태로 저장되어 있는데, [x_min, y_min, x_max, y_max] 형태의 꼭짓점 좌표 정보로 변환해야한다.\n","\n","이렇게 정보를 결합해야 나중에 학습에 용이하다."],"metadata":{"id":"6tcvl8ih5b_9"}},{"cell_type":"code","source":["def process_image(image_file):\n","    image_string = tf.io.read_file(image_file)\n","    try:\n","        image_data = tf.image.decode_jpeg(image_string, channels=3)\n","        return 0, image_string, image_data\n","    except tf.errors.InvalidArgumentError:\n","        return 1, image_string, None\n","\n","print('슝=3')"],"metadata":{"id":"7S2SBzJb5be6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def xywh_to_voc(file_name, boxes, image_data):\n","    shape = image_data.shape\n","    image_info = {}\n","    image_info['filename'] = file_name\n","    image_info['width'] = shape[1]\n","    image_info['height'] = shape[0]\n","    image_info['depth'] = 3\n","\n","    difficult = []\n","    classes = []\n","    xmin, ymin, xmax, ymax = [], [], [], []\n","\n","    for box in boxes:\n","        classes.append(1)\n","        difficult.append(0)\n","        xmin.append(box[0])\n","        ymin.append(box[1])\n","        xmax.append(box[0] + box[2])\n","        ymax.append(box[1] + box[3])\n","    image_info['class'] = classes\n","    image_info['xmin'] = xmin\n","    image_info['ymin'] = ymin\n","    image_info['xmax'] = xmax\n","    image_info['ymax'] = ymax\n","    image_info['difficult'] = difficult\n","\n","    return image_info\n","\n","print('슝=3')"],"metadata":{"id":"h_66kev--Dvk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이렇게 결합된 데이터의 형태를 5개만 확인해보자.   \n","그리고 이 정보를 활용하여 텐서플로우 데이터셋을 생성해보자."],"metadata":{"id":"to1hlcOH-Fxu"}},{"cell_type":"code","source":["file_path = os.path.join(DATA_PATH, 'wider_face_split', 'wider_face_train_bbx_gt.txt')\n","for i, info in enumerate(parse_widerface(file_path)):\n","    print('--------------------')\n","    image_file = os.path.join(DATA_PATH, 'WIDER_train', 'images', info[0])\n","    _, image_string, image_data = process_image(image_file)\n","    boxes = xywh_to_voc(image_file, info[1], image_data)\n","    print(boxes)\n","    if i > 3:\n","        break"],"metadata":{"id":"ODgOFPD0-FUW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 14-3. 데이터셋 전처리(2) TFRecord 생성"],"metadata":{"id":"g7zoStrmWTSU"}},{"cell_type":"markdown","source":["### TFRecord 만들기\n","오늘 다루는 대용량 데이터셋의 처리속도 향상을 위해, 전처리 작업을 통해 TFRecord 데이터셋으로 변환해보자.   \n","TFRecord란 TensorFlow만의 학습 데이터 저장 포맷으로, 이진 레코드의 스퀀스를 저장한다. TFRecord 형태의 학습 데이터를 사용하여 모델 학습을 하면 학습 속도가 개선된다.\n","\n","TFRecord는 여러 개의 tf.train.Example로 이루어져 있고, 한 개의 tf.train.Example은 여러 개의 tf.train.Feature로 이루어져 있다.\n","\n","데이터 단위를 이루는 tf.train.Example 인스턴스를 생성하는 메소드를 선언해보자."],"metadata":{"id":"KJyMqo_x_dYx"}},{"cell_type":"code","source":["def make_example(image_string, image_infos):\n","    for info in image_infos:\n","        filename = info['filename']\n","        width = info['width']\n","        height = info['height']\n","        depth = info['depth']\n","        classes = info['class']\n","        xmin = info['xmin']\n","        ymin = info['ymin']\n","        xmax = info['xmax']\n","        ymax = info['ymax']\n","\n","    if isinstance(image_string, type(tf.constant(0))):\n","        encoded_image = [image_string.numpy()]\n","    else:\n","        encoded_image = [image_string]\n","\n","    base_name = [tf.compat.as_bytes(os.path.basename(filename))]\n","    \n","    example = tf.train.Example(features=tf.train.Features(feature={\n","        'filename':tf.train.Feature(bytes_list=tf.train.BytesList(value=base_name)),\n","        'height':tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n","        'width':tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n","        'classes':tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n","        'x_mins':tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n","        'y_mins':tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n","        'x_maxes':tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n","        'y_maxes':tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n","        'image_raw':tf.train.Feature(bytes_list=tf.train.BytesList(value=encoded_image))\n","    }))\n","    \n","    return example\n","\n","print('슝=3')"],"metadata":{"id":"7QA6f19a_6Oh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["전처리에 필요한 함수들이 갖추어졌다.   \n","데이터셋의 이미지 파일, 그리고 bounding box 정보를 모아 위의 make_example 메소드를 통해 만든 example을 serialize하여 TFRecord 파일로 생성하게 된다.\n","- [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord)"],"metadata":{"id":"Ns6_Lg_5jQop"}},{"cell_type":"code","source":["for split in ['train', 'val']:\n","    if split == 'train':\n","        output_file = TRAIN_TFRECORD_PATH \n","        anno_txt = 'wider_face_train_bbx_gt.txt'\n","        file_path = 'WIDER_train'\n","    else:\n","        output_file = VALID_TFRECORD_PATH\n","        anno_txt = 'wider_face_val_bbx_gt.txt'\n","        file_path = 'WIDER_val'\n","\n","    with tf.io.TFRecordWriter(output_file) as writer:\n","        for info in tqdm.tqdm(parse_widerface(os.path.join(DATA_PATH, 'wider_face_split', anno_txt))):\n","            image_file = os.path.join(DATA_PATH, file_path, 'images', info[0])\n","            error, image_string, image_data = process_image(image_file)\n","            boxes = xywh_to_voc(image_file, info[1], image_data)\n","\n","            if not error:\n","                tf_example = make_example(image_string, [boxes])\n","                writer.write(tf_example.SerializeToString())"],"metadata":{"id":"s9usaaiNjg0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/aiffel_dataset/GD14_face_sticker/dataset"],"metadata":{"id":"9SyKeQJxj2fd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 14-4. 모델 구현(1) Default boxes"],"metadata":{"id":"nCq4-9oYWTTG"}},{"cell_type":"markdown","source":["### SSD의 Default box\n","SSD 모델의 가장 중요한 특징 중 하나는 Default box를 필요로 한다는 점이다.   \n","Default box란, object가 존재할만한 다양한 크기의 box 좌표 및 클래스 정보를 일정 개수만큼 미리 고정해 둔 것이다. 이를 anchor box, prior box라고 부른다.   \n","SSD의 default box의 다른 점은 여러 층의 feature map에서 box를 만든다는 점이다. 층 수 만큼 box도 많아지고, 층마다 box의 크기도 다양해진다.   \n","ground truth에 해당하는 bounding box의 IoU를 계산하여 일정 크기(0.5) 이상 겹치는 default box를 선택하는 방식이 RCNN 계열의 sliding window 방식보다 훨씬 속도가 빠르면서 유사한 정확도를 얻을 수 있다.   \n","![](https://d3s0tskafalll9.cloudfront.net/media/images/gc-9v3-p-4-1_adjeL1p.max-800x600.jpg)"],"metadata":{"id":"cmXAXr9KkN6t"}},{"cell_type":"markdown","source":["![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-11-P-06.max-800x600.png)\n","\n","default box를 생성하기 위해 기준이 되는 feature map을 먼저 생성해야한다. 그림에서는 8x8, 4x4의 예가 나오지만 이번에는 4가지 유형의 feature map을 생성해보자."],"metadata":{"id":"970vmtB2Q3D5"}},{"cell_type":"code","source":["BOX_MIN_SIZES = [[10, 16, 24], [32, 48], [64, 96], [128, 192, 256]]\n","BOX_STEPS = [8, 16, 32, 64]\n","\n","print('슝=3')"],"metadata":{"id":"KycIatyRRBKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_sizes = (IMAGE_HEIGHT, IMAGE_WIDTH)\n","min_sizes = BOX_MIN_SIZES\n","steps= BOX_STEPS\n","\n","feature_maps = [\n","    [math.ceil(image_sizes[0] / step), math.ceil(image_sizes[1] / step)]\n","    for step in steps\n","]\n","feature_maps"],"metadata":{"id":"X7tf89zDRGFO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["feature map별로 순회를 하면서 default box를 생성해보자."],"metadata":{"id":"QokCKAOaRn_o"}},{"cell_type":"code","source":["boxes = []\n","for k, f in enumerate(feature_maps):\n","    for i, j in product(range(f[0]), range(f[1])):\n","        for min_size in min_sizes[k]:\n","            s_kx = min_size / image_sizes[1]\n","            s_ky = min_size / image_sizes[0]\n","            cx = (j + 0.5) * steps[k] / image_sizes[1]\n","            cy = (i + 0.5) * steps[k] / image_sizes[0]\n","            boxes += [cx, cy, s_kx, s_ky]\n","\n","len(boxes)"],"metadata":{"id":"UUyL0sZQRrGE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이렇게 생성된 boxes는 default box 정보가 구분없이 나열되어 있으므로 4개씩 재배열해주자."],"metadata":{"id":"dCkVy1EumUIU"}},{"cell_type":"code","source":["pretty_boxes = np.asarray(boxes).reshape([-1, 4])\n","print(pretty_boxes.shape)\n","print(pretty_boxes)"],"metadata":{"id":"OYuO4xsRmaSE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4700개의 default box가 만들어졌다. feature_maps와 min_size로부터 40x32x3 + 20x16x2 + 10x8x2 + 5x4x3 개가 생성됐다.\n","\n","위 과정을 사용하기 편리하도록 함수로 정의해보자."],"metadata":{"id":"vTahxbx-md_g"}},{"cell_type":"code","source":["def default_box():\n","    image_sizes = (IMAGE_HEIGHT, IMAGE_WIDTH)\n","    min_sizes = BOX_MIN_SIZES\n","    steps= BOX_STEPS\n","    feature_maps = [\n","        [math.ceil(image_sizes[0] / step), math.ceil(image_sizes[1] / step)]\n","        for step in steps\n","    ]\n","    boxes = []\n","    for k, f in enumerate(feature_maps):\n","        for i, j in product(range(f[0]), range(f[1])):\n","            for min_size in min_sizes[k]:\n","                s_kx = min_size / image_sizes[1]\n","                s_ky = min_size / image_sizes[0]\n","                cx = (j + 0.5) * steps[k] / image_sizes[1]\n","                cy = (i + 0.5) * steps[k] / image_sizes[0]\n","                boxes += [cx, cy, s_kx, s_ky]\n","    boxes = np.asarray(boxes).reshape([-1, 4])\n","    return boxes\n","\n","print('슝=3')"],"metadata":{"id":"5cL6sW_bm0Ae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 14-5. 모델 구현(2) SSD"],"metadata":{"id":"4cgm_6rIWTT2"}},{"cell_type":"markdown","source":["### SSD model 빌드하기\n","SSD 모델을 생성해보자.\n","\n","SSD 모델에서 일반적으로 많이 쓰이는 convolution block, depthwise convolution block, skip connection으로 쓰일 branch block을 준비하자."],"metadata":{"id":"UOJbSbPEm13b"}},{"cell_type":"code","source":["def _conv_block(inputs, filters, kernel=(3, 3), strides=(1, 1)):\n","    block_id = (tf.keras.backend.get_uid())\n","    if strides == (2, 2):\n","        x = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv_pad_%d' % block_id)(inputs)\n","        x = tf.keras.layers.Conv2D(filters, kernel,\n","                                   padding='valid',\n","                                   use_bias=False,\n","                                   strides=strides,\n","                                   name='conv_%d' % block_id)(x)\n","    else:\n","        x = tf.keras.layers.Conv2D(filters, kernel,\n","                                   padding='same',\n","                                   use_bias=False,\n","                                   strides=strides,\n","                                   name='conv_%d' % block_id)(inputs)\n","    \n","    x = tf.keras.layers.BatchNormalization(name='conv_bn_%d' % block_id)(x)\n","    return tf.keras.layers.ReLU(name='conv_relu_%d' % block_id)(x)\n","\n","print('슝=3')"],"metadata":{"id":"2_Eqdk7PqkDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _depthwise_conv_block(inputs, filters, strides=(1, 1)):\n","    block_id = tf.keras.backend.get_uid()\n","    if strides == (1, 1):\n","        x = inputs\n","    else:\n","        x = tf.keras.layers.ZeroPadding2D(((1, 1), (1, 1)), name='conv_pad_%d' % block_id)(inputs)\n","    x = tf.keras.layers.DepthwiseConv2D((3, 3),\n","                                        padding='same' if strides == (1, 1) else 'valid',\n","                                        strides=strides,\n","                                        use_bias=False,\n","                                        name='conv_dw_%d' % block_id)(x)\n","    x = tf.keras.layers.BatchNormalization(name='conv_dw_%d_bn' % block_id)(x)\n","    x = tf.keras.layers.ReLU(name='conv_dw_%d_relu' % block_id)(x)\n","    x = tf.keras.layers.Conv2D(filters, (1, 1),\n","                               padding='same',\n","                               use_bias=False,\n","                               strides=(1, 1),\n","                               name='conv_pw_%d' % block_id)(x)\n","    x = tf.keras.layers.BatchNormalization(name='conv_pw_%d_bn' % block_id)(x)\n","    return tf.keras.layers.ReLU(name='conv_pw_%d_relu' % block_id)(x)\n","\n","print('슝=3')"],"metadata":{"id":"m0uVHBIvq5ml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _branch_block(inputs, filters):\n","    x = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(inputs)\n","    x = tf.keras.layers.LeakyReLU()(x)\n","    x = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n","    x1 = tf.keras.layers.Conv2D(filters * 2, kernel_size=(3, 3), padding='same')(inputs)\n","    x = tf.keras.layers.Concatenate(axis=-1)([x, x1])\n","    return tf.keras.layers.ReLU()(x)\n","\n","print('슝=3')"],"metadata":{"id":"B3CR4ODKrRXI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["여러 블록을 쌓아 모델을 만든 후, 중간중간 Branch 부분에 head라고 불리는 convolution layer를 붙일것이다.   \n","하나의 head에 convolution layer 2개가 필요하다. 하나는 confidence를 예측하기 위해, 하나는 location을 예측하기 위해 사용한다.\n","\n","branch마다 head가 연결되어 있기 때문에 모델의 중간 레이어에서도 예측을 위한 정보를 가져올 수 있다."],"metadata":{"id":"MHPbT3jIrcqd"}},{"cell_type":"code","source":["def _create_head_block(inputs, filters):\n","    x = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n","    return x\n","\n","print('슝=3')"],"metadata":{"id":"LqtBB9aCtVGA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _compute_heads(inputs, num_class, num_cell):\n","    conf = _create_head_block(inputs, num_cell * num_class)\n","    conf = tf.keras.layers.Reshape((-1, num_class))(conf)\n","    loc = _create_head_block(inputs, num_cell * 4)\n","    loc = tf.keras.layers.Reshape((-1, 4))(loc)\n","    return conf, loc\n","\n","print('슝=3')"],"metadata":{"id":"W7tYkhpZtXL_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 14-6. 모델 학습(1) Augmentation, jaccard 적용"],"metadata":{"id":"FnE2wTBfWTUc"}},{"cell_type":"markdown","source":["# 14-7. 모델 학습(2) train"],"metadata":{"id":"XTJuHAs3WTVF"}},{"cell_type":"markdown","source":["# 14-8. inference(1) NMS"],"metadata":{"id":"R5rP9E5sWTVu"}},{"cell_type":"markdown","source":["# 14-9. inference(2) 사진에서 얼굴 찾기"],"metadata":{"id":"2jqFsqMvWTWS"}},{"cell_type":"markdown","source":["# 14-10. 프로젝트: 스티커를 붙여주자"],"metadata":{"id":"0yrm_6wmWTWw"}}]}