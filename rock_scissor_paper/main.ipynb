{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xaq3WAxDmQ7k"
   },
   "source": [
    "### Resize Data images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WgVLPlv5mdGR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200  images to be resized.\n",
      "1200  images resized.\n",
      "1200  images to be resized.\n",
      "1200  images resized.\n",
      "1200  images to be resized.\n",
      "1200  images resized.\n",
      "data 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "# \t\tnew_gary_img=new_img.convert('L')\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "    \n",
    "# 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "    \n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"data 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDDG4iFBnZAK"
   },
   "source": [
    "### Data labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JEsHNCiukTDc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3600 입니다.\n",
      "x_train shape: (3600, 28, 28, 3)\n",
      "y_train shape: (3600,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=3600):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28  # 28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "loHyd7L2mIIM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f747c69aeb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 불러오기\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWt235P-nutZ"
   },
   "source": [
    "### 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2OVHfoKWnvL8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 26, 26, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 11, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 26,211\n",
      "Trainable params: 25,987\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_channel_3=64\n",
    "n_dense=32\n",
    "n_train_epoch=12\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3))) # rgb라 1 -> 3으로 바꿈\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu', input_shape=(28,28,3))) # rgb라 1 -> 3으로 바꿈\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu', input_shape=(28,28,3))) # rgb라 1 -> 3으로 바꿈\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 최종 분류기의 Class수이다. 주먹, 가위, 보 3종류이므로 10 -> 3\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnvF_7xKn6UY"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oYgLXrjqn6Bk",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "113/113 [==============================] - 1s 4ms/step - loss: 0.7917 - accuracy: 0.6303\n",
      "Epoch 2/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8272\n",
      "Epoch 3/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8711\n",
      "Epoch 4/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8911\n",
      "Epoch 5/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9142\n",
      "Epoch 6/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9314\n",
      "Epoch 7/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9319\n",
      "Epoch 8/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9411\n",
      "Epoch 9/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9422\n",
      "Epoch 10/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9617\n",
      "Epoch 11/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9514\n",
      "Epoch 12/12\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73b3daa3a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# result = \n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Resized Test Data images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130  images to be resized.\n",
      "130  images resized.\n",
      "130  images to be resized.\n",
      "130  images resized.\n",
      "130  images to be resized.\n",
      "130  images resized.\n",
      "테스트 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "# \t\tnew_gary_img=new_img.convert('L')\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 테스트 가위, 바위, 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"테스트 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eLfLM2WloADc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 390 입니다.\n",
      "x_test shape: (390, 28, 28, 3)\n",
      "y_test shape: (390,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "def load_data2(img_path, number_of_data=390):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/AI_study/rock_scissor_paper/data/test\"\n",
    "(x_test, y_test)=load_data2(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yk8PCxaeoAPt"
   },
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KuyyikHSoPnf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.4591 - accuracy: 0.8231\n",
      "test_loss: 0.45906978845596313 \n",
      "test_accuracy: 0.8230769038200378\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13/13 - 0s - loss: 0.2940 - accuracy: 0.8897\n",
    "# test_loss: 0.2940012812614441 \n",
    "# test_accuracy: 0.8897435665130615"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sH_a1Ymx3BLY",
    "oyDMnkig3IaD",
    "YtWKvsOL3Suj",
    "j6X-LEUvN-B9",
    "SI-sYOGbd3_D"
   ],
   "name": "220104_exp_1. 인공지능과 가위바위보",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
