{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd035f14",
   "metadata": {},
   "source": [
    "딥러닝을 연구하는 사람들이 많고 다양한 방법을 적용하면서 사전학습된 네트워크(Pre-trained network)들이 많이 탄생했다. 이들은 tensorflow나 pytorch에서 사용할 수 있게 프레임워크 차원으로 지원하고 있다.   \n",
    "[tensorflow_slim_Pre-trained_models](https://github.com/tensorflow/models/tree/master/research/slim) 링크에 들어가 보면 다양한 사전학습된 네트워크를 살펴볼 수 있다. __이러한 딥러닝 네트워크들이 어떻게 생겨났고 어떤 시도로 만들어졌는지 알아보자__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d41cd",
   "metadata": {},
   "source": [
    "# ImageNet Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5457b5",
   "metadata": {},
   "source": [
    "이미지넷은 2010년 ILSVRC2010을 시작으로 대량의 이미지 데이터를 포함하는 데이터셋이다. 이들은 모은 데이터셋을 챌린지를 위해 제공했다. 유명한 테스크가 이미지 분류기(Image Classification Task)이다.   \n",
    "2010년에는 NEC-UIUC팀이 Descriptor Coding, SVM을 결합한 방식으로 Loss 28%로 1등을 했다. 2011년에는 Xerox Research Centre Europe이 Loss 26%로 1등을 했다. 2012년에는 토론토 대학의 SuperVision팀이 Loss 16%로 1등을 달성했다. 갑자기 오류율이 확 줄었는데 어떻개 해결했을까?   \n",
    "[top-5 errror, top-1 error](https://bskyvision.com/422)를 확인해보면 알겠지만 이미지들을 분류기에 넣어서 결과값(예측한 확률)을 봤을 때 Top-1은 가장 높은애가 정답과 일치할 경우만 True로 체크하는 것이고 Top-5는 상위 5개가 정답과 일치할 경우에 True로 체크한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449e370e",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크의 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57782b58",
   "metadata": {},
   "source": [
    "SuperVision이 전년도 대비 10% 오류율을 낮추면서 1등을 할 수 있었던 방법은 CNN 구조로 네트워크를 깊게 쌓았기 때문이다.   \n",
    "![](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99FEB93C5C80B5192E)  \n",
    "[AlexNet의 구조](https://bskyvision.com/421)를 살펴보면 2개의 GPU로 병렬연산을 하기 위해 위 아래로 나눠져서 설계되었다. 8개의 레이어로 구성되어 있고 이들은 5개의 컨볼루션 레이어와 3개의 full-connected 레이어로 구성되어 있다. 링크에 레이어마다 어떤 작업이 수행되는지 자세히 나와있으니 확인해보자. [AlexNet 논문](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)도 한번 확인해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ecaac2",
   "metadata": {},
   "source": [
    "# CNN의 VGG 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31eae26",
   "metadata": {},
   "source": [
    "AlexNet처럼 이미지넷 챌린지에서 공개된 모델로 2014년 준우승을 거둔 모델이다. 이전에 우승한 네트워크들이 10개가 안되는 CNN층을 가진 반면, VGG16, VGG19는 각각 16, 19개의 층으로 이루어져 있다.   \n",
    "이 모델의 핵심은 네트워크의 깊이를 깊게 만드는 것이 성능에 어떤 영향을 미치는지 확인하고자 만들어졌다. 그래서 커널의 사이즈를 가장 작은 3x3으로 만들어 레이어를 쌓는 방식으로 만들었다. 자세한 레이어의 설명은 [VGGNet 구조](https://bskyvision.com/504)를 살펴보자.   \n",
    "\n",
    "VGG가 나온 같은 해 우승을 한 GooleNet은 망의 깊이(layer의 수)는 훨씬 깊은데 free parameter의 수는 1/12 수준이고 전체 연산량의 숫자도 AlexNet에 비해 적다. 하지만 비교적 복잡한 구조때문에 VGG모델이 더 인기를 끌었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629ce83",
   "metadata": {},
   "source": [
    "# Vanishing Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b226d88",
   "metadata": {},
   "source": [
    "모델이 깊어질수록 모델의 학습을 위한 Gradient가 사라지는 현상이 발생한다. 왜냐하면 Gradient descent를 통해 기울기를 학습하는데 깊은 레이어는 데이터에 따른 차이가 충분하게 반영되지 못하기 때문이다. 원인은 레이어의 가중치가 반복해서 곱해지면 1보다 작을 때 0에 너무 가까워지고 1보다 클 때 그 값이 엄청나게 커지기 때문이다. 이렇게 gradient가 작아 레이어를 학습시키기에 충분하지 않은 경우를 vanishing 했다고 하여 기울기 소실(Vanishing Gradient)라고 한다.   \n",
    "\n",
    "그래서 활성화 함수를 변경하거나 가중치 초기화 방법을 사용하면 문제를 완화할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b04e55",
   "metadata": {},
   "source": [
    "# Vanishing, Exploding Gradient 문제를 해결하기 위한 ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c1db2",
   "metadata": {},
   "source": [
    "![](https://d3i71xaburhd42.cloudfront.net/58d3c288cdeeeba045514f32f8a5c5f75aa19fd7/2-Figure1-1.png)\n",
    "ImageNet 챌린지 모델들의 레이어 수와 error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff83d0a",
   "metadata": {},
   "source": [
    "이론적으로 신경망 레이어 층을 깊게 할수록 훈련 세트에서 나아져야한다. 하지만 실제로는 Loss값이 늘어남을 느꼈다. 레이어가 깊을수록 최적화 알고리즘으로 훈련을 하는것이 어려워지고 너무 깊은 신경망으로 구조를 잡으면 훈련 로스가 커진다. 하지만 ResNet은 층이 깊어질수록 훈련 오류가 감소하는 성능을 갖고 있다. 어떻게 문제를 해결했을까? \n",
    "\n",
    "Skip Connection 구조를 사용해서 vanishing gradient 문제를 해결했다.   \n",
    "![](https://theaisummer.com/static/8d19d048cd68d6dce362e025cf3b635a/1ac66/skip-connection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9166c9c1",
   "metadata": {},
   "source": [
    "한 층의 활성값을 갖고 훨씬 깊은 층에 적용하는 방식이다.   \n",
    "\n",
    "ResNet외에 Skip connection을 사용하는 DenseNet이나 U-Net도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889eabcd",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 구현하면서 구조 분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6138419",
   "metadata": {},
   "source": [
    "Tensorflow의 pre-trained model들은 slim이라는 고수준 API로 구현되어 있다.   \n",
    "[tensorflow models repository](https://github.com/tensorflow/models)   \n",
    "Keras는 Keras applications를 통해 사전학습 모델을 제공한다.   \n",
    "[keras applications docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362da2b",
   "metadata": {},
   "source": [
    "# VGG-16\n",
    "![](https://blog.kakaocdn.net/dn/K990l/btqwDJ7C54R/664Ksm6gyTGBR1wK3YPDFk/img.png)   \n",
    "\n",
    "[VGG-16 코드 확인하기](https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd361c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 50000 x_test: 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# CIFAR100 데이터셋 가져오기\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(\"x_train:\", len(x_train), \"x_test:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88137b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 325,956\n",
      "Trainable params: 325,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_input = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=img_input, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba55a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 8s 3ms/step - loss: 3.6229 - accuracy: 0.1567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a79fe2760>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)    # 1 Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c40b3b",
   "metadata": {},
   "source": [
    "위에 링크에서 코드를 확인후 코드 블록을 가져와 구조를 분석해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d579865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 블록 OK!!\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 블록\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block1_conv1')(img_input)\n",
    "x = layers.Conv2D(64, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block1_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "print('첫 번째 블록 OK!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356b0045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 번째 블록 OK!!\n"
     ]
    }
   ],
   "source": [
    "# 두 번째 블록\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "print('두 번째 블록 OK!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c68621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세 번째 블록 OK!!\n"
     ]
    }
   ],
   "source": [
    "# 세 번째 블록\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "print('세 번째 블록 OK!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b7ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네 번째 블록 OK!!\n"
     ]
    }
   ],
   "source": [
    "# 네 번째 블록\n",
    "\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "print('네 번째 블록 OK!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8fb3de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다섯 번째 블록 OK!!\n"
     ]
    }
   ],
   "source": [
    "# 다섯 번째 블록\n",
    "\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "print('다섯 번째 블록 OK!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c13f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여섯 번째 블록 OK!!\n"
     ]
    }
   ],
   "source": [
    "# 여섯 번째 블록\n",
    "# if include_top: 부분\n",
    "\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "\n",
    "print('여섯 번째 블록 OK!!')\n",
    "\n",
    "classes=100\n",
    "x = layers.Dense(classes, activation='softmax', name='predictions')(x)    # CIFAR100을 위한 모델 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc569f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG-16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 34,006,948\n",
      "Trainable params: 34,006,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(name=\"VGG-16\", inputs=img_input, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73355c5",
   "metadata": {},
   "source": [
    "위에서 만든 CNN 모델보다 100배가 넘는 34M 크기가 됐다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b926f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 48s 30ms/step - loss: 4.6061 - accuracy: 0.0087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f495fc315b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)    # 1 Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058f393",
   "metadata": {},
   "source": [
    "# ResNet-50\n",
    "![](https://blog.kakaocdn.net/dn/bdQ7nn/btqzVCKyKVV/5nkGhNvCqK9BcIgasYRxH0/img.jpg)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aae5d4",
   "metadata": {},
   "source": [
    "[ResNet-50 코드 확인하기](https://git.dst.etit.tu-chemnitz.de/external/tf-models/-/blob/1d057dfc32f515a63ab1e23fd72052ab2a954952/official/vision/image_classification/resnet_model.py) residual에 포함된 Skip connection을 생각하면서 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e72182c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 GoGo!!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend, regularizers, initializers, models\n",
    "\n",
    "# L2 regularizer 선언\n",
    "def _gen_l2_regularizer(use_l2_regularizer=True, l2_weight_decay=1e-4):\n",
    "  return regularizers.l2(l2_weight_decay) if use_l2_regularizer else None\n",
    "\n",
    "print('Resnet50 GoGo!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c70a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2),\n",
    "               use_l2_regularizer=True,\n",
    "               batch_norm_decay=0.9,\n",
    "               batch_norm_epsilon=1e-5):\n",
    "  \"\"\"A block that has a conv layer at shortcut.\n",
    "  Note that from stage 3,\n",
    "  the second conv layer at main path is with strides=(2, 2)\n",
    "  And the shortcut should have strides=(2, 2) as well\n",
    "  Args:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: 'a','b'..., current block label, used for generating layer names\n",
    "    strides: Strides for the second conv layer in the block.\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "  \"\"\"\n",
    "  filters1, filters2, filters3 = filters\n",
    "  if backend.image_data_format() == 'channels_last':\n",
    "    bn_axis = 3\n",
    "  else:\n",
    "    bn_axis = 1\n",
    "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      strides=strides,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "  shortcut = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      strides=strides,\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '1')(\n",
    "          input_tensor)\n",
    "  shortcut = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '1')(\n",
    "          shortcut)\n",
    "\n",
    "  x = layers.add([x, shortcut])\n",
    "  x = layers.Activation('relu')(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f5a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor,\n",
    "                   kernel_size,\n",
    "                   filters,\n",
    "                   stage,\n",
    "                   block,\n",
    "                   use_l2_regularizer=True,\n",
    "                   batch_norm_decay=0.9,\n",
    "                   batch_norm_epsilon=1e-5):\n",
    "  \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "  Args:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: 'a','b'..., current block label, used for generating layer names\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "  \"\"\"\n",
    "  filters1, filters2, filters3 = filters\n",
    "  if backend.image_data_format() == 'channels_last':\n",
    "    bn_axis = 3\n",
    "  else:\n",
    "    bn_axis = 1\n",
    "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "  x = layers.add([x, input_tensor])\n",
    "  x = layers.Activation('relu')(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de87fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(num_classes,\n",
    "             batch_size=None,\n",
    "             use_l2_regularizer=True,\n",
    "             rescale_inputs=False,\n",
    "             batch_norm_decay=0.9,\n",
    "             batch_norm_epsilon=1e-5):\n",
    "  \"\"\"Instantiates the ResNet50 architecture.\n",
    "  Args:\n",
    "    num_classes: `int` number of classes for image classification.\n",
    "    batch_size: Size of the batches for each step.\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv/Dense layer.\n",
    "    rescale_inputs: whether to rescale inputs from 0 to 1.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "  Returns:\n",
    "      A Keras model instance.\n",
    "  \"\"\"\n",
    "\n",
    "  input_shape = (32, 32, 3)  # CIFAR100을 위한 input_shape 조정 \n",
    "  img_input = layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "  if rescale_inputs:\n",
    "    # Hub image modules expect inputs in the range [0, 1]. This rescales these\n",
    "    # inputs to the range expected by the trained model.\n",
    "    x = layers.Lambda(\n",
    "        lambda x: x * 255.0 - backend.constant(\n",
    "            imagenet_preprocessing.CHANNEL_MEANS,\n",
    "            shape=[1, 1, 3],\n",
    "            dtype=x.dtype),\n",
    "        name='rescale')(\n",
    "            img_input)\n",
    "  else:\n",
    "    x = img_input\n",
    "\n",
    "  if backend.image_data_format() == 'channels_first':\n",
    "    x = layers.Permute((3, 1, 2))(x)\n",
    "    bn_axis = 1\n",
    "  else:  # channels_last\n",
    "    bn_axis = 3\n",
    "\n",
    "  block_config = dict(\n",
    "      use_l2_regularizer=use_l2_regularizer,\n",
    "      batch_norm_decay=batch_norm_decay,\n",
    "      batch_norm_epsilon=batch_norm_epsilon)\n",
    "  x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(x)\n",
    "  x = layers.Conv2D(\n",
    "      64, (7, 7),\n",
    "      strides=(2, 2),\n",
    "      padding='valid',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='conv1')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name='bn_conv1')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "  x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "  x = conv_block(\n",
    "      x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), **block_config)\n",
    "  x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', **block_config)\n",
    "\n",
    "  x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', **block_config)\n",
    "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', **block_config)\n",
    "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', **block_config)\n",
    "\n",
    "  x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', **block_config)\n",
    "\n",
    "  x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', **block_config)\n",
    "  x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c', **block_config)\n",
    "\n",
    "  x = layers.GlobalAveragePooling2D()(x)\n",
    "  x = layers.Dense(\n",
    "      num_classes,\n",
    "      kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      bias_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='fc1000')(\n",
    "          x)\n",
    "\n",
    "  # A softmax that is followed by the model loss must be done cannot be done\n",
    "  # in float16 due to numeric issues. So we pass dtype=float32.\n",
    "  x = layers.Activation('softmax', dtype='float32')(x)\n",
    "\n",
    "  # Create model.\n",
    "  return models.Model(img_input, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a6929d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 16, 64)   9408        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4096        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16384       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16384       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36864       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16384       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36864       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16384       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32768       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131072      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131072      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   524288      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524288      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359296     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1048576     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2097152     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1, 1, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1048576     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359296     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1048576     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1048576     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359296     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1048576     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 100)          204900      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 100)          0           fc1000[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,766,052\n",
      "Trainable params: 23,712,932\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = resnet50(num_classes=100)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e071a37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 72s 42ms/step - loss: 8.4027 - accuracy: 0.0656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f495e7974c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)    # 1 Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ffdb8",
   "metadata": {},
   "source": [
    "VGG-16의 결과값 loss: 4.6061 - accuracy: 0.0087   \n",
    "ResNet-50의 결과값 loss: 8.4027 - accuracy: 0.0656   \n",
    "을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b86e2",
   "metadata": {},
   "source": [
    "## Skip connection은 어떻게 구현되어 있을까?\n",
    "\n",
    "`conv_block()`에서 shortcut으로 구현되어 있다. `x = layers.add([x, shortcut])`   \n",
    "`identity_block()`에서 `x = layers.add([x, input_tensor])`으로 다시 합친다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
