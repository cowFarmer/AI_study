{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22546ccb",
   "metadata": {},
   "source": [
    "# 회귀(Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d62e193",
   "metadata": {},
   "source": [
    "회귀분석은 분석 방법중 하나로 여러 데이터를 기반으로 연속형 변수의 관계를 모델링하고 이의 적합도를 측정하는 방식이다.   \n",
    "\n",
    "예를들어 부모의 키와 자식 키의 관계인데, 상호간 관련성을 갖고 있는 독립변수(independent variable; 혹은 설명 변수 explanatory variable)와 종속변수(dependent variable; 혹은 반응 변수 response variable)로 말할 수 있다.   \n",
    "\n",
    "부모의 키를 독립변수로 보면 자식의 키는 부모의 키에 비례하는 종속변수로 볼 수 있을까?   \n",
    "![](https://www.biostat.jhsph.edu/courses/bio653/misc/Regr_FigA2.gif)   \n",
    "Galton이 분석한 데이터이다. 아버지의 키 $x$와 자식의 키 $y$의 사이에 기울기가 1보다 작아 아버지의 키와 무관하게 자식의 키는 평균에 수렴하는 것을 보게 됐다. 이는 평균으로 회귀(regression)하는 개념이다. 그리고 이 그래프는 선형 회귀분석(Linear Regression)이라고 한다   \n",
    "\n",
    "오늘날 회귀분석은 두 개 이상의 변수 사이에 있는 함수 관계를 보는 통계적 방법을 의미한다. 간단하면서 실생활에 적용되는 경우가 많아 어느정도 틀만 맞으면 회귀 분석으로 문제를 해결할 만큼 보편적이다. 이 틀은 1) 선형성, 2) 독립성, 3) 등분산성, 4) 정규성 4가지의 조건을 본다.   \n",
    "[선형 회귀분석 기본가정](https://kkokkilkon.tistory.com/175)   \n",
    "\n",
    "지도학습은 대부분 데이터 $X$에 대한 정답 $y$가 주어지는 형태였는데, 크게 분류(classification), 회귀(regression) 문제로 나뉜다.\n",
    "- 분류: 데이터 x의 여러 feature 값들을 통해 클래스 y를 추론\n",
    "- 회귀: 데이터 x의 여러 feature 값들을 통해 연관된 다른 데이터 y의 정확한 값 추론   \n",
    "분류는 확률을 출력하고 회귀는 종속변수 값을 출력되는 형태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a09a2b",
   "metadata": {},
   "source": [
    "# 선형 회귀 분석(Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d21779",
   "metadata": {},
   "source": [
    "종속변수 Y와 한개 이상의 독립변수 X와의 상관관계를 선형으로 모델링하는 회귀 분석 기법이다.   \n",
    "하나의 독립변수 그리고 둘 이상의 종속변수를 갖고 있으면 다중 선형회귀라고 한다.   \n",
    "\n",
    "- 선형회귀모델 표기법 in 머신러닝   \n",
    "$H = Wx + b$   \n",
    "H는 가정(Hypothesis), W는 가중치(Weight), b는 편향(bias)이다. 주어진 데이터로 W, b의 값을 구하기 위해서 머신러닝, 딥러닝으로 학습한다. 이들은 스칼라 값이 아닌 고차원의 행렬(matrix) 형태로 이쓴 경우가 많고 개수가 많을수록 모델의 크기가 커지고 학습도 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241d628",
   "metadata": {},
   "source": [
    "잔차(Residuals)란 __회귀모델을 이용해 추정한 값과 실제 데이터의 차이__ 를 말한다. 예를들어 `(2,8)` 이라는 데이터와 선형 회귀모델의 식이 `y=2x+3`일때 잔차 값은 8(실제 y값)-7(실제 데이터의 x값을 모델에 넣었을 때 추론된 y값) = 1이 된다.   \n",
    "최소제곱법은 이런 잔차를 이용해서 회귀모델을 찾는 대표적인 방법중 하나다. n개의 점 데이터에 대해서 잔차의 제곱의 합을 최소로 하는 W,b를 구하는 방법이다.   \n",
    "실제 코드로 Boston dataset의 attribute에 선형 회귀 모델을 구해보고 결정계수를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07177f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "boston = load_boston()\n",
    "data, price = boston['data'], boston['target']\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data, price, test_size=0.2, random_state=5)\n",
    "\n",
    "df = pd.DataFrame(x_train, columns=boston['feature_names'])\n",
    "print(\"boston dataset의 차원: \", data.shape)\n",
    "print(\"price의 차원\", price.shape)\n",
    "print(\"boston train dataset의 차원: \", x_train.shape)\n",
    "print(\"boston test dataset의 차원: \", x_test.shape)\n",
    "\n",
    "print(\"Boston dataset의 예시\")\n",
    "print(data.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea07a7",
   "metadata": {},
   "source": [
    "506 row, 13가지 attribute(features)로 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features에 대한 설명을 볼 수 있다.\n",
    "print(boston[\"DESCR\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "919183e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/3658551685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Boston dataset - (X:Y = each attr: price) with R2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msingle_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboston\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# i번째 features에 대한 data 및 이름\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 선형 회귀 모델\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x2520 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 features에 선형회귀 적용해보기\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,35))\n",
    "fig.suptitle('Boston dataset - (X:Y = each attr: price) with R2', fontsize=16, y=0.9)\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    single_attr, attr_name = data[:, i].reshape(-1, 1), boston['feature_names'][i] # i번째 features에 대한 data 및 이름\n",
    "    estimator = LinearRegression() # 선형 회귀 모델\n",
    "\n",
    "    # x에 single_attr, y에 price에 해당하는 데이터를 대입해서 최소제곱법을 이용하여 모델 내 W, b를 구하기\n",
    "    estimator.fit(single_attr, price) \n",
    "\n",
    "    # 위 fit() 과정을 통해 구한 회귀계수를 기반으로 회귀모델에 X값을 대입했을 때의 예측 Y 값\n",
    "    pred_price = estimator.predict(single_attr)\n",
    "\n",
    "    score = metrics.r2_score(price, pred_price) # 결정계수를 구하는 함수\n",
    "\n",
    "    # 캔버스 생성\n",
    "    ax = fig.add_subplot(7, 2, i+1)\n",
    "    ax.scatter(single_attr, price) # 실제 데이터에 대한 산포도\n",
    "    ax.plot(single_attr, pred_price, color='red') # 선형회귀모델의 추세선\n",
    "    ax.set_title(\"{} x price, R2 score={:.3f}\".format(attr_name ,score))\n",
    "    ax.set_xlabel(attr_name) # x축\n",
    "    ax.set_ylabel('price') # y축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744f9bf",
   "metadata": {},
   "source": [
    "R2 score가 높은 편인 LSTAT, RM의 두 데이터가 회귀선을 따라서 잘 모여있는 것을 확인할 수 있다.\n",
    "여기서 R2 score는 회귀모델이 잘 결정되었는지 확인할때 참고하는 지표로 결정계수(R-squared, R2 score 등)라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718409b0",
   "metadata": {},
   "source": [
    "### 경사하강법\n",
    "회귀모델에서 주어진 데이터의 손실함수를 최소화 하는 $W$와 $b$를 구하는것이 핵심이다. 그래서 머신러닝에서는 손실함수의 gradient(미분값)가 최소가 되는 지점이 손실함수의 최소 지점이라고 가정한다.\n",
    "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNc7Ho%2FbtqBLHKc17S%2FuYR1YABBefaW0FzXc7G0S1%2Fimg.png)\n",
    "$J(W)$의 최소의 가중치 값을 구하기 위해 시각적으로 표현한 경사하강법 사진이다. 경사하강법에서 learning rate의 값이 커질수록 빠른 수렴을 하지만, 최적의 W값을 뛰어 넘는 경우가 생겨 수렴하지 못할 경우를 유의하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1fdeac",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀분석(Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b7a0b",
   "metadata": {},
   "source": [
    "로지스틱 회귀분석이란 데이터가 어떤 범수에 속할 확률을 0~1 사이의 값으로 예측하고 더 높은 확률로 분류해주는 지도 학습 알고리즘이다. 이진 분류(binary classfication) 문제를 풀 때 많이 사용한다.\n",
    "> 1. 실제 데이터를 대입해서 Odds 및 회귀계수를 구한다.   \n",
    "2. Log-odds를 계산하고 sigmoid function를 넣어서 특정 범주에 속할 확률 값을 구한다.   \n",
    "3. 설정한 threshold에 맞춰 설정값 이상이면 1, 이하면 0으로 이진 분류를 한다.   \n",
    "\n",
    "유방암 데이터셋을 이용해서 로지스틱 회귀분석으로 적합한 이진 분류를 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀분석 예제: 유방암 데이터셋\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer=load_breast_cancer()\n",
    "\n",
    "# y = 0(Malignant - 악성 종양), y=1(Benign - 양성 종양)\n",
    "cancer_X, cancer_y= cancer.data, cancer['target']\n",
    "train_X, test_X, train_y, test_y = train_test_split(cancer_X, cancer_y, test_size=0.1, random_state=10) # train 데이터셋과 test 데이터셋으로 나눔\n",
    "print(\"전체 검사자 수: {}\".format(len(cancer_X)))\n",
    "print(\"Attribute 수: {}\".format(len(cancer_X[0])))\n",
    "print(\"Train dataset에 사용되는 검사자 수: {}\".format(len(train_X)))\n",
    "print(\"Test dataset에 사용되는 검사자 수: {}\".format(len(test_X)))\n",
    "cancer_df = pd.DataFrame(cancer_X, columns=cancer['feature_names'])\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "LR = LogisticRegression() #로지스틱 회귀분석\n",
    "LR.fit(train_X, train_y) # 유방암 train data를 이용하여 로지스틱 회귀분석 모델 학습\n",
    "pred = LR.predict(test_X) # 학습된 로지스틱 회귀분석 모델을 이용한 예측값 출력\n",
    "\n",
    "\n",
    "# 로지스틱 회귀분석 모델의 예측값과 실제값 비교결과를 나타낸 통계표\n",
    "print(classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d9463",
   "metadata": {},
   "source": [
    "# Softmax, Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364f726",
   "metadata": {},
   "source": [
    "### Softmax   \n",
    "위에서는 로지스틱 회귀로 이진 분류를 했는데 여러 범주로 분류하는 다중 로지스틱 회귀(Multinomial Logistic Regression)으로 확장될 수 있다. 그래서 sigmoid는 다중 분류하는 softmax로 확장되어야 한다.   \n",
    "softmax도 0~1 사이의 값으로 확률 값이 정해지는데 모든 범주에 해당하는 softmax 값을 다 더했을 때 1이 되고, 큰 log-odds와 작은 log-odds의 차이를 극대화해서 어떤 범주에 분류되는지 확실히 알 수 있게 된다. 그리고 one-hot encoding을 통해 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4546e7cd",
   "metadata": {},
   "source": [
    "### Cross Entropy\n",
    "\n",
    "softmax 함수의 손실 함수로 쓰인다.   \n",
    "$H(p,q)=-\\displaystyle\\sum_{x}p(x)logq(x)$   \n",
    "가중치가 최적화 될 수록 $H(p,q)$ 값이 감소한다. 그리고 $p(x)$는 실제 데이터 범주 값, $q(x)$는 softmax의 결과값을 대입한다.   \n",
    "\n",
    "선형회귀와 어떤 부분이 다를까?   \n",
    "선형회귀에서 손실함수는 잔차(residual)의 제곱의 합이다. 로지스틱 회귀에서는 종속변수 방향이 확률변수 방향이다.   \n",
    "\n",
    "유방암 데이터셋을 이용해서 softmax, cross entropy 예제를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4193ce7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/1853314028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 데이터 로드는 선형회귀 분석에 있는 코드 블럭 참고\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msysconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msysconfig_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/platform/test.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_test_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogletest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_googletest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/test_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munittest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparameterized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/absl/testing/parameterized.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collections_abc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsltest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/absl/testing/absltest.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0munittest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmock\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 로드는 선형 회귀분석에 있는 코드 블럭 참고\n",
    "n_dense=30\n",
    "n_train_epoch=20\n",
    "num_classes = 2 # 악성, 양성\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "\n",
    "#레이어 3장\n",
    "model.add(keras.layers.Dense(n_dense, input_shape=(30,), use_bias=True))\n",
    "model.add(keras.layers.Dense(n_dense,  use_bias=True))\n",
    "model.add(keras.layers.Dense(n_dense,  use_bias=True))\n",
    "\n",
    "model.add(keras.layers.Dense(num_classes, use_bias=True, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(train_X, train_y, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(test_X, test_y, verbose=1)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed42a18",
   "metadata": {},
   "source": [
    "||선형 회귀분석|로지스틱 회귀분석|다중 로지스틱 회귀분석|\n",
    "|---|---|---|---|\n",
    "|문제 유형|종속변수가 연속형, 독립 변수의 변화에 따라 종속변수 값 추정| 종속변수 범주가 2개(이진 분류), 범주별 확률을 추정해서 최대확률 범주 결정하는 분류 모델| 종속변수의 범주가 여러 개|\n",
    "|쓰이는 함수, 변수|최소제곱법 많이 사용|logits(=log-odds), sigmoid 함수|cross entropy 함수, softmax 함수|\n",
    "|손실함수|최소제곱법 많이 사용|cross entropy(class가 2개)|cross entropy|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
