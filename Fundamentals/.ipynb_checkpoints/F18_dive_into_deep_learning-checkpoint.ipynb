{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f726f00",
   "metadata": {},
   "source": [
    "# Numpy를 이용해서 딥러닝의 간단한 신경망과 훈련 과정되짚어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bda55e",
   "metadata": {},
   "source": [
    "### 다층 퍼셉트론(Multi-Layer Perceptron; MLP)\n",
    "![](https://ichi.pro/assets/images/max/724/0*ZRqDRiz_jGI76NJv.png)\n",
    "\n",
    "입력층은 $x_d$ , 은닉층은 $Z_H$ , 출력층은 $S_K$로 구성되어 있으며   \n",
    "입력-은닉 가중치는 $W^d*H$, 은닉-출력 가중치는 $W^H*K$로 되어있다.   \n",
    "위의 모델은 입력층 노드`d=784`개, 은닉층 `H=50`개, 출력층 `K=10`개로 되어있다.   \n",
    "\n",
    "입력층 -> 은닉층, 은닉층 -> 출력층 사이에 행렬(Matrix)가 존재한다.   \n",
    "위 모델은 입력층-은닉층 사이에 `784x50`, 은닉층-출력층 사이에 `50x10`의 행렬이 존재한다.   \n",
    "이 행렬은 파라미터, Weight라고 부른다 그리고 이런 식의 관계가 성립한다. $y = W * X + b$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d8eb2",
   "metadata": {},
   "source": [
    "## 활성화 함수, 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf6835",
   "metadata": {},
   "source": [
    "### 활성화 함수(Activation Functions)\n",
    "딥러닝에서 활성화 함수가 필수적이다. 보통 비선형 함수에서 활성화 함수를 사용하는데 MLP에서 사용하면 모델의 표현력이 좋아진다. 자주 쓰이는 활성화 함수를 알아보자\n",
    "1. Sigmoid\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-2.max-800x600.png)\n",
    "위 MLP의 은닉층에 활성화 함수로 사용했다.   \n",
    "`model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))`   \n",
    "vanishing gradient 문제 발생, exp 함수 사용시 비용이 큼   \n",
    "\n",
    "2. Tanh\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-3.max-800x600.png)   \n",
    "함수의 중심을 0으로 옮겨 sigmoid의 느린 최적화 문제를 해결, vanishing gradient 문제 발생   \n",
    "\n",
    "3. ReLU\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-4.max-800x600.png)   \n",
    "위의 Sigmoid나 Tanh보다 학습이 빠름, 연산 비용이 크지 않고 구현이 간단한 장점 갖고 있어서 요즘 많이 사용함   \n",
    "~~hinge함수와 y축 기준으로 미러된거처럼 생겼음~~   \n",
    "### 손실 함수(Loss Function)\n",
    "비선형 활성화 함수를 갖고 여러 개의 은닉층을 거친 다음 신호 정보들을 출력층으로 전달한다. 이때 우리가 원하는 정답과 전달된 신호 정보들의 차이를 계산하고, 차이를 줄이기 위해 파라미터들을 조정하는 것이 딥러닝의 학습 흐름이다.   \n",
    "이 차이를 구할때 사용되는 함수가 손실함수(Loss function), 비용함수(Cost function)이라고 한다.\n",
    "- 평균제곱오차(MSE: Mean Square Error)   \n",
    "![](https://user-images.githubusercontent.com/10937193/58108494-e7bc7580-7c26-11e9-90a1-b988522a0b64.png)\n",
    "- 교차 엔트로피(Cross Entropy)   \n",
    "두 확률분포 사이의 유사도가 클수록 작아진다. \n",
    "![](https://mblogthumb-phinf.pstatic.net/MjAxODA2MTVfMjYg/MDAxNTI5MDQ4Mzc3MzI2.r0u34AMec-6ZLnAIxbfD-G0cfTfOz2cja8TTfBkUUbEg.oiIeDj9lu6Mtp780pgiNZDBGYn5thLSq1vpQPDpZshog.PNG.ssdyka/e_4.2.png?type=w2)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8924d7d4",
   "metadata": {},
   "source": [
    "## 경사하강법(Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c387e7",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14v3-3-1.max-800x600.png)   \n",
    "경사하강법은 손실 함수의 값이 최소가 되게끔 찾아주는 역할을 한다. 즉 손실 함수를 통해 구한 오차를 갖고 각 파라미터를 조정하는 것이 경사하강법이다.   \n",
    "학습률(learning rate)라는 개념을 도입해서 기울기 값과 학습률을 곱한 만큼 하강한다. [learning rate 관련 글](https://aileen93.tistory.com/71)   \n",
    "딥러닝 학습에 있어서 초기 가중치(파라미터) 설정은 엄청 중요하다 [가중치 관련 글](https://reniew.github.io/13/)   \n",
    "파라미너 W의 변화에 맞춰 오차(Loss) L의 변화량을 구해야한다. 그리고 오차 기울기가 커지는 반대 방향으로 파라미터를 조정해주는데 적절한 step size 역할을 하는 learning rate가 필수적이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a0783",
   "metadata": {},
   "source": [
    "## 오차역전파법(Backpropagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61db918",
   "metadata": {},
   "source": [
    "경사하강법의 기울기를 갖고 어떻게 입력층까지 전달할까? 이 때 오차역전파법 개념이 사용된다.   \n",
    "![](https://www.researchgate.net/profile/Rozaida_Ghazali/publication/234005707/figure/fig2/AS:667830315917314@1536234563135/The-structure-of-single-hidden-layer-MLP-with-Backpropagation-algorithm.png)\n",
    "MLP를 학습시키기 위한 알고리즘중 하나로 Output 결과와 내가 원하는 target값의 차이를 구한 뒤 그 오차 값을 각 레이어들을 되돌아가면서 역전파하고 기존에 갖고 있는 변수들을 갱신해 나간다.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a77b8",
   "metadata": {},
   "source": [
    "## 코드로 훑어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e655df0",
   "metadata": {},
   "source": [
    "MNIST 데이터셋 되짚어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e87ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 1ms/step - loss: 0.5022 - accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2331 - accuracy: 0.9345\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1828 - accuracy: 0.9477\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1510 - accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1287 - accuracy: 0.9631\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1126 - accuracy: 0.9681\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0996 - accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0893 - accuracy: 0.9751\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0807 - accuracy: 0.9774\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0734 - accuracy: 0.9793\n",
      "313/313 - 0s - loss: 0.1013 - accuracy: 0.9688\n",
      "test_loss: 0.10132098942995071 \n",
      "test_accuracy: 0.9688000082969666\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터 로드 혹은 다운로드\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 2개의 다층 퍼셉트론(MLP)으로 이루어져 있음\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성, 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942e0b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbda9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3961807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12662372, -0.74118953,  1.065441  ,  1.36870968, -0.12523814,\n",
       "        0.26912894, -0.70882715,  0.19370196,  0.10321834,  0.42514518,\n",
       "       -0.12239343, -0.53237096,  1.44275486,  0.32369199,  0.04628522,\n",
       "        0.65369418, -1.05946976,  0.04602635,  1.92207173, -0.62493227,\n",
       "        0.44159586,  1.22167555,  0.34528989, -0.5217953 ,  1.47837736,\n",
       "        0.43004148,  0.80290969,  0.21727459,  0.21450746,  0.21858376,\n",
       "        0.680882  ,  0.98370844,  1.3317004 , -0.23647292, -1.5266766 ,\n",
       "        1.26204531, -0.45288107, -0.30313248,  0.80600025,  0.32680646,\n",
       "        1.11041245,  0.10557256, -1.45584262, -0.07755707,  0.70446739,\n",
       "        0.98790539, -0.26623663,  2.43657882,  0.635133  ,  1.14107369])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터의 은닉층 출력을 확인해 봅시다.  50dim의 벡터가 나오나요?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0d7a7",
   "metadata": {},
   "source": [
    "신경망을 구성하는 활성화 함수와 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a9ec6",
   "metadata": {},
   "source": [
    "활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0268a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24478472 0.32274408 0.74372895 0.7971716  0.46873132 0.56687905\n",
      " 0.32985805 0.54827464 0.5257817  0.60471379 0.46943978 0.36996407\n",
      " 0.8088809  0.58022375 0.51156924 0.65784245 0.2574108  0.51150456\n",
      " 0.87236928 0.34866052 0.60863923 0.77235828 0.58547493 0.37243253\n",
      " 0.81432736 0.60588357 0.69059655 0.55410596 0.55342218 0.5544294\n",
      " 0.66393552 0.72784343 0.79112176 0.44115573 0.17848046 0.779378\n",
      " 0.38867598 0.4247919  0.69125653 0.58098214 0.752206   0.52636865\n",
      " 0.18910401 0.48062045 0.6691775  0.728674   0.43383123 0.91957443\n",
      " 0.65365244 0.75787672]\n"
     ]
    }
   ],
   "source": [
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 element가 0에서 1사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077ddec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go~\n"
     ]
    }
   ],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache\n",
    "\n",
    "print('go~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486b0e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30150714 -0.12284833  0.00800629  0.07573885 -0.01625715  0.02890017\n",
      " -0.10698277 -0.02347573 -0.20881785  0.24476469]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ad054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a455463e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07635073, 0.09128591, 0.10404786, 0.11133944, 0.10155369,\n",
       "       0.1062447 , 0.09274576, 0.10082325, 0.08376597, 0.13184268])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34525eef",
   "metadata": {},
   "source": [
    "손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b67b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_one_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_one_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "299f6353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07635073 0.09128591 0.10404786 0.11133944 0.10155369 0.1062447\n",
      " 0.09274576 0.10082325 0.08376597 0.13184268]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "133fa5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.276411728144512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4f63e",
   "metadata": {},
   "source": [
    "경사하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dac3c303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01527015,  0.01825718,  0.02080957,  0.02226789,  0.02031074,\n",
       "        -0.17875106,  0.01854915,  0.02016465,  0.01675319,  0.02636854],\n",
       "       [-0.1843055 ,  0.01877014,  0.01961971,  0.01814222,  0.02404028,\n",
       "         0.01857225,  0.01906641,  0.01638699,  0.01701822,  0.03268927],\n",
       "       [ 0.01538727,  0.01986503,  0.02267966,  0.01860579, -0.17948816,\n",
       "         0.02040485,  0.01601499,  0.0199626 ,  0.02085349,  0.02571448],\n",
       "       [ 0.01789224, -0.17963996,  0.01941062,  0.0219001 ,  0.02026539,\n",
       "         0.01835836,  0.01789029,  0.01925692,  0.0172312 ,  0.02743484],\n",
       "       [ 0.01465407,  0.01803658,  0.01768773,  0.0245698 ,  0.02042707,\n",
       "         0.02383552,  0.01667395,  0.02197722,  0.01594919, -0.17381113]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ee01fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06463602,  0.02186671,  0.05202662,  0.05482721, -0.08625946,\n",
       "        -0.03250986,  0.04503571,  0.05153068,  0.04593114, -0.08781272],\n",
       "       [-0.06431038, -0.09319647,  0.05310105,  0.05799625, -0.00908573,\n",
       "        -0.03366543,  0.04782187,  0.05292784,  0.04656254, -0.05815153],\n",
       "       [-0.12664274, -0.04939243,  0.05686992,  0.06016478, -0.01360179,\n",
       "        -0.04768856,  0.05130506,  0.05516025,  0.0496456 , -0.03582009],\n",
       "       [-0.07280603, -0.08559702,  0.04846669,  0.05041368, -0.03779818,\n",
       "        -0.03426337,  0.04290778,  0.04654367,  0.04249616, -0.00036339],\n",
       "       [-0.07670909, -0.06590691,  0.06496568,  0.06782192, -0.08801749,\n",
       "        -0.03297049,  0.05662508,  0.0632712 ,  0.05729442, -0.04637432],\n",
       "       [-0.07667428, -0.00586023,  0.05375467,  0.05551901, -0.07967544,\n",
       "        -0.05260245,  0.04667069,  0.05205295,  0.04718949, -0.0403744 ],\n",
       "       [-0.00615255, -0.02702856,  0.05019408,  0.05195389, -0.08756921,\n",
       "        -0.09844878,  0.04278561,  0.04886532,  0.04378773, -0.01838753],\n",
       "       [-0.06780976, -0.03576699,  0.05383065,  0.05721759, -0.03306931,\n",
       "        -0.08145783,  0.04773789,  0.05278571,  0.04685475, -0.0403227 ],\n",
       "       [-0.01487232, -0.0276783 ,  0.04808245,  0.05044276, -0.06458967,\n",
       "        -0.09571792,  0.04150119,  0.04710793,  0.0418552 , -0.02613132],\n",
       "       [-0.10494347, -0.0492211 ,  0.05916129,  0.0598631 , -0.05399267,\n",
       "        -0.10170315,  0.05202297,  0.05561487,  0.05132032,  0.03187785],\n",
       "       [-0.05666512, -0.03329395,  0.05266166,  0.05654969, -0.03285703,\n",
       "        -0.07526255,  0.04668387,  0.05215215,  0.04591186, -0.05588058],\n",
       "       [-0.0689945 , -0.02874146,  0.05935957,  0.06361555, -0.04018562,\n",
       "        -0.08218468,  0.0525808 ,  0.05874128,  0.05177893, -0.06596986],\n",
       "       [-0.11723778, -0.07996117,  0.06233113,  0.06628727, -0.00990019,\n",
       "        -0.06209262,  0.0562133 ,  0.0606269 ,  0.05434186, -0.03060869],\n",
       "       [-0.07072193, -0.02925646,  0.06155904,  0.06546118, -0.06156746,\n",
       "        -0.06427508,  0.05411142,  0.0607618 ,  0.05395418, -0.07002669],\n",
       "       [-0.07052352, -0.04340005,  0.04760733,  0.04973437, -0.05925611,\n",
       "        -0.01627977,  0.04171661,  0.04632598,  0.04201214, -0.03793697],\n",
       "       [-0.04515123, -0.02345063,  0.03509583,  0.03930439, -0.01737366,\n",
       "         0.00618736,  0.0315132 ,  0.03608245,  0.03111112, -0.09331883],\n",
       "       [-0.04798259, -0.05487803,  0.0342809 ,  0.03593948, -0.03491981,\n",
       "        -0.00832784,  0.03021082,  0.03329722,  0.03024935, -0.01786951],\n",
       "       [-0.0708026 , -0.04695856,  0.0566387 ,  0.05810572, -0.09099817,\n",
       "        -0.03677124,  0.04898798,  0.05450648,  0.04990764, -0.02261595],\n",
       "       [-0.10540988, -0.06188621,  0.06504324,  0.06776421, -0.07175393,\n",
       "        -0.03126776,  0.0572127 ,  0.06299018,  0.05725859, -0.03995114],\n",
       "       [-0.07324173, -0.03452691,  0.05961909,  0.0643647 , -0.0321542 ,\n",
       "        -0.07299108,  0.05307044,  0.0592713 ,  0.05206016, -0.07547177],\n",
       "       [-0.05080532, -0.02291778,  0.0355856 ,  0.03556791, -0.06013142,\n",
       "        -0.04419507,  0.03063134,  0.0334906 ,  0.03114695,  0.0116272 ],\n",
       "       [-0.08375516, -0.05010145,  0.04025779,  0.04294331,  0.00125692,\n",
       "        -0.04039494,  0.03652847,  0.03916064,  0.03505365, -0.02094924],\n",
       "       [-0.10508626, -0.03722728,  0.05419402,  0.05566754, -0.04537024,\n",
       "        -0.06688349,  0.04792231,  0.05162085,  0.04723849, -0.00207593],\n",
       "       [-0.02714544, -0.02169867,  0.03639878,  0.03570785, -0.08947202,\n",
       "        -0.04978494,  0.03051781,  0.03409028,  0.03195925,  0.0194271 ],\n",
       "       [-0.06989243, -0.02610377,  0.03664878,  0.03787626, -0.0316741 ,\n",
       "        -0.03661159,  0.03241757,  0.03512059,  0.0320339 , -0.00981521],\n",
       "       [-0.0575653 , -0.09888362,  0.0551394 ,  0.05986929, -0.04111179,\n",
       "         0.00441147,  0.04899343,  0.05510569,  0.04883719, -0.07479577],\n",
       "       [-0.05352296, -0.01493557,  0.04298583,  0.04531369, -0.04643826,\n",
       "        -0.04941852,  0.03769515,  0.04214767,  0.03763345, -0.0414605 ],\n",
       "       [-0.10536083, -0.03980294,  0.04983895,  0.04978721, -0.06641053,\n",
       "        -0.04173249,  0.04354182,  0.04659098,  0.04366508,  0.01988276],\n",
       "       [ 0.0050165 , -0.07343227,  0.04052773,  0.04168337, -0.09350796,\n",
       "        -0.01677448,  0.03414203,  0.03942208,  0.0359983 , -0.01307529],\n",
       "       [-0.05235148, -0.07437044,  0.04577578,  0.04757728, -0.05510237,\n",
       "        -0.02432547,  0.04002435,  0.04422895,  0.04031863, -0.01177523],\n",
       "       [-0.03987043, -0.04111842,  0.03190314,  0.03399932, -0.02511164,\n",
       "        -0.01907713,  0.02825499,  0.03138781,  0.02804696, -0.02841461],\n",
       "       [-0.09766805, -0.10356106,  0.04041843,  0.04237998, -0.00786913,\n",
       "         0.0154564 ,  0.0366574 ,  0.03866777,  0.03566603, -0.00014777],\n",
       "       [-0.10479972, -0.05342194,  0.05126275,  0.05266471, -0.04748862,\n",
       "        -0.03155188,  0.04534822,  0.04885126,  0.04496859, -0.00583338],\n",
       "       [ 0.00810292, -0.07211539,  0.04002219,  0.04313314, -0.04321733,\n",
       "        -0.05399588,  0.03480274,  0.03993317,  0.03507182, -0.03173737],\n",
       "       [-0.00554091, -0.05661497,  0.05067042,  0.05356957, -0.07559097,\n",
       "        -0.06547835,  0.04363495,  0.05004028,  0.04447259, -0.0391626 ],\n",
       "       [-0.05443235, -0.08780987,  0.04892911,  0.05187385, -0.03314924,\n",
       "        -0.03912415,  0.04336868,  0.04776767,  0.04289979, -0.02032348],\n",
       "       [-0.07800958, -0.05278919,  0.04330133,  0.04341813, -0.05614661,\n",
       "        -0.03948271,  0.03778815,  0.04055613,  0.03792314,  0.02344121],\n",
       "       [-0.08019713, -0.01214564,  0.04756082,  0.05175855,  0.01682084,\n",
       "        -0.10915313,  0.04328239,  0.04706234,  0.0408807 , -0.04586975],\n",
       "       [-0.02415899, -0.10935098,  0.05275833,  0.05633066, -0.06800482,\n",
       "        -0.00415794,  0.04598513,  0.05228822,  0.04679457, -0.04848418],\n",
       "       [-0.0198688 , -0.06607264,  0.04801337,  0.04984801, -0.0812551 ,\n",
       "        -0.04173168,  0.04121578,  0.04672615,  0.04230625, -0.01918133],\n",
       "       [-0.09893744, -0.05137782,  0.07105366,  0.0761881 , -0.03470261,\n",
       "        -0.08617369,  0.06336394,  0.07010492,  0.06199891, -0.07151797],\n",
       "       [-0.08500782, -0.02848217,  0.06395443,  0.06844416, -0.04716605,\n",
       "        -0.07028722,  0.0566711 ,  0.06326226,  0.05594537, -0.07733407],\n",
       "       [-0.12567579, -0.03454309,  0.06151951,  0.06473658, -0.02598038,\n",
       "        -0.07229564,  0.05510775,  0.05958541,  0.0535843 , -0.03603866],\n",
       "       [-0.11518624, -0.12218141,  0.06068403,  0.06542848,  0.00828538,\n",
       "        -0.02989593,  0.05526934,  0.05942468,  0.05310922, -0.03493756],\n",
       "       [-0.096861  , -0.06811536,  0.06529923,  0.06914278, -0.03646101,\n",
       "        -0.07375893,  0.05812411,  0.06367939,  0.05700297, -0.03805219],\n",
       "       [-0.03200445, -0.0795964 ,  0.04471733,  0.04555505, -0.0803572 ,\n",
       "        -0.0241954 ,  0.03834485,  0.04277945,  0.0394979 ,  0.00525887],\n",
       "       [-0.05856494, -0.04517702,  0.03057985,  0.0330983 , -0.0137974 ,\n",
       "         0.01264101,  0.02754355,  0.03035456,  0.0270927 , -0.04377061],\n",
       "       [-0.10235762, -0.04744896,  0.05251119,  0.05649327,  0.00015653,\n",
       "        -0.05822101,  0.04759051,  0.05156506,  0.04571183, -0.04600078],\n",
       "       [-0.01646565, -0.04931833,  0.04189723,  0.04373786, -0.07154809,\n",
       "        -0.03510034,  0.03596555,  0.04101235,  0.03694271, -0.02712328],\n",
       "       [-0.02422329, -0.03318957,  0.01832365,  0.01846995, -0.02877235,\n",
       "        -0.00788185,  0.01586042,  0.01729327,  0.01616089,  0.00795887]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac12e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64f25faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f2001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab06f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed6cbf",
   "metadata": {},
   "source": [
    "오차역전파법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0002e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d4fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07513461 0.22286265 0.09685668 0.04703451 0.08553811 0.15138841\n",
      "  0.0477268  0.11130724 0.08728707 0.07486393]\n",
      " [0.0836481  0.21668237 0.10592716 0.04455877 0.07923846 0.13658801\n",
      "  0.05561419 0.10144962 0.0984856  0.07780772]\n",
      " [0.09013689 0.18937667 0.10432438 0.05008898 0.08806897 0.12928442\n",
      "  0.05562383 0.12181306 0.09824247 0.07304033]\n",
      " [0.10638658 0.16839502 0.09162457 0.04945984 0.10512028 0.1306251\n",
      "  0.05661647 0.11663879 0.10316049 0.07197286]\n",
      " [0.08782615 0.16575594 0.1161166  0.04701027 0.11646285 0.1306896\n",
      "  0.06218191 0.11211907 0.09978648 0.06205113]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.2719835079067785\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_one_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2992d",
   "metadata": {},
   "source": [
    "모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09a81a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_one_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb07c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.09187374 0.10251572 0.05484677 0.11889112 0.1557883  0.1039344\n",
      "  0.09739202 0.1242035  0.07842745 0.07212698]\n",
      " [0.07179152 0.11134596 0.05332285 0.11725929 0.15605565 0.0861357\n",
      "  0.09663905 0.13313541 0.1007554  0.07355918]\n",
      " [0.07223014 0.07797382 0.05077095 0.11543298 0.15918526 0.11966505\n",
      "  0.10085746 0.15074135 0.08594869 0.0671943 ]\n",
      " [0.07283142 0.09764474 0.05481978 0.11077584 0.13274357 0.12212322\n",
      "  0.08904892 0.16605372 0.08805399 0.06590479]\n",
      " [0.08657013 0.09630065 0.05334276 0.12677896 0.14295732 0.10930316\n",
      "  0.09426612 0.13182183 0.07686684 0.08179223]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.3131326599238236\n",
      "---------\n",
      "[[0.10868509 0.11526851 0.0502034  0.10082176 0.1643114  0.1229908\n",
      "  0.0834103  0.10155663 0.06816519 0.08458691]\n",
      " [0.08970293 0.12672156 0.04906347 0.09921021 0.16816931 0.09950609\n",
      "  0.08293074 0.10919126 0.08808495 0.08741947]\n",
      " [0.08635903 0.08991457 0.04655228 0.09695906 0.17872828 0.13409952\n",
      "  0.08817608 0.12320584 0.07565369 0.08035165]\n",
      " [0.08567969 0.11761161 0.05065758 0.09480045 0.143571   0.13732764\n",
      "  0.07818971 0.13557079 0.07812876 0.07846276]\n",
      " [0.10125826 0.10960247 0.04878187 0.1075205  0.15284222 0.1227187\n",
      "  0.08188256 0.10753336 0.06722701 0.10063304]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.1330856556390896\n",
      "---------\n",
      "[[0.12366694 0.12499194 0.04556707 0.08625752 0.16800276 0.14026714\n",
      "  0.0715744  0.08468077 0.05924738 0.09574407]\n",
      " [0.10730231 0.13851749 0.04467029 0.08464888 0.17501214 0.11043756\n",
      "  0.07126323 0.09132727 0.07689351 0.09992732]\n",
      " [0.09904684 0.09963771 0.04221081 0.08212538 0.19380251 0.14443113\n",
      "  0.07712885 0.10271687 0.06644701 0.09245289]\n",
      " [0.09679512 0.13616354 0.04628777 0.08169705 0.15002709 0.14851449\n",
      "  0.06865327 0.11280282 0.06912965 0.08992919]\n",
      " [0.11385013 0.12006266 0.04423295 0.0920693  0.1581748  0.13260217\n",
      "  0.07128763 0.08963259 0.05877744 0.11931032]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.9914306522457497\n",
      "---------\n",
      "[[0.13668522 0.13213314 0.04127112 0.07454183 0.16866576 0.15592303\n",
      "  0.06177419 0.07177512 0.05171893 0.10551165]\n",
      " [0.12423736 0.14717968 0.04052964 0.07294587 0.17836224 0.11921587\n",
      "  0.06158046 0.07764715 0.06735782 0.1109439 ]\n",
      " [0.11012783 0.10735055 0.03813895 0.07029091 0.20587513 0.15138323\n",
      "  0.06782249 0.08712654 0.05855445 0.10332991]\n",
      " [0.10611495 0.15330292 0.04213043 0.07104553 0.15356638 0.15637776\n",
      "  0.06055289 0.09541089 0.06132387 0.10017437]\n",
      " [0.12433133 0.12805571 0.04003117 0.07970059 0.1605856  0.13957049\n",
      "  0.06244894 0.07606795 0.05161041 0.1375978 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.876639886379785\n",
      "---------\n",
      "[[0.1477589  0.13719175 0.03742877 0.06506557 0.16758898 0.17026661\n",
      "  0.05370729 0.06169573 0.04542754 0.11386885]\n",
      " [0.14030957 0.15327041 0.03678898 0.0634971  0.17956907 0.12624031\n",
      "  0.0536047  0.06694878 0.05934504 0.12042605]\n",
      " [0.11957495 0.11335456 0.03447981 0.06081099 0.21616683 0.15572804\n",
      "  0.06007044 0.07502522 0.0518987  0.11289046]\n",
      " [0.11370155 0.1691954  0.03835056 0.06236909 0.1552932  0.16166567\n",
      "  0.05375054 0.08186064 0.05467209 0.10914127]\n",
      " [0.13281347 0.13402538 0.03628465 0.06973774 0.16126088 0.14427521\n",
      "  0.05512553 0.06554769 0.04560058 0.15532886]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.7809820834859493\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d8ea3",
   "metadata": {},
   "source": [
    "추론 과정과 정확도(Accuracy) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88c8d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a2947e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15700483, 0.14062729, 0.03404962, 0.05733493, 0.1655913 ,\n",
       "       0.18363519, 0.04705606, 0.05368119, 0.04017621, 0.12084337])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8dc86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4604e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15700483 0.14062729 0.03404962 0.05733493 0.1655913  0.18363519\n",
      " 0.04705606 0.05368119 0.04017621 0.12084337]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_one_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462ffb9",
   "metadata": {},
   "source": [
    "전체 학습 과정이 구현된 사이클 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3fa3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 초기화 하고 시작\n",
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba6e708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.304791197292111\n",
      "train acc, test acc | 0.09915, 0.1009\n",
      "Loss:  0.7838873330596253\n",
      "train acc, test acc | 0.7970333333333334, 0.8\n",
      "Loss:  0.5032683507429573\n",
      "train acc, test acc | 0.87605, 0.8797\n",
      "Loss:  0.4683964449123461\n",
      "train acc, test acc | 0.89785, 0.9001\n",
      "Loss:  0.35660300169852666\n",
      "train acc, test acc | 0.90805, 0.9116\n",
      "Loss:  0.27523559354753496\n",
      "train acc, test acc | 0.9152666666666667, 0.9169\n",
      "Loss:  0.27336250965216985\n",
      "train acc, test acc | 0.9201166666666667, 0.9211\n",
      "Loss:  0.31260954132347146\n",
      "train acc, test acc | 0.9239333333333334, 0.9243\n",
      "Loss:  0.20143860714531084\n",
      "train acc, test acc | 0.9285333333333333, 0.9295\n",
      "Loss:  0.1720801819239371\n",
      "train acc, test acc | 0.93145, 0.932\n",
      "Loss:  0.21553141019344257\n",
      "train acc, test acc | 0.9347666666666666, 0.9354\n",
      "Loss:  0.3190854449733473\n",
      "train acc, test acc | 0.9374833333333333, 0.9387\n",
      "Loss:  0.15817791333225067\n",
      "train acc, test acc | 0.9396, 0.9393\n",
      "Loss:  0.25244678650724384\n",
      "train acc, test acc | 0.9416, 0.9417\n",
      "Loss:  0.15872802232416475\n",
      "train acc, test acc | 0.94345, 0.9431\n",
      "Loss:  0.3105175718902894\n",
      "train acc, test acc | 0.9455833333333333, 0.9441\n",
      "Loss:  0.2122782703380877\n",
      "train acc, test acc | 0.9473833333333334, 0.9465\n",
      "Loss:  0.18733015883460807\n",
      "train acc, test acc | 0.9492666666666667, 0.9462\n",
      "Loss:  0.1410041396340152\n",
      "train acc, test acc | 0.9504166666666667, 0.9473\n",
      "Loss:  0.09662423299039018\n",
      "train acc, test acc | 0.9522666666666667, 0.9491\n",
      "Loss:  0.16923404028998928\n",
      "train acc, test acc | 0.9533666666666667, 0.9493\n",
      "Loss:  0.14264658727330481\n",
      "train acc, test acc | 0.9542833333333334, 0.9499\n",
      "Loss:  0.1775937777627661\n",
      "train acc, test acc | 0.9558333333333333, 0.9517\n",
      "Loss:  0.10462853339738765\n",
      "train acc, test acc | 0.9565166666666667, 0.9523\n",
      "Loss:  0.12295848905663777\n",
      "train acc, test acc | 0.9574, 0.9533\n",
      "Loss:  0.15601739534745385\n",
      "train acc, test acc | 0.9584166666666667, 0.9543\n",
      "Loss:  0.15100187970080123\n",
      "train acc, test acc | 0.9597, 0.9543\n",
      "Loss:  0.08802769736225793\n",
      "train acc, test acc | 0.9604166666666667, 0.9556\n",
      "Loss:  0.10024913430086556\n",
      "train acc, test acc | 0.9609833333333333, 0.956\n",
      "Loss:  0.12958468343484494\n",
      "train acc, test acc | 0.9621166666666666, 0.9566\n",
      "Loss:  0.06407680475388261\n",
      "train acc, test acc | 0.9626333333333333, 0.9574\n",
      "Loss:  0.050852130866934735\n",
      "train acc, test acc | 0.9638333333333333, 0.9581\n",
      "Loss:  0.1302498822982418\n",
      "train acc, test acc | 0.9647166666666667, 0.9594\n",
      "Loss:  0.09352157110126737\n",
      "train acc, test acc | 0.9653166666666667, 0.9591\n",
      "Loss:  0.10412712655215936\n",
      "train acc, test acc | 0.9657166666666667, 0.9599\n",
      "Loss:  0.16545021548316996\n",
      "train acc, test acc | 0.9663666666666667, 0.9603\n",
      "Loss:  0.17411188262567948\n",
      "train acc, test acc | 0.9672, 0.9604\n",
      "Loss:  0.07372376596168899\n",
      "train acc, test acc | 0.9673333333333334, 0.9607\n",
      "Loss:  0.11817048031022495\n",
      "train acc, test acc | 0.96835, 0.961\n",
      "Loss:  0.1080689616417795\n",
      "train acc, test acc | 0.9684333333333334, 0.961\n",
      "Loss:  0.08024397303568855\n",
      "train acc, test acc | 0.9691166666666666, 0.962\n",
      "Loss:  0.10768728327510424\n",
      "train acc, test acc | 0.9694166666666667, 0.9627\n",
      "Loss:  0.0704945935561977\n",
      "train acc, test acc | 0.9700833333333333, 0.9634\n",
      "Loss:  0.13518750743972335\n",
      "train acc, test acc | 0.9705, 0.9629\n",
      "Loss:  0.16817557730145008\n",
      "train acc, test acc | 0.9708333333333333, 0.9641\n",
      "Loss:  0.053560791083619066\n",
      "train acc, test acc | 0.9716, 0.9633\n",
      "Loss:  0.15898729614309454\n",
      "train acc, test acc | 0.9715833333333334, 0.9641\n",
      "Loss:  0.0947971080568363\n",
      "train acc, test acc | 0.9722, 0.9639\n",
      "Loss:  0.09352496055819333\n",
      "train acc, test acc | 0.9726333333333333, 0.9646\n",
      "Loss:  0.11472306550753665\n",
      "train acc, test acc | 0.97295, 0.9653\n",
      "Loss:  0.04684011346704011\n",
      "train acc, test acc | 0.9736333333333334, 0.9656\n",
      "Loss:  0.1254851060274574\n",
      "train acc, test acc | 0.9741, 0.966\n",
      "Loss:  0.12744525506007537\n",
      "train acc, test acc | 0.9746166666666667, 0.9653\n",
      "Loss:  0.11958017663949018\n",
      "train acc, test acc | 0.9748833333333333, 0.9667\n",
      "Loss:  0.056758211256459024\n",
      "train acc, test acc | 0.97515, 0.9667\n",
      "Loss:  0.035633874074258026\n",
      "train acc, test acc | 0.9754, 0.9676\n",
      "Loss:  0.07540127318984237\n",
      "train acc, test acc | 0.97585, 0.967\n",
      "Loss:  0.043712675793646676\n",
      "train acc, test acc | 0.9759333333333333, 0.9669\n",
      "Loss:  0.032583119029470906\n",
      "train acc, test acc | 0.9766666666666667, 0.9669\n",
      "Loss:  0.1362247551025725\n",
      "train acc, test acc | 0.9768333333333333, 0.9673\n",
      "Loss:  0.12368163632102495\n",
      "train acc, test acc | 0.97735, 0.967\n",
      "Loss:  0.10824951826894282\n",
      "train acc, test acc | 0.9772666666666666, 0.9679\n",
      "Loss:  0.08055617565737655\n",
      "train acc, test acc | 0.97765, 0.9678\n",
      "Loss:  0.0909716195276917\n",
      "train acc, test acc | 0.97785, 0.9686\n",
      "Loss:  0.11157854115193622\n",
      "train acc, test acc | 0.9782, 0.9681\n",
      "Loss:  0.036065840828400086\n",
      "train acc, test acc | 0.9783666666666667, 0.9685\n",
      "Loss:  0.08332602257647911\n",
      "train acc, test acc | 0.9788333333333333, 0.9683\n",
      "Loss:  0.13650787089597904\n",
      "train acc, test acc | 0.9792833333333333, 0.9685\n",
      "Loss:  0.06767056932327015\n",
      "train acc, test acc | 0.9792333333333333, 0.9682\n",
      "Loss:  0.07635073346795698\n",
      "train acc, test acc | 0.9790833333333333, 0.9687\n",
      "Loss:  0.03417274007432695\n",
      "train acc, test acc | 0.9797333333333333, 0.9693\n",
      "Loss:  0.04733450071344703\n",
      "train acc, test acc | 0.9796, 0.9693\n",
      "Loss:  0.037111206217271576\n",
      "train acc, test acc | 0.9799666666666667, 0.9696\n",
      "Loss:  0.12313667478879159\n",
      "train acc, test acc | 0.9800333333333333, 0.9696\n",
      "Loss:  0.05370967279305403\n",
      "train acc, test acc | 0.9803, 0.9692\n",
      "Loss:  0.1250544434575457\n",
      "train acc, test acc | 0.98085, 0.9693\n",
      "Loss:  0.0756721327207504\n",
      "train acc, test acc | 0.981, 0.9698\n",
      "Loss:  0.0616926576580579\n",
      "train acc, test acc | 0.9808666666666667, 0.9695\n",
      "Loss:  0.040582314636686566\n",
      "train acc, test acc | 0.9809, 0.9699\n",
      "Loss:  0.052534581194315165\n",
      "train acc, test acc | 0.9817666666666667, 0.9704\n",
      "Loss:  0.05573843928552141\n",
      "train acc, test acc | 0.9816, 0.9707\n",
      "Loss:  0.06228318648888535\n",
      "train acc, test acc | 0.9816, 0.9704\n",
      "Loss:  0.048930330298491594\n",
      "train acc, test acc | 0.9820833333333333, 0.9703\n",
      "Loss:  0.1262637720720931\n",
      "train acc, test acc | 0.9825333333333334, 0.9698\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train_reshaped[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "        \n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7594de77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "422629e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
