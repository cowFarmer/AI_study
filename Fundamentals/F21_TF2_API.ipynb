{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48eeba2",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6417192",
   "metadata": {},
   "source": [
    "딥러닝 프레임워크로 Tensorflow를 많이 사용했는데, pyTorch도 있다. pyTorch는 파이써닉하고 직관적인 API 설계와 쉬운 사용 방법이 장점이다. Tensorflow도 이번에 V2가 되면서 파이토치의 장점들을 흡수했고 keras를 표준 API로 삼으면서 강력하게 버전업했다.   \n",
    "앞으로 계속 사용하게될 tensorflow를 살펴보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00992a5",
   "metadata": {},
   "source": [
    "## TensorFlow2 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14f899",
   "metadata": {},
   "source": [
    "tensorflow2는 딥러닝 모델을 작성할 때 다양한 방법이 있다. `Sequential`, `Functional`, `Model Subclassing`이 있다. 예시를 보면서 살펴보자.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e4dbe4",
   "metadata": {},
   "source": [
    "- TensorFlow2 Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996dffda",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3815898576.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_105/3815898576.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    model.add(__넣고싶은 레이어__)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "\n",
    "model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15736c7",
   "metadata": {},
   "source": [
    "딥러닝 모델을 sequential하게 차곡차곡 add로 쌓아가는 방식이다. 반드시 입력 1가지, 출력 1가지를 전제로 하기 때문에 입출력이 여러 개인 경우에는 적합하지 않은 모델링 방식이다.   \n",
    "[텐서플로 2.0 시작하기: 초보자용](https://www.tensorflow.org/tutorials/quickstart/beginner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8023dc74",
   "metadata": {},
   "source": [
    "- TensorFlow2 Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(__원하는 입력값 모양__))\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(input)\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "outputs = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd062a3",
   "metadata": {},
   "source": [
    "`keras.Model`을 사용한다. 사실 `Sequential Model`도 `keras.Model`을 상속받아 확장한 사례이다. 이를 사용하면 `Sequential Model`보다 자유로운 모델링을 진행할 수 있고 함수형으로 모델을 구성할 수 있습니다. 즉 입력과 출력을 규정함으로써 모델 전체를 규정합니다. `input`을 규정하면서 텐서가 여러개 될 수 있고 레이어들을 자유롭게 엮어 output까지 규정하면 이 둘만으로 Model이 규정된다. 다중 입출력을 가지는 모델을 구성할 수 있다.   \n",
    "[The Keras functional API](https://www.tensorflow.org/guide/keras/functional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fea987",
   "metadata": {},
   "source": [
    "- TensorFlow2 Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ec7ef",
   "metadata": {},
   "source": [
    "제일 자유로운 모델링을 진행할 수 있다. 본질적으로는 `Functional`한 접근과 차이가 없지만 `__init__()`메서드 안에서 레이어 구성을 정의하고 `call()`메서드 안에서 레이어간 `forward propagation`을 구현한다.    \n",
    "[텐서플로 2.0 시작하기: 전문가용](https://www.tensorflow.org/tutorials/quickstart/advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb978f8",
   "metadata": {},
   "source": [
    "## MNIST Sequential API 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef004e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769ef4c",
   "metadata": {},
   "source": [
    "## MNIST Functional API 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93a1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf9e692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c437de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef07f75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 36s 4ms/step - loss: 0.1058 - accuracy: 0.9676\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0343 - accuracy: 0.9892\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0203 - accuracy: 0.9931\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0122 - accuracy: 0.9962\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0091 - accuracy: 0.9970\n",
      "313/313 - 1s - loss: 0.0475 - accuracy: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04746171087026596, 0.9876999855041504]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f751ce3",
   "metadata": {},
   "source": [
    "## MNIST Subclassing 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c9de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c0f3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff104f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01bb9f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1070 - accuracy: 0.9671\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0326 - accuracy: 0.9895\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0195 - accuracy: 0.9937\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0094 - accuracy: 0.9969\n",
      "313/313 - 1s - loss: 0.0453 - accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0452626496553421, 0.9896000027656555]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac33da1",
   "metadata": {},
   "source": [
    "## CIFAR-100 Sequntial API 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abcb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5254a7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd878f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b704909a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 3.6056 - accuracy: 0.1604\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9194 - accuracy: 0.2802\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6221 - accuracy: 0.3403\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4081 - accuracy: 0.3850\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2470 - accuracy: 0.4195\n",
      "313/313 - 1s - loss: 2.5882 - accuracy: 0.3476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.588207960128784, 0.3476000130176544]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5537b53",
   "metadata": {},
   "source": [
    "## CIFAR-100 Functional API 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff4f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1220d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20651209",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac1aebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6034 - accuracy: 0.1547\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9169 - accuracy: 0.2798\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6228 - accuracy: 0.3387\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4157 - accuracy: 0.3832\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2501 - accuracy: 0.4207\n",
      "313/313 - 1s - loss: 2.6061 - accuracy: 0.3508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6060843467712402, 0.3508000075817108]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274a6a7",
   "metadata": {},
   "source": [
    "## CIFAR-100 Subclassing API 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3febd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7175e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43ec8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ad0f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9912 - accuracy: 0.4763\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8391 - accuracy: 0.5118\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7022 - accuracy: 0.5410\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5749 - accuracy: 0.5728\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4559 - accuracy: 0.5990\n",
      "313/313 - 1s - loss: 2.9329 - accuracy: 0.3559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9329421520233154, 0.35589998960494995]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206a980",
   "metadata": {},
   "source": [
    "## GradientTape 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9836955",
   "metadata": {},
   "source": [
    "비슷한 문제 2개를 3개의 모델 구성 방법을 활용해서 딥러닝으로 구현했다. 모델 학습 설정 부분은 완전히 동일하게 구성했다.   \n",
    "`model.fit()`으로 훈련 과정을 Numpy만 갖고 구현하는 과정을 생각해보자.   \n",
    "1. Forward Propagation 수행 및 중간 레이어값 저장\n",
    "2. Loss값 계산\n",
    "3. 중간 레이어값 및 Loss를 활용한 체인룰(chain rule)방식 역전파(backward propagation) 수행\n",
    "4. 학습 파라미터 업데이트\n",
    "\n",
    "위의 4단계로 이루어진 train_step을 여러 번 반복해야한다. TF2 API는 `model.fit()` 메서드에 모두 추상화되어 있다.   \n",
    "\n",
    "`tf.GradientTape`는 위와 같이 순전파(forward pass)로 진행되는 모든 연산의 중간 레이어값을 tape에 기록하고 이를 이용해 gradient를 계산하고 tape를 폐기하는 기능을 갖고 있다. 학습을 세팅하고 핏을 맞추는 `model.compile()`, `model.fit()` 부분을 중심으로 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b52440b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffe85de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e79456",
   "metadata": {},
   "source": [
    "`model.compile()` -> `tape.gradient()`를 통해 해당 기능이 구현되고 있다. 매 스텝 학습이 진행될 때마다 gradient를 추출한 후 `optimizer.apply_gradients()`를 통해 `model.trainable_variables`를 지정해주는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afe0554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 3.0828\n",
      "Epoch 1: last batch loss = 2.6083\n",
      "Epoch 2: last batch loss = 2.2664\n",
      "Epoch 3: last batch loss = 2.0935\n",
      "Epoch 4: last batch loss = 1.9813\n",
      "It took 78.9842140674591 seconds\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "            if step % batch_size == batch_size-1:\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdba90",
   "metadata": {},
   "source": [
    "`model.fit()`으로 수행되던 학습 과정은 매 스텝마다 위에서 구현한 `train_step()`으로 구현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa7411",
   "metadata": {},
   "source": [
    "`tf.GradientTape()`를 활용하면 `model.compile()`과 `model.fit()` 안에 감추어 있던 학습 단계를 끄집어내서 자유롭게 재구성할 수 있게된다. 지도학습, 강화학습, GAN(Generative Advasarial Network)학습을 위해선 `train_step` 메서드의 재구성이 필수적이므로 꼭 알아두자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc4c049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 897ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3423"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1467eb",
   "metadata": {},
   "source": [
    "그래디언트를 활용할 필요가 없는 evaluation 단계는 `model.predict()` 메서드를 활용할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
